diff -rupN /home/grads/poremba/gems_orig/common/Makefile.common /home/grads/poremba/gems/common/Makefile.common
--- /home/grads/poremba/gems_orig/common/Makefile.common	2011-02-07 16:36:53.000000000 -0500
+++ /home/grads/poremba/gems/common/Makefile.common	2010-10-02 10:50:57.000000000 -0400
@@ -60,7 +60,7 @@ ifeq ($(SIMICS_VERSION),3.0)
   SIMICS_EXEC_ROOT := $(GEMS_ROOT)/simics
   # NOTE: This variable must be updated to point to the src/include directory
   # of your Simics 3.0 installation
-  SIMICS_INCLUDE_ROOT := $(GEMS_ROOT)/simics_exec/src/include
+  SIMICS_INCLUDE_ROOT := /home/mdl/srikanta/simics/simics-3.0.31/src/include
 else
   SIMICS_ROOT := /dev/blah
   SIMICS_EXEC_ROOT := /dev/foo
@@ -113,8 +113,8 @@ ifeq ($(HOST_TYPE),v9-sol8-64)
   LDFLAGS += -m64 -L/s/getopt-0/lib -lgetopt
 else
 ifeq ($(HOST_TYPE),x86-linux)
-  CC =  /s/gcc-3.4.1/bin/g++
-  #CC =  /usr/bin/g++
+  #CC =  /s/gcc-3.4.1/bin/g++
+  CC =  /usr/bin/g++
   OPT_FLAGS = -march=i686
   LDFLAGS += -ggdb -g3
 else
diff -rupN /home/grads/poremba/gems_orig/common/Makefile.simics_version /home/grads/poremba/gems/common/Makefile.simics_version
--- /home/grads/poremba/gems_orig/common/Makefile.simics_version	2011-02-07 16:36:53.000000000 -0500
+++ /home/grads/poremba/gems/common/Makefile.simics_version	2010-10-02 10:49:42.000000000 -0400
@@ -4,9 +4,9 @@
 # 2.2.X (for Simics 2.0.X and 2.2.X)
 # 3.0
 
-SIMICS_VERSION := 2.2.X
+SIMICS_VERSION := 3.0
 
 # Whether to use SPARC or x86 specific code paths
 #  Comment out to compile for x86
-TARGET_MACHINE_TYPE = SPARC
+#TARGET_MACHINE_TYPE = SPARC
 
diff -rupN /home/grads/poremba/gems_orig/opal/module/Makefile /home/grads/poremba/gems/opal/module/Makefile
--- /home/grads/poremba/gems_orig/opal/module/Makefile	2011-02-07 16:36:56.000000000 -0500
+++ /home/grads/poremba/gems/opal/module/Makefile	2010-10-02 10:51:44.000000000 -0400
@@ -17,10 +17,10 @@
 #   CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 
 # For Simics 2.X
-GEMS_ROOT = $(SIMICS_BASE)/../
+#GEMS_ROOT = $(SIMICS_BASE)/../
 
 # For Simics 3.0
-#GEMS_ROOT = $(SRC_BASE)/../../
+GEMS_ROOT = $(SRC_BASE)/../../
 
 include $(GEMS_ROOT)/common/Makefile.simics_version
 
diff -rupN /home/grads/poremba/gems_orig/opal/system/#cacccccccls# /home/grads/poremba/gems/opal/system/#cacccccccls#
--- /home/grads/poremba/gems_orig/opal/system/#cacccccccls#	1969-12-31 19:00:00.000000000 -0500
+++ /home/grads/poremba/gems/opal/system/#cacccccccls#	2010-10-19 14:20:01.000000000 -0400
@@ -0,0 +1,5 @@
+
+
+
+
+
diff -rupN /home/grads/poremba/gems_orig/opal/system/cache.C /home/grads/poremba/gems/opal/system/cache.C
--- /home/grads/poremba/gems_orig/opal/system/cache.C	2011-02-07 16:36:55.000000000 -0500
+++ /home/grads/poremba/gems/opal/system/cache.C	2011-02-14 16:57:26.000000000 -0500
@@ -177,6 +177,7 @@ generic_cache_template<BlockType>::gener
 #endif
 
 //**************************************************************************
+#if 0
 template <class BlockType>
 generic_cache_template<BlockType>::~generic_cache_template()
 {
@@ -185,8 +186,10 @@ generic_cache_template<BlockType>::~gene
     cache = NULL;
   }
 }
+#endif
 
 //**************************************************************************
+#if 0
 template <class BlockType>
 bool generic_cache_template<BlockType>::TagSearch(pa_t a, bool setMRU, bool setDirty,
     BlockType** block_ptr, uint32 *way) {
@@ -218,8 +221,10 @@ bool generic_cache_template<BlockType>::
 #endif
   return cachehit;
 }
+#endif
 
 //**************************************************************************
+#if 0
 template <class BlockType>
 void generic_cache_template<BlockType>::DoBeforeReplace(BlockType *b, uint32 way) {
   /* update stats */
@@ -228,13 +233,17 @@ void generic_cache_template<BlockType>::
     if (IsDirty(*b)) STAT_INC(writebacks);
   }
 }
+#endif
 
 //**************************************************************************
+#if 0
 template <class BlockType>
 void generic_cache_template<BlockType>::DoAfterFill(BlockType *b, uint32 way) {
 }
+#endif
 
 //**************************************************************************
+#if 0
 template <class BlockType>
 void generic_cache_template<BlockType>::DoWhenAccessHit(BlockType *b, bool read, bool data) {
   ASSERT(IsValid(*b));
@@ -247,8 +256,10 @@ void generic_cache_template<BlockType>::
     STAT_INC(write_hit);
   }
 }
+#endif 
 
 //**************************************************************************
+#if 0
 template <class BlockType>
 void generic_cache_template<BlockType>::DoWhenAccessMiss(my_addr_t a, bool read, bool data) {
   if(read) {
@@ -259,6 +270,7 @@ void generic_cache_template<BlockType>::
     STAT_INC(write_miss);
   }
 }
+#endif
 
 //**************************************************************************
 #if 0
@@ -300,6 +312,7 @@ bool generic_cache_template<BlockType>::
 #endif
 
 //**************************************************************************
+#if 0
 template <class BlockType>
 uint32 generic_cache_template<BlockType>::GetLRU(BlockType* set) {
 
@@ -319,6 +332,7 @@ uint32 generic_cache_template<BlockType>
   }
   return lru;
 }
+#endif
 
 //**************************************************************************
 #if 0
@@ -361,6 +375,7 @@ pa_t generic_cache_template<BlockType>::
 #endif
 
 //**************************************************************************
+#if 0
 template <class BlockType>
 void generic_cache_template<BlockType>::Warmup(pa_t a) {
 
@@ -380,8 +395,10 @@ void generic_cache_template<BlockType>::
   /* write new block into the cache */
   set[replace_set].address_state = ba | CACHE_BLK_VALID;
 }
+#endif
 
 //**************************************************************************
+#if 0
 template <class BlockType>
 void generic_cache_template<BlockType>::OracleAccess(pa_t a) {
   /* used when we want the execution of a particular load or store to
@@ -411,6 +428,7 @@ void generic_cache_template<BlockType>::
   set[replace_set].address_state = ba | CACHE_BLK_VALID;
   set[replace_set].last_access = m_eventQueue->getCycle();
 }
+#endif 
 
 //**************************************************************************
 /* this function is called when a store is retired.  If the address
@@ -493,6 +511,7 @@ void generic_cache_template<BlockType>::
 #endif
 
 //**************************************************************************
+#if 0
 template <class BlockType>
 attr_value_t generic_cache_template<BlockType>::get_cache_data( void *ptr, void *obj ) {
   generic_cache_template<BlockType> *cache_obj  = static_cast<generic_cache_template<BlockType> *>(ptr);
@@ -530,8 +549,10 @@ attr_value_t generic_cache_template<Bloc
   }
   return (ret);
 }
+#endif 
 
 //**************************************************************************
+#if 0
 template <class BlockType>
 set_error_t generic_cache_template<BlockType>::set_cache_data( void *ptr,
     void *obj, attr_value_t *value ) {
@@ -567,8 +588,10 @@ set_error_t generic_cache_template<Block
   }  
   return Sim_Set_Ok;
 }
+#endif
 
 //**************************************************************************
+#if 0
 template <class BlockType>
 int generic_cache_template<BlockType>::registerCheckpoint( confio_t *conf )
 {
@@ -579,6 +602,7 @@ int generic_cache_template<BlockType>::r
                                  generic_cache_template<BlockType>::set_cache_data, (void *) this );
   return rc;
 }
+#endif
 
 /*------------------------------------------------------------------------*/
 /* Accessor(s) / mutator(s)                                               */
diff -rupN /home/grads/poremba/gems_orig/opal/system/cache.h /home/grads/poremba/gems/opal/system/cache.h
--- /home/grads/poremba/gems_orig/opal/system/cache.h	2011-02-07 16:36:54.000000000 -0500
+++ /home/grads/poremba/gems/opal/system/cache.h	2011-02-14 16:57:42.000000000 -0500
@@ -59,6 +59,12 @@
 
 #include "mshr.h"
 #include "scheduler.h"
+#include "confio.h"
+#include "hfa.h"
+#include "hfacore.h"
+#include "bitlib.h"
+
+#define DEBUG_CACHE
 
 /*------------------------------------------------------------------------*/
 /* Macro declarations                                                     */
@@ -220,7 +226,13 @@ public:
     m_ideal = ideal;
   } ;
 
-  virtual ~generic_cache_template();
+  ~generic_cache_template()
+  {
+    if (cache) {
+      free(cache);
+      cache = NULL;
+    }
+  };
   //@}
 
   /// get block size in byte
@@ -239,6 +251,10 @@ public:
   /// interface used by the procssor
   bool Read(pa_t a, waiter_t *w, bool data_request = true,
             bool *primary_bool = NULL){
+    static int reads = 0;
+
+    printf("Read called!\n");
+
     /* always hit if ideal */
     if(m_ideal) return true;
     
@@ -261,6 +277,11 @@ public:
       ASSERT(w);
       hit = (NULL == mshr->Miss(a, (cache_t *)this, priority, w, primary_bool));
     }
+
+    if( ( reads++ % 10000 ) == 0 )
+      {
+	printf("After 10K reads: %d read miss, %d write miss\n", read_miss, write_miss);
+      }
     
     return hit;
   };
@@ -293,7 +314,25 @@ public:
     mshr->Miss(a, (cache_t *)this, PREFETCH_PRIORITY, NULL);
   };
 
-  void Warmup(pa_t a);
+  void Warmup(pa_t a)
+  {
+    uint32 index = Set(a);
+    pa_t ba = BlockAddress(a);
+    ASSERT(index < n_sets);
+    
+    /* search all sets until we find a match */
+    BlockType *set = &cache[index * m_assoc];
+    for (uint32 i = 0 ; i < m_assoc ; i ++) {
+      bool hit = IsValid(set[i]) && (getBlockAddress(set[i]) == ba);
+      if (hit) { 
+	return;
+      }
+    }
+    int replace_set = random() % m_assoc;
+    /* write new block into the cache */
+    set[replace_set].address_state = ba | CACHE_BLK_VALID;
+    
+  };
 
   /** This function is called when mshr is ready to fill the incoming
    *  cache line
@@ -374,35 +413,221 @@ public:
   /** This function is called when upper level mshr want to oracle
    *  access a block
    */
-  void OracleAccess(pa_t a);
+  void OracleAccess(pa_t a)
+  {
+    /* used when we want the execution of a particular load or store to
+     * be prefetched perfectly.
+     */
+    uint32 index = Set(a);
+    pa_t ba = BlockAddress(a);
+    ASSERT(index < n_sets);
+    STAT_INC(reads);
+    
+    /* search all sets until we find a match */
+    BlockType *set = &cache[index * m_assoc];
+    int replace_set = 0;
+    for (uint32 i = 0 ; i < m_assoc ; i ++) {
+      bool hit = IsValid(set[i]) && (getBlockAddress(set[i]) == ba);
+      if (hit) { 
+	STAT_INC(read_hit);
+	return;
+      } 
+      if (set[i].last_access < set[replace_set].last_access) {
+	replace_set = i;
+      }
+    };
+    
+    /* write new block into the cache */
+    STAT_INC(read_miss);
+    set[replace_set].address_state = ba | CACHE_BLK_VALID;
+    set[replace_set].last_access = m_eventQueue->getCycle();
+    
+  };
 
   /// This interface is provided _only_ for saving the state (via confio)
-  int  registerCheckpoint( confio_t *conf );
+  int  registerCheckpoint( confio_t *conf )
+  {
+    int rc;
+    
+    rc = conf->register_attribute( name,
+				   generic_cache_template<BlockType>::get_cache_data, (void *) this,
+				   generic_cache_template<BlockType>::set_cache_data, (void *) this );
+    return rc;
+  };
   
 protected:
 
   /// interface used by simics
-  static attr_value_t get_cache_data( void *ptr, void *obj );
-  static set_error_t  set_cache_data( void *ptr, void *obj, attr_value_t *value );
+  static attr_value_t get_cache_data( void *ptr, void *obj )
+    {
+      generic_cache_template<BlockType> *cache_obj  = static_cast<generic_cache_template<BlockType> *>(ptr);
+      BlockType                    *cache_sets = cache_obj->cache;
+      uint32                        n_sets = cache_obj->n_sets;
+      uint32                        assoc  = cache_obj->m_assoc;
+      attr_value_t                  ret;
+      attr_value_t                 *vec;
+      attr_value_t                 *subvec;
+      
+      memset( &ret, 0, sizeof(attr_value_t) );
+      ret.kind = Sim_Val_List;
+      vec = mallocAttribute(n_sets + 1);
+      ret.u.list.size   = n_sets + 1;
+      ret.u.list.vector = vec;
+      
+      // saves the current global time
+      vec[n_sets].kind      = Sim_Val_Integer;
+      vec[n_sets].u.integer = cache_obj->getEventQueue()->getCycle();
+      
+      for (uint32 i = 0; i < n_sets; i++ ) {
+	vec[i].kind        = Sim_Val_List;
+	vec[i].u.list.size = assoc * 2;
+	subvec             = mallocAttribute(assoc * 2);
+	vec[i].u.list.vector = subvec;
+	
+	for (uint32 j = 0; j < assoc; j++) {
+	  subvec[j*2].kind      = Sim_Val_Integer;
+	  subvec[j*2].u.integer = cache_sets[i*assoc + j].address_state;
+	  subvec[j*2 + 1].kind      = Sim_Val_Integer;
+	  // assuming cycles will be restarted at 0, we need to shift all
+	  // mru times by the current cycle value 
+	  subvec[j*2 + 1].u.integer = cache_sets[i*assoc + j].last_access;
+	}
+      }
+      return (ret);
+    };
+
+
+  static set_error_t  set_cache_data( void *ptr, void *obj, attr_value_t *value )
+    {
+      generic_cache_template<BlockType> *cache_obj  = static_cast<generic_cache_template<BlockType> *>(ptr);
+      BlockType                    *cache_sets = cache_obj->cache;
+      uint32                       n_sets = cache_obj->n_sets;
+      uint32                       assoc  = cache_obj->m_assoc;
+      attr_value_t                 *vec;
+      attr_value_t                 *subvec;
+      
+      if (value->kind != Sim_Val_List)
+	return Sim_Set_Need_List;
+      if (value->u.list.size != n_sets + 1)
+	return Sim_Set_Illegal_Value;
+      
+      vec = value->u.list.vector;
+      
+      if (vec[n_sets].kind != Sim_Val_Integer)
+	return Sim_Set_Illegal_Value;
+      int64 offsetCycle = vec[n_sets].u.integer;
+      for (uint32 i = 0; i < n_sets; i++ ) {
+	if (vec[i].kind != Sim_Val_List)
+	  return Sim_Set_Need_List;
+	if (vec[i].u.list.size != assoc * 2)
+	  return Sim_Set_Illegal_Value;
+	
+	subvec = vec[i].u.list.vector;
+	for (uint32 j = 0; j < assoc; j++) {
+	  cache_sets[i*assoc + j].address_state = subvec[j*2].u.integer;
+	  cache_sets[i*assoc + j].last_access   = subvec[j*2 + 1].u.integer -
+	    offsetCycle;
+	}
+      }  
+      return Sim_Set_Ok;
+      
+    };
 
   /// search for a block with address
   bool TagSearch(pa_t a, bool setMRU, bool setDirty,
-                 BlockType** block, uint32* way);
+                 BlockType** block_ptr, uint32* way) {
+    
+    uint32 index = Set(a);
+    pa_t   ba = BlockAddress(a);
+    bool   cachehit = false;
+    ASSERT(index < n_sets);
+    
+    /* search all sets until we find a match */
+    BlockType *set = &cache[index * m_assoc];
+    for (uint32 i = 0 ; i < m_assoc ; i ++) {
+      // if it is found in the cache ...
+      if ( (IsValid(set[i]) && getBlockAddress(set[i]) == ba) ) {
+	if(setMRU)
+	  set[i].last_access = m_eventQueue->getCycle();
+	if(setDirty)
+	  set[i].address_state |= CACHE_BLK_DIRTY;
+	cachehit = true;
+	if(block_ptr) *block_ptr = &set[i];
+	if(way) *way = i;
+	break;
+      }
+    }
+    
+#ifdef DEBUG_CACHE
+    DEBUG_OUT( "%s TagSearch 0x%0llx (TagSearch: index: 0x%0x) ... %d\n",
+	       name, a, index, cachehit);
+#endif
+    return cachehit;
+  };
 
   /// get LRU way of an address
-  uint32       GetLRU(BlockType* set);
+  uint32       GetLRU(BlockType* set)
+  {
+    // search all blocks in this set to find InValid or LRU
+    uint32 lru       = 0;
+    tick_t lru_cycle = set[lru].last_access;
+    for (uint32 i = 0 ; i < m_assoc ; i++) {
+      if (IsValid(set[i])) {
+	if(set[i].last_access < lru_cycle) {
+	  lru_cycle = set[i].last_access;
+	  lru = i;
+	}
+      } else {
+	lru = i;
+	break;
+      }
+    }
+    return lru;
+  };
 
   /// handler called before a block is replaced
-  virtual void DoBeforeReplace(BlockType *b, uint32 way);
+  void DoBeforeReplace(BlockType *b, uint32 way)
+  {
+    /* update stats */
+    if(IsValid(*b)) {
+      STAT_INC(replacements);
+      if (IsDirty(*b)) STAT_INC(writebacks);
+    }
+  };
 
   /// handler called after a block is filled
-  virtual void DoAfterFill(BlockType *b, uint32 way);
+  void DoAfterFill(BlockType *b, uint32 way)
+  {
+  };
 
   /// handler called when cache access hit
-  virtual void DoWhenAccessHit(BlockType *b, bool read, bool data);
+  void DoWhenAccessHit(BlockType *b, bool read, bool data)
+  {
+    ASSERT(IsValid(*b));
+    
+    if(read) {
+      STAT_INC(reads);
+      STAT_INC(read_hit);
+    } else {
+      STAT_INC(writes);
+      STAT_INC(write_hit);
+    }
+
+  };
 
   /// handler called when cache access miss
-  virtual void DoWhenAccessMiss(my_addr_t a, bool read, bool data);
+  void DoWhenAccessMiss(my_addr_t a, bool read, bool data)
+  {
+
+    if(read) {
+      STAT_INC(reads);
+      STAT_INC(read_miss);
+    } else {
+      STAT_INC(writes);
+      STAT_INC(write_miss);
+    }
+
+  };
 
   /** @name Cache line state accessors:
    *        gets the cache state (readable, writeable, etc.)
diff -rupN /home/grads/poremba/gems_orig/opal/system/system.C /home/grads/poremba/gems/opal/system/system.C
--- /home/grads/poremba/gems_orig/opal/system/system.C	2011-02-07 16:36:54.000000000 -0500
+++ /home/grads/poremba/gems/opal/system/system.C	2011-02-07 16:32:19.000000000 -0500
@@ -196,6 +196,7 @@ system_t::system_t( const char *configur
 #ifdef MODINIT_VERBOSE
   DEBUG_OUT("[ 10] system_t() constructor\n");
 #endif
+
   hfa_checkerr("system initialization");
 
   if (configurationFile == NULL)
diff -rupN /home/grads/poremba/gems_orig/protocols/MOESI_CMP_directory_mainmem-dir.sm /home/grads/poremba/gems/protocols/MOESI_CMP_directory_mainmem-dir.sm
--- /home/grads/poremba/gems_orig/protocols/MOESI_CMP_directory_mainmem-dir.sm	1969-12-31 19:00:00.000000000 -0500
+++ /home/grads/poremba/gems/protocols/MOESI_CMP_directory_mainmem-dir.sm	2011-02-01 14:27:24.000000000 -0500
@@ -0,0 +1,734 @@
+
+/*
+    Copyright (C) 1999-2005 by Mark D. Hill and David A. Wood for the
+    Wisconsin Multifacet Project.  Contact: gems@cs.wisc.edu
+    http://www.cs.wisc.edu/gems/
+
+    --------------------------------------------------------------------
+
+    This file is part of the SLICC (Specification Language for
+    Implementing Cache Coherence), a component of the Multifacet GEMS
+    (General Execution-driven Multiprocessor Simulator) software
+    toolset originally developed at the University of Wisconsin-Madison.
+                                                                                
+    SLICC was originally developed by Milo Martin with substantial
+    contributions from Daniel Sorin.
+
+    Substantial further development of Multifacet GEMS at the
+    University of Wisconsin was performed by Alaa Alameldeen, Brad
+    Beckmann, Ross Dickson, Pacia Harper, Milo Martin, Michael Marty,
+    Carl Mauer, Kevin Moore, Manoj Plakal, Daniel Sorin, Min Xu, and
+    Luke Yen.
+
+    --------------------------------------------------------------------
+
+    If your use of this software contributes to a published paper, we
+    request that you (1) cite our summary paper that appears on our
+    website (http://www.cs.wisc.edu/gems/) and (2) e-mail a citation
+    for your published paper to gems@cs.wisc.edu.
+
+    If you redistribute derivatives of this software, we request that
+    you notify us and either (1) ask people to register with us at our
+    website (http://www.cs.wisc.edu/gems/) or (2) collect registration
+    information and periodically send it to us.
+
+    --------------------------------------------------------------------
+
+    Multifacet GEMS is free software; you can redistribute it and/or
+    modify it under the terms of version 2 of the GNU General Public
+    License as published by the Free Software Foundation.
+
+    Multifacet GEMS is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+    General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with the Multifacet GEMS; if not, write to the Free Software
+    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
+    02111-1307, USA
+
+    The GNU General Public License is contained in the file LICENSE.
+
+### END HEADER ###
+*/
+/*
+ * $Id: MOESI_CMP_directory-dir.sm 1.11 05/01/19 15:48:35-06:00 mikem@royal16.cs.wisc.edu $
+ */
+
+machine(Directory, "Directory protocol") {
+
+  // ** IN QUEUES **
+  MessageBuffer foo1, network="From", virtual_network="0", ordered="false";  // a mod-L2 bank -> this Dir
+  MessageBuffer requestToDir, network="From", virtual_network="1", ordered="false";  // a mod-L2 bank -> this Dir
+  MessageBuffer responseToDir, network="From", virtual_network="2", ordered="false";  // a mod-L2 bank -> this Dir
+
+  MessageBuffer goo1, network="To", virtual_network="0", ordered="false";  
+  MessageBuffer forwardFromDir, network="To", virtual_network="1", ordered="false";  
+  MessageBuffer responseFromDir, network="To", virtual_network="2", ordered="false";  // Dir -> mod-L2 bank
+
+   MessageBuffer addressFromMem, network="From", virtual_network="4", ordered="false";
+
+
+  // STATES
+  enumeration(State, desc="Directory states", default="Directory_State_I") {
+    // Base states
+    I, desc="Invalid";
+    S, desc="Shared";
+    O, desc="Owner";
+    M, desc="Modified";
+
+    IS, desc="Blocked, was in idle";
+    SS, desc="Blocked, was in shared";
+    OO, desc="Blocked, was in owned";
+    MO, desc="Blocked, going to owner or maybe modified";
+    MM, desc="Blocked, going to modified";
+
+    MI, desc="Blocked on a writeback";
+    MIS, desc="Blocked on a writeback, but don't remove from sharers when received";
+    OS, desc="Blocked on a writeback";
+    OSS, desc="Blocked on a writeback, but don't remove from sharers when received";
+  }
+
+  // Events
+  enumeration(Event, desc="Directory events") {
+    GETX, desc="A GETX arrives";
+    GETS, desc="A GETS arrives";
+    PUTX, desc="A PUTX arrives";
+    PUTO, desc="A PUTO arrives";
+    PUTO_SHARERS, desc="A PUTO arrives, but don't remove from sharers list";
+    Unblock, desc="An unblock message arrives";
+    Last_Unblock, desc="An unblock message arrives, we're not waiting for any additional unblocks";
+    Exclusive_Unblock, desc="The processor become the exclusive owner (E or M) of the line";
+    Clean_Writeback, desc="The final message as part of a PutX/PutS, no data";
+    Dirty_Writeback, desc="The final message as part of a PutX/PutS, contains data";
+    Dirty_Writeback_Nack, desc="The main memory was busy and couldnt write the data ";
+
+    Msg_From_Mem_Read, desc="The main memory sub-system returns valid data for this directory";
+    Msg_From_Mem_Other, desc="The main memory sub-system returns valid data for another directory";
+    Msg_From_Mem_Write, desc="The main memory sub-system returns end of transaction for a write";
+    
+	GETX_Persistent, desc="A GETX is replayed";
+    GETS_Persistent, desc="A GETS is replayed ";
+
+  }
+
+  // TYPES
+
+  // DirectoryEntry
+  structure(Entry, desc="...") {
+    State DirectoryState,          desc="Directory state";
+    DataBlock DataBlk,             desc="data for the block";
+    NetDest Sharers,                   desc="Sharers for this block";
+    NetDest Owner,                     desc="Owner of this block";
+    int WaitingUnblocks,           desc="Number of acks we're waiting for";
+  }
+
+  external_type(DirectoryMemory) {
+    Entry lookup(Address);
+    bool isPresent(Address);
+  }
+
+	 MemResponseType send_put_request_to_memory(Address address,CoherenceRequestType type,MachineID Requestor,MachineID dirOwner, DataBlock dBlock);
+	 MemResponseType send_get_request_to_memory(Address address, CoherenceRequestType type, MachineID Requestor, MachineID dirOwner);
+  // ** OBJECTS **
+
+  DirectoryMemory directory, constructor_hack="i";
+
+  State getState(Address addr) {
+    return directory[addr].DirectoryState;
+  }
+  
+  void setState(Address addr, State state) {
+    if (directory.isPresent(addr)) {
+
+      if (state == State:I) {
+        assert(directory[addr].Owner.count() == 0);
+        assert(directory[addr].Sharers.count() == 0);
+      }
+
+      if (state == State:S) {
+        assert(directory[addr].Owner.count() == 0);
+      }
+
+      if (state == State:O) {
+        assert(directory[addr].Owner.count() == 1);
+        assert(directory[addr].Sharers.isSuperset(directory[addr].Owner) == false);
+      }
+
+      if (state == State:M) {
+        assert(directory[addr].Owner.count() == 1);
+        assert(directory[addr].Sharers.count() == 0);
+      }
+
+      if ((state != State:SS) && (state != State:OO)) {
+        assert(directory[addr].WaitingUnblocks == 0);
+      }
+
+      if ( (directory[addr].DirectoryState != State:I) && (state == State:I) ) {
+        directory[addr].DirectoryState := state;
+         // disable coherence checker
+        // sequencer.checkCoherence(addr);
+      } 
+      else {
+        directory[addr].DirectoryState := state;
+      }
+    }
+  }
+
+  // if no sharers, then directory can be considered both a sharer and exclusive w.r.t. coherence checking
+  bool isBlockShared(Address addr) {
+    if (directory.isPresent(addr)) {
+      if (directory[addr].DirectoryState == State:I) {
+        return true;
+      }
+    }
+    return false;
+  }
+
+  bool isBlockExclusive(Address addr) {
+    if (directory.isPresent(addr)) {
+      if (directory[addr].DirectoryState == State:I) {
+        return true;
+      }
+    }
+    return false;
+  }
+  
+
+  // ** OUT_PORTS **
+  out_port(forwardNetwork_out, RequestMsg, forwardFromDir);
+  out_port(responseNetwork_out, ResponseMsg, responseFromDir);
+//  out_port(requestQueue_out, ResponseMsg, requestFromDir); // For recycling requests
+  out_port(goo1_out, ResponseMsg, goo1); 
+  
+  // ** IN_PORTS **
+
+  in_port(foo1_in, ResponseMsg, foo1) {
+  
+  }
+  
+  // in_port(unblockNetwork_in, ResponseMsg, unblockToDir) {
+  //  if (unblockNetwork_in.isReady()) {
+  in_port(unblockNetwork_in, ResponseMsg, responseToDir) {
+    if (unblockNetwork_in.isReady()) {
+      peek(unblockNetwork_in, ResponseMsg) {
+        if (in_msg.Type == CoherenceResponseType:UNBLOCK) {
+          if (directory[in_msg.Address].WaitingUnblocks == 1) {
+            trigger(Event:Last_Unblock, in_msg.Address);
+          } else {
+            trigger(Event:Unblock, in_msg.Address);
+          }
+        } else if (in_msg.Type == CoherenceResponseType:UNBLOCK_EXCLUSIVE) {
+          trigger(Event:Exclusive_Unblock, in_msg.Address);
+        } else if (in_msg.Type == CoherenceResponseType:WRITEBACK_DIRTY_DATA) {
+          //trigger(Event:Dirty_Writeback, in_msg.Address);
+			if (getState(in_msg.Address) == State:MI ||getState(in_msg.Address) == State:MIS || getState(in_msg.Address) == State:OSS || getState(in_msg.Address) == State:OS  ) {
+			if ( send_put_request_to_memory(in_msg.Address, CoherenceRequestType:PUTX, in_msg.Sender, machineID, in_msg.DataBlk) ==  MemResponseType:MEM_RETRY){ 
+			  trigger(Event:Dirty_Writeback_Nack,in_msg.Address);
+			}else {
+			  trigger(Event:Dirty_Writeback,in_msg.Address);
+			}
+		  }else {
+			trigger(Event:Dirty_Writeback,in_msg.Address);
+		  }
+
+        } else if (in_msg.Type == CoherenceResponseType:WRITEBACK_CLEAN_ACK) {
+          trigger(Event:Clean_Writeback, in_msg.Address);
+        } else {
+          error("Invalid message");
+        }
+      }
+    }
+  }
+
+  in_port(requestQueue_in, RequestMsg, requestToDir) {
+    if (requestQueue_in.isReady()) {
+      peek(requestQueue_in, RequestMsg) {
+        if (in_msg.Type == CoherenceRequestType:GETS) {
+          trigger(Event:GETS, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:GETX) {
+          trigger(Event:GETX, in_msg.Address);
+		}else if (in_msg.Type == CoherenceRequestType:GETS_PERSISTENT) {
+          trigger(Event:GETS_Persistent, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:GETX_PERSISTENT) {
+          trigger(Event:GETX_Persistent, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:PUTX) {
+          trigger(Event:PUTX, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:PUTO) {
+          trigger(Event:PUTO, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:PUTO_SHARERS) {
+          trigger(Event:PUTO_SHARERS, in_msg.Address);
+        } else {
+          error("Invalid message");
+        }
+      }
+    }
+  }
+
+  in_port(addressMem_in, MemResponseMsg, addressFromMem) {
+	if (addressMem_in.isReady()) {
+	  DEBUG_EXPR(machineID);
+	  peek(addressMem_in, MemResponseMsg) {
+		if (in_msg.Type == CoherenceRequestType:GETX || in_msg.Type == CoherenceRequestType:GETS || in_msg.Type == CoherenceRequestType:GETX_PERSISTENT|| in_msg.Type == CoherenceRequestType:GETS_PERSISTENT) { /* The only
+ones we care about really */
+		  if (map_Address_to_Directory(in_msg.Address) != machineID) {
+			trigger(Event:Msg_From_Mem_Other, in_msg.Address);
+		  }else {
+			trigger(Event:Msg_From_Mem_Read, in_msg.Address);
+		  }
+		}else {
+			trigger(Event:Msg_From_Mem_Write, in_msg.Address);
+		}
+	  }
+	}
+  }
+
+
+  // Actions
+  
+  action(a_sendWriteBackAck, "a", desc="Send writeback ack to requestor") {
+    peek(requestQueue_in, RequestMsg) {
+      enqueue(forwardNetwork_out, RequestMsg, latency="DIRECTORY_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceRequestType:WB_ACK;
+        out_msg.Requestor := in_msg.Requestor;
+        out_msg.Destination.add(in_msg.Requestor);
+        out_msg.MessageSize := MessageSizeType:Writeback_Control;
+      }
+    }
+  }
+
+   action(aa_sendMemWriteBackAck, "\a", desc="The main memory successfully did a writeback") {
+    peek(unblockNetwork_in, ResponseMsg) {
+      enqueue(forwardNetwork_out, RequestMsg, latency="DIRECTORY_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceRequestType:MEM_ACK;
+        out_msg.Requestor := in_msg.Sender;
+        out_msg.Destination.add(in_msg.Sender);
+        out_msg.MessageSize := MessageSizeType:Writeback_Control;
+      }
+    }
+  }
+
+
+
+  action(b_sendWriteBackNack, "b", desc="Send writeback nack to requestor") {
+    peek(requestQueue_in, RequestMsg) {
+      enqueue(forwardNetwork_out, RequestMsg, latency="DIRECTORY_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceRequestType:WB_NACK;
+        out_msg.Requestor := in_msg.Requestor;
+        out_msg.Destination.add(in_msg.Requestor);
+        out_msg.MessageSize := MessageSizeType:Writeback_Control;
+      }
+    }
+  }
+
+    action(bb_sendMemWriteBackNack, "\b", desc="The main memory could not do a writeback") {
+     peek(unblockNetwork_in, ResponseMsg) {
+      enqueue(forwardNetwork_out, RequestMsg, latency="DIRECTORY_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceRequestType:MEM_NACK;
+        out_msg.Requestor := in_msg.Sender;
+        out_msg.Destination.add(in_msg.Sender);
+        out_msg.MessageSize := MessageSizeType:Writeback_Control;
+      }
+    }
+  }
+
+
+  action(c_clearOwner, "c", desc="Clear the owner field") {
+    directory[address].Owner.clear();
+  }
+
+  action(c_moveOwnerToSharer, "cc", desc="Move owner to sharers") {
+    directory[address].Sharers.addNetDest(directory[address].Owner); 
+    directory[address].Owner.clear();
+  }
+
+  action(cc_clearSharers, "\c", desc="Clear the sharers field") {
+    directory[address].Sharers.clear();
+  }
+
+  action(d_sendData, "d", desc="Send data to requestor") {
+    peek(addressMem_in, MemResponseMsg) {
+      //enqueue(responseNetwork_out, ResponseMsg, latency="MEMORY_LATENCY") {
+      //enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+      enqueue(responseNetwork_out, ResponseMsg, latency="1") {
+        out_msg.Address := address;
+
+        if (in_msg.Type == CoherenceRequestType:GETS && directory[address].Sharers.count() == 0) {
+          out_msg.Type := CoherenceResponseType:DATA_EXCLUSIVE;
+        } else {
+          out_msg.Type := CoherenceResponseType:DATA;
+        }
+
+        out_msg.Sender := machineID;
+        out_msg.SenderMachine := MachineType:Directory;
+        out_msg.Destination.add(in_msg.Requestor);
+        out_msg.DataBlk := directory[in_msg.Address].DataBlk;
+        out_msg.Dirty := false; // By definition, the block is now clean
+        out_msg.Acks := directory[address].Sharers.count();
+        if (directory[address].Sharers.isElement(in_msg.Requestor)) {
+          out_msg.Acks := out_msg.Acks - 1;
+        }
+        out_msg.MessageSize := MessageSizeType:Response_Data;
+      }
+    }
+  }
+
+  action(e_ownerIsUnblocker, "e", desc="The owner is now the unblocker") {
+    peek(unblockNetwork_in, ResponseMsg) {
+      directory[address].Owner.clear();
+      directory[address].Owner.add(in_msg.Sender);
+    }
+  }
+
+  action(f_forwardRequest, "f", desc="Forward request to owner") {
+    peek(requestQueue_in, RequestMsg) {
+      enqueue(forwardNetwork_out, RequestMsg, latency="DIRECTORY_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := in_msg.Type;
+        out_msg.Requestor := in_msg.Requestor;
+        out_msg.Destination.addNetDest(directory[in_msg.Address].Owner);
+        out_msg.Acks := directory[address].Sharers.count();
+        if (directory[address].Sharers.isElement(in_msg.Requestor)) {
+          out_msg.Acks := out_msg.Acks - 1;
+        }
+        out_msg.MessageSize := MessageSizeType:Forwarded_Control;
+      }
+    }
+  }
+
+  action(g_sendInvalidations, "g", desc="Send invalidations to sharers, not including the requester") {
+    peek(requestQueue_in, RequestMsg) {
+      if ((directory[in_msg.Address].Sharers.count() > 1) || 
+          ((directory[in_msg.Address].Sharers.count() > 0) && (directory[in_msg.Address].Sharers.isElement(in_msg.Requestor) == false))) {
+        enqueue(forwardNetwork_out, RequestMsg, latency="DIRECTORY_LATENCY") {
+          out_msg.Address := address;
+          out_msg.Type := CoherenceRequestType:INV;
+          out_msg.Requestor := in_msg.Requestor;
+          // out_msg.Destination := directory[in_msg.Address].Sharers;
+          out_msg.Destination.addNetDest(directory[in_msg.Address].Sharers);
+          out_msg.Destination.remove(in_msg.Requestor);
+          out_msg.MessageSize := MessageSizeType:Invalidate_Control;
+        }
+      }
+    }
+  }
+
+  action(gg_sendReadReqMem, "\g", desc="Send GETX/GETS Request to main memory") {
+	peek(requestQueue_in, RequestMsg) {
+	  DEBUG_EXPR(in_msg.Address);
+	  DEBUG_EXPR(in_msg.Type);
+	  DEBUG_EXPR(in_msg.Requestor);
+	  if ( send_get_request_to_memory(in_msg.Address,in_msg.Type,in_msg.Requestor,machineID) ==  MemResponseType:MEM_RETRY){
+		DEBUG_EXPR(MemResponseType:MEM_RETRY);
+		enqueue(forwardNetwork_out, RequestMsg, latency="DIRECTORY_LATENCY") {
+		  out_msg.Address := address;
+		  out_msg.Type := CoherenceRequestType:MEM_NACK;
+		  out_msg.Requestor := in_msg.Requestor;
+		  out_msg.Destination.add(in_msg.Requestor);
+		  out_msg.MessageSize := MessageSizeType:Control;
+		}
+	  }
+	}
+  }
+
+  action(i_popIncomingRequestQueue, "i", desc="Pop incoming request queue") {
+    requestQueue_in.dequeue();
+  }
+
+  action(j_popIncomingUnblockQueue, "j", desc="Pop incoming unblock queue") {
+    unblockNetwork_in.dequeue();
+  }
+
+   action(jj_popIncomingMemQueue, "/j", desc="Pop incoming main memory Queue") {
+    addressMem_in.dequeue();
+  }
+
+  action(l_writeDataToMemory, "l", desc="Write PUTX/PUTO data to memory") {
+    peek(unblockNetwork_in, ResponseMsg) {
+      assert(in_msg.Dirty);
+      assert(in_msg.MessageSize == MessageSizeType:Writeback_Data);
+      directory[in_msg.Address].DataBlk := in_msg.DataBlk;
+      DEBUG_EXPR(in_msg.Address);
+      DEBUG_EXPR(in_msg.DataBlk);
+    }
+  }
+
+  action(ll_checkDataInMemory, "\l", desc="Check PUTX/PUTO data is same as in the memory") {
+    peek(unblockNetwork_in, ResponseMsg) {
+      assert(in_msg.Dirty == false);
+      assert(in_msg.MessageSize == MessageSizeType:Writeback_Control);
+
+      // NOTE: The following check would not be valid in a real
+      // implementation.  We include the data in the "dataless"
+      // message so we can assert the clean data matches the datablock
+      // in memory
+      assert(directory[in_msg.Address].DataBlk == in_msg.DataBlk);
+    }
+  }
+
+  action(m_addUnlockerToSharers, "m", desc="Add the unlocker to the sharer list") {
+    peek(unblockNetwork_in, ResponseMsg) {
+      directory[address].Sharers.add(in_msg.Sender);      
+    }
+  }
+
+  action(n_incrementOutstanding, "n", desc="Increment outstanding requests") {
+    directory[address].WaitingUnblocks := directory[address].WaitingUnblocks + 1;
+  }
+
+  action(o_decrementOutstanding, "o", desc="Decrement outstanding requests") {
+    directory[address].WaitingUnblocks := directory[address].WaitingUnblocks - 1;
+    assert(directory[address].WaitingUnblocks >= 0);
+  }
+
+  //  action(z_stall, "z", desc="Cannot be handled right now.") {
+    // Special name recognized as do nothing case
+  //  }
+
+  action(zz_recycleRequest, "\z", desc="Recycle the request queue") {
+    requestQueue_in.recycle();
+  }
+
+  // TRANSITIONS
+
+  transition(I, GETX, MM) {
+    //d_sendData;
+	gg_sendReadReqMem;
+    i_popIncomingRequestQueue;
+  }
+
+  transition(S, GETX, MM) {
+    //d_sendData;
+	gg_sendReadReqMem;
+    g_sendInvalidations;
+    i_popIncomingRequestQueue;
+  }
+
+  transition(I, GETS, IS) {
+    //d_sendData;
+	gg_sendReadReqMem;
+    i_popIncomingRequestQueue;
+  }
+
+  transition({S, SS}, GETS, SS) {
+    //d_sendData;
+	gg_sendReadReqMem;
+    n_incrementOutstanding;
+    i_popIncomingRequestQueue;
+  }
+
+  transition({I, S}, PUTO) {
+    b_sendWriteBackNack;
+    i_popIncomingRequestQueue;
+  }
+
+  transition({I, S, O}, PUTX) {
+    b_sendWriteBackNack;
+    i_popIncomingRequestQueue;
+  }
+
+  transition(O, GETX, MM) {
+    f_forwardRequest;
+    g_sendInvalidations;
+    i_popIncomingRequestQueue;
+  }
+
+  transition({O, OO}, GETS, OO) {
+    f_forwardRequest;
+    n_incrementOutstanding;
+    i_popIncomingRequestQueue;
+  }
+
+  transition(M, GETX, MM) {
+    f_forwardRequest;
+    i_popIncomingRequestQueue;
+  }
+
+  transition(M, GETS, MO) {
+    f_forwardRequest;
+    i_popIncomingRequestQueue;
+  }
+
+  transition(M, PUTX, MI) {
+    a_sendWriteBackAck;
+    i_popIncomingRequestQueue;
+  }
+
+  // happens if M->O transition happens on-chip
+  transition(M, PUTO, MI) {
+    a_sendWriteBackAck;
+    i_popIncomingRequestQueue;
+  }
+
+  transition(M, PUTO_SHARERS, MIS) {
+    a_sendWriteBackAck;
+    i_popIncomingRequestQueue;
+  }
+
+  transition(O, PUTO, OS) {
+    a_sendWriteBackAck;
+    i_popIncomingRequestQueue;
+  }
+
+  transition(O, PUTO_SHARERS, OSS) {
+    a_sendWriteBackAck;
+    i_popIncomingRequestQueue;
+  }
+
+
+  transition({MM, MO, MI, MIS, OS, OSS}, {GETS, GETX, PUTO, PUTO_SHARERS, PUTX}) {
+    zz_recycleRequest;
+  }
+
+  transition({MM, MO}, Exclusive_Unblock, M) {
+    cc_clearSharers;
+    e_ownerIsUnblocker;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(MO, Unblock, O) {
+    m_addUnlockerToSharers;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition({IS, SS, OO}, {GETX, PUTO, PUTO_SHARERS, PUTX}) {
+    zz_recycleRequest;
+  }
+
+  transition(IS, GETS) {
+    zz_recycleRequest;
+  }
+
+  transition(IS, Unblock, S) {
+    m_addUnlockerToSharers;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(IS, Exclusive_Unblock, M) {
+    cc_clearSharers;
+    e_ownerIsUnblocker;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(SS, Unblock) {
+    m_addUnlockerToSharers;
+    o_decrementOutstanding;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(SS, Last_Unblock, S) {
+    m_addUnlockerToSharers;
+    o_decrementOutstanding;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(OO, Unblock) {
+    m_addUnlockerToSharers;
+    o_decrementOutstanding;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(OO, Last_Unblock, O) {
+    m_addUnlockerToSharers;
+    o_decrementOutstanding;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(MI, Dirty_Writeback, I) {
+    c_clearOwner;
+    cc_clearSharers;
+    l_writeDataToMemory;
+	aa_sendMemWriteBackAck;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(MIS, Dirty_Writeback, S) {
+    c_moveOwnerToSharer;
+    l_writeDataToMemory;
+	aa_sendMemWriteBackAck;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(MIS, Clean_Writeback, S) {
+    c_moveOwnerToSharer;
+	aa_sendMemWriteBackAck;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(OS, Dirty_Writeback, S) {
+    c_clearOwner;
+    l_writeDataToMemory;
+	aa_sendMemWriteBackAck;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(OSS, Dirty_Writeback, S) {
+    c_moveOwnerToSharer;
+    l_writeDataToMemory;
+	aa_sendMemWriteBackAck;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(OSS, Clean_Writeback, S) {
+    c_moveOwnerToSharer;
+	aa_sendMemWriteBackAck;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(MI, Clean_Writeback, I) {
+    c_clearOwner;
+    cc_clearSharers;
+    ll_checkDataInMemory;
+	aa_sendMemWriteBackAck;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(OS, Clean_Writeback, S) {
+    c_clearOwner;
+    ll_checkDataInMemory;
+	aa_sendMemWriteBackAck;
+    j_popIncomingUnblockQueue;
+  }
+
+  transition({MI, MIS}, Unblock, M) {
+    j_popIncomingUnblockQueue;
+  }
+
+  transition({OS, OSS}, Unblock, O) {
+    j_popIncomingUnblockQueue;
+  }
+
+  transition(MM,{GETX_Persistent}) {
+	gg_sendReadReqMem;
+	i_popIncomingRequestQueue;
+ }
+
+ transition({IS,SS},{GETS_Persistent}) {
+	gg_sendReadReqMem;
+	i_popIncomingRequestQueue;
+ }
+
+  transition({MI,MIS,OS,OSS},{Dirty_Writeback_Nack}) {
+	bb_sendMemWriteBackNack;	
+    j_popIncomingUnblockQueue;
+  }
+
+  transition({MM,IS,SS} , Msg_From_Mem_Read) {
+	d_sendData;
+	jj_popIncomingMemQueue;
+  }
+
+  transition({MM,IS,SS} , {Msg_From_Mem_Other}) {
+	jj_popIncomingMemQueue;
+  }
+  
+  transition({I,M,MI,MO,MM,IS,O,OS,S,SS} , Msg_From_Mem_Write) {
+	jj_popIncomingMemQueue;
+  }
+
+}
diff -rupN /home/grads/poremba/gems_orig/protocols/MOESI_CMP_directory_mainmem-L1cache.sm /home/grads/poremba/gems/protocols/MOESI_CMP_directory_mainmem-L1cache.sm
--- /home/grads/poremba/gems_orig/protocols/MOESI_CMP_directory_mainmem-L1cache.sm	1969-12-31 19:00:00.000000000 -0500
+++ /home/grads/poremba/gems/protocols/MOESI_CMP_directory_mainmem-L1cache.sm	2011-01-27 07:58:35.000000000 -0500
@@ -0,0 +1,1178 @@
+
+/*
+    Copyright (C) 1999-2005 by Mark D. Hill and David A. Wood for the
+    Wisconsin Multifacet Project.  Contact: gems@cs.wisc.edu
+    http://www.cs.wisc.edu/gems/
+
+    --------------------------------------------------------------------
+
+    This file is part of the SLICC (Specification Language for
+    Implementing Cache Coherence), a component of the Multifacet GEMS
+    (General Execution-driven Multiprocessor Simulator) software
+    toolset originally developed at the University of Wisconsin-Madison.
+                                                                                
+    SLICC was originally developed by Milo Martin with substantial
+    contributions from Daniel Sorin.
+
+    Substantial further development of Multifacet GEMS at the
+    University of Wisconsin was performed by Alaa Alameldeen, Brad
+    Beckmann, Ross Dickson, Pacia Harper, Milo Martin, Michael Marty,
+    Carl Mauer, Kevin Moore, Manoj Plakal, Daniel Sorin, Min Xu, and
+    Luke Yen.
+
+    --------------------------------------------------------------------
+
+    If your use of this software contributes to a published paper, we
+    request that you (1) cite our summary paper that appears on our
+    website (http://www.cs.wisc.edu/gems/) and (2) e-mail a citation
+    for your published paper to gems@cs.wisc.edu.
+
+    If you redistribute derivatives of this software, we request that
+    you notify us and either (1) ask people to register with us at our
+    website (http://www.cs.wisc.edu/gems/) or (2) collect registration
+    information and periodically send it to us.
+
+    --------------------------------------------------------------------
+
+    Multifacet GEMS is free software; you can redistribute it and/or
+    modify it under the terms of version 2 of the GNU General Public
+    License as published by the Free Software Foundation.
+
+    Multifacet GEMS is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+    General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with the Multifacet GEMS; if not, write to the Free Software
+    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
+    02111-1307, USA
+
+    The GNU General Public License is contained in the file LICENSE.
+
+### END HEADER ###
+*/
+/*
+ * $Id: MOESI_CMP_directory-L1cache.sm 1.16 05/01/19 15:55:38-06:00 beckmann@s0-28.cs.wisc.edu $
+ *
+ */
+
+machine(L1Cache, "Directory protocol") {
+
+  // NODE L1 CACHE
+  // From this node's L1 cache TO the network
+  // a local L1 -> this L2 bank, currently ordered with directory forwarded requests
+  MessageBuffer requestFromL1Cache, network="To", virtual_network="0", ordered="false";
+  MessageBuffer foo, network="To", virtual_network="1", ordered="false";
+  // a local L1 -> this L2 bank
+  MessageBuffer responseFromL1Cache, network="To", virtual_network="2", ordered="false";
+//  MessageBuffer writebackFromL1Cache, network="To", virtual_network="3", ordered="false";
+  
+  
+  // To this node's L1 cache FROM the network
+  // a L2 bank -> this L1
+  MessageBuffer requestToL1Cache, network="From", virtual_network="0", ordered="false";
+  MessageBuffer goo, network="From", virtual_network="1", ordered="false";
+  // a L2 bank -> this L1
+  MessageBuffer responseToL1Cache, network="From", virtual_network="2", ordered="false";
+  
+
+
+  // STATES
+  enumeration(State, desc="Cache states", default="L1Cache_State_I") {
+    // Base states
+    I, desc="Idle";
+    S, desc="Shared";
+    O, desc="Owned";
+    M, desc="Modified (dirty)";
+    M_W, desc="Modified (dirty)";
+    MM, desc="Modified (dirty and locally modified)";
+    MM_W, desc="Modified (dirty and locally modified)";
+
+    // Transient States
+    IM, "IM", desc="Issued GetX";
+    SM, "SM", desc="Issued GetX, we still have an old copy of the line";
+    OM, "SM", desc="Issued GetX, received data";
+    IS, "IS", desc="Issued GetS";
+    SI, "OI", desc="Issued PutS, waiting for ack";
+    OI, "OI", desc="Issued PutO, waiting for ack";
+    MI, "MI", desc="Issued PutX, waiting for ack";
+    II, "II", desc="Issued PutX/O, saw Fwd_GETS or Fwd_GETX, waiting for ack";
+  }
+
+  // EVENTS
+  enumeration(Event, desc="Cache events") {
+    Load,            desc="Load request from the processor";
+    Ifetch,          desc="I-fetch request from the processor";
+    Store,           desc="Store request from the processor";
+    L1_Replacement,  desc="Replacement";
+
+    // Requests
+    Own_GETX,      desc="We observe our own GetX forwarded back to us";
+    Fwd_GETX,      desc="A GetX from another processor";
+    Fwd_GETS,      desc="A GetS from another processor";
+    Inv,           desc="Invalidations from the directory";
+
+    // Responses
+    Ack,             desc="Received an ack message";
+    Data,            desc="Received a data message, responder has a shared copy";
+    Exclusive_Data,  desc="Received a data message";
+
+    Writeback_Ack,   desc="Writeback O.K. from directory";
+    Writeback_Ack_Data,   desc="Writeback O.K. from directory";
+    Writeback_Nack,  desc="Writeback not O.K. from directory";
+
+    // Triggers
+    All_acks,                  desc="Received all required data and message acks";
+    
+    // Timeouts
+    Use_Timeout, desc="lockout period ended";
+  }
+
+  // TYPES
+
+  // CacheEntry
+  structure(Entry, desc="...", interface="AbstractCacheEntry") {
+    State CacheState,        desc="cache state";
+    bool Dirty,              desc="Is the data dirty (different than memory)?";
+    DataBlock DataBlk,       desc="data for the block";
+  }
+
+  // TBE fields
+  structure(TBE, desc="...") {
+    Address Address,         desc="Physical address for this TBE";
+    State TBEState,          desc="Transient state";
+    DataBlock DataBlk,       desc="data for the block, required for concurrent writebacks";
+    bool Dirty,              desc="Is the data dirty (different than memory)?";
+    int NumPendingMsgs, default="0",     desc="Number of acks/data messages that this processor is waiting for";
+  }
+
+  external_type(CacheMemory) {
+    bool cacheAvail(Address);
+    Address cacheProbe(Address);
+    void allocate(Address);
+    void deallocate(Address);
+    Entry lookup(Address);
+    void changePermission(Address, AccessPermission);
+    bool isTagPresent(Address);
+  }
+
+  external_type(TBETable) {
+    TBE lookup(Address);
+    void allocate(Address);
+    void deallocate(Address);
+    bool isPresent(Address);
+  }
+
+
+  MessageBuffer mandatoryQueue, ordered="false", abstract_chip_ptr="true";
+  Sequencer sequencer, abstract_chip_ptr="true", constructor_hack="i";
+
+  TBETable TBEs, template_hack="<L1Cache_TBE>";
+  CacheMemory L1IcacheMemory, template_hack="<L1Cache_Entry>", constructor_hack='L1_CACHE_NUM_SETS_BITS,L1_CACHE_ASSOC,MachineType_L1Cache,int_to_string(i)+"_L1I"', abstract_chip_ptr="true";
+  CacheMemory L1DcacheMemory, template_hack="<L1Cache_Entry>", constructor_hack='L1_CACHE_NUM_SETS_BITS,L1_CACHE_ASSOC,MachineType_L1Cache,int_to_string(i)+"_L1D"', abstract_chip_ptr="true";
+  TimerTable useTimerTable;
+
+  Entry getCacheEntry(Address addr), return_by_ref="yes" {
+    if (L1DcacheMemory.isTagPresent(addr)) {
+      return L1DcacheMemory[addr];
+    } else {
+      return L1IcacheMemory[addr];
+    }
+  }
+
+  void changePermission(Address addr, AccessPermission permission) {
+    if (L1DcacheMemory.isTagPresent(addr)) {
+      return L1DcacheMemory.changePermission(addr, permission);
+    } else {
+      return L1IcacheMemory.changePermission(addr, permission);
+    }
+  }
+
+  bool isCacheTagPresent(Address addr) {
+    return (L1DcacheMemory.isTagPresent(addr) || L1IcacheMemory.isTagPresent(addr));
+  }
+
+  State getState(Address addr) {
+    assert((L1DcacheMemory.isTagPresent(addr) && L1IcacheMemory.isTagPresent(addr)) == false);
+
+    if(TBEs.isPresent(addr)) { 
+      return TBEs[addr].TBEState;
+    } else if (isCacheTagPresent(addr)) {
+      return getCacheEntry(addr).CacheState;
+    }
+    return State:I;
+  }
+
+  void setState(Address addr, State state) {
+    assert((L1DcacheMemory.isTagPresent(addr) && L1IcacheMemory.isTagPresent(addr)) == false);
+
+    if (TBEs.isPresent(addr)) {
+      TBEs[addr].TBEState := state;
+    }
+
+    if (isCacheTagPresent(addr)) {
+      if ( ((getCacheEntry(addr).CacheState != State:M) && (state == State:M)) ||  
+         ((getCacheEntry(addr).CacheState != State:MM) && (state == State:MM)) ||
+         ((getCacheEntry(addr).CacheState != State:S) && (state == State:S)) ||
+         ((getCacheEntry(addr).CacheState != State:O) && (state == State:O)) ) {  
+
+        getCacheEntry(addr).CacheState := state;
+        sequencer.checkCoherence(addr);
+      }
+      else {
+        getCacheEntry(addr).CacheState := state;
+      }
+
+      // Set permission
+      if (state == State:MM || state == State:MM_W) {
+        changePermission(addr, AccessPermission:Read_Write);
+      } else if ((state == State:S) || 
+                 (state == State:O) || 
+                 (state == State:M) || 
+                 (state == State:M_W) || 
+                 (state == State:SM) || 
+                 (state == State:OM)) {
+        changePermission(addr, AccessPermission:Read_Only);
+      } else {
+        changePermission(addr, AccessPermission:Invalid);
+      }
+    }
+  }
+
+  bool isBlockExclusive(Address addr) {
+
+    if (isCacheTagPresent(addr)) {
+      if ( (getCacheEntry(addr).CacheState == State:M) || (getCacheEntry(addr).CacheState == State:MM) 
+           || (getCacheEntry(addr).CacheState == State:MI) || (getCacheEntry(addr).CacheState == State:MM_W)
+         ) {
+        return true;
+      }
+    }
+
+    return false;
+  }
+
+  bool isBlockShared(Address addr) {
+    if (isCacheTagPresent(addr)) {
+      if ( (getCacheEntry(addr).CacheState == State:S) || (getCacheEntry(addr).CacheState == State:O) 
+           || (getCacheEntry(addr).CacheState == State:SM)
+           || (getCacheEntry(addr).CacheState == State:OI)
+           || (getCacheEntry(addr).CacheState == State:SI)
+           || (getCacheEntry(addr).CacheState == State:OM)
+           ) {
+        return true;
+      }
+    }
+
+    return false;
+  }
+
+
+  Event mandatory_request_type_to_event(CacheRequestType type) {
+    if (type == CacheRequestType:LD) {
+      return Event:Load;
+    } else if (type == CacheRequestType:IFETCH) {
+      return Event:Ifetch;
+    } else if ((type == CacheRequestType:ST) || (type == CacheRequestType:ATOMIC)) {
+      return Event:Store;
+    } else {
+      error("Invalid CacheRequestType");
+    }
+  }
+
+  MessageBuffer triggerQueue, ordered="true";
+
+  // ** OUT_PORTS **
+
+  out_port(requestNetwork_out, RequestMsg, requestFromL1Cache);
+  out_port(responseNetwork_out, ResponseMsg, responseFromL1Cache);
+  out_port(triggerQueue_out, TriggerMsg, triggerQueue);
+  out_port(foo_out, ResponseMsg, foo);
+
+  // ** IN_PORTS **
+
+  // Use Timer 
+  in_port(useTimerTable_in, Address, useTimerTable) {
+    if (useTimerTable_in.isReady()) {
+        trigger(Event:Use_Timeout, useTimerTable.readyAddress());
+    }
+  }
+
+
+  in_port(goo_in, RequestMsg, goo) {
+    if (goo_in.isReady()) {
+      peek(goo_in, RequestMsg) {
+        assert(false);
+      }
+    }
+  }
+
+  // Trigger Queue
+  in_port(triggerQueue_in, TriggerMsg, triggerQueue) {
+    if (triggerQueue_in.isReady()) {
+      peek(triggerQueue_in, TriggerMsg) {
+        if (in_msg.Type == TriggerType:ALL_ACKS) {
+          trigger(Event:All_acks, in_msg.Address);
+        } else {
+          error("Unexpected message");
+        }
+      }
+    }
+  }
+
+  // Nothing from the request network
+
+  // Request Network
+  in_port(requestNetwork_in, RequestMsg, requestToL1Cache) {
+    if (requestNetwork_in.isReady()) {
+      peek(requestNetwork_in, RequestMsg) {
+        assert(in_msg.Destination.isElement(machineID));
+        DEBUG_EXPR("MRM_DEBUG: L1 received");
+        DEBUG_EXPR(in_msg.Type);
+        if (in_msg.Type == CoherenceRequestType:GETX) {
+          if (in_msg.Requestor == machineID && in_msg.RequestorMachine == MachineType:L1Cache) {
+            trigger(Event:Own_GETX, in_msg.Address);
+          } else {
+            trigger(Event:Fwd_GETX, in_msg.Address);
+          }          
+        } else if (in_msg.Type == CoherenceRequestType:GETS) {
+          trigger(Event:Fwd_GETS, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:WB_ACK) {
+          trigger(Event:Writeback_Ack, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:WB_ACK_DATA) {
+          trigger(Event:Writeback_Ack_Data, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:WB_NACK) {
+          trigger(Event:Writeback_Nack, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:INV) {
+          trigger(Event:Inv, in_msg.Address);
+        } else {
+          error("Unexpected message");
+        }
+      }
+    }
+  }
+
+  // Response Network
+  in_port(responseToL1Cache_in, ResponseMsg, responseToL1Cache) {
+    if (responseToL1Cache_in.isReady()) {
+      peek(responseToL1Cache_in, ResponseMsg) {
+        if (in_msg.Type == CoherenceResponseType:ACK) {
+          trigger(Event:Ack, in_msg.Address);
+        } else if (in_msg.Type == CoherenceResponseType:DATA) {
+          trigger(Event:Data, in_msg.Address);
+        } else if (in_msg.Type == CoherenceResponseType:DATA_EXCLUSIVE) {
+          trigger(Event:Exclusive_Data, in_msg.Address);
+        } else {
+          error("Unexpected message");
+        }
+      }
+    }
+  }
+
+  // Nothing from the unblock network
+  // Mandatory Queue betweens Node's CPU and it's L1 caches
+  in_port(mandatoryQueue_in, CacheMsg, mandatoryQueue, desc="...") {
+    if (mandatoryQueue_in.isReady()) {
+      peek(mandatoryQueue_in, CacheMsg) {
+
+        // Check for data access to blocks in I-cache and ifetchs to blocks in D-cache
+
+        if (in_msg.Type == CacheRequestType:IFETCH) {
+          // ** INSTRUCTION ACCESS ***
+
+          // Check to see if it is in the OTHER L1
+          if (L1DcacheMemory.isTagPresent(in_msg.Address)) {
+            // The block is in the wrong L1, put the request on the queue to the shared L2
+            trigger(Event:L1_Replacement, in_msg.Address);
+          }
+          if (L1IcacheMemory.isTagPresent(in_msg.Address)) { 
+            // The tag matches for the L1, so the L1 asks the L2 for it.
+            trigger(mandatory_request_type_to_event(in_msg.Type), in_msg.Address);
+          } else {
+            if (L1IcacheMemory.cacheAvail(in_msg.Address)) {
+              // L1 does't have the line, but we have space for it in the L1 so let's see if the L2 has it
+              trigger(mandatory_request_type_to_event(in_msg.Type), in_msg.Address);
+            } else {
+              // No room in the L1, so we need to make room in the L1
+              trigger(Event:L1_Replacement, L1IcacheMemory.cacheProbe(in_msg.Address));
+            }
+          }
+        } else {
+          // *** DATA ACCESS ***
+
+          // Check to see if it is in the OTHER L1
+          if (L1IcacheMemory.isTagPresent(in_msg.Address)) {
+            // The block is in the wrong L1, put the request on the queue to the shared L2
+            trigger(Event:L1_Replacement, in_msg.Address);
+          }
+          if (L1DcacheMemory.isTagPresent(in_msg.Address)) { 
+            // The tag matches for the L1, so the L1 ask the L2 for it
+            trigger(mandatory_request_type_to_event(in_msg.Type), in_msg.Address);
+          } else {
+            if (L1DcacheMemory.cacheAvail(in_msg.Address)) {
+              // L1 does't have the line, but we have space for it in the L1 let's see if the L2 has it
+              trigger(mandatory_request_type_to_event(in_msg.Type), in_msg.Address);
+            } else { 
+              // No room in the L1, so we need to make room in the L1
+              trigger(Event:L1_Replacement, L1DcacheMemory.cacheProbe(in_msg.Address));
+            }
+          }
+        }
+      }
+    }
+  }
+
+  
+  // ACTIONS
+
+  action(a_issueGETS, "a", desc="Issue GETS") {
+    peek(mandatoryQueue_in, CacheMsg) {
+      enqueue(requestNetwork_out, RequestMsg, latency="L1_REQUEST_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceRequestType:GETS;
+        out_msg.Requestor := machineID;
+        out_msg.Destination.add(map_L1CacheMachId_to_L2Cache(address, machineID));
+        out_msg.MessageSize := MessageSizeType:Request_Control;
+        out_msg.AccessMode := in_msg.AccessMode;
+        out_msg.Prefetch := in_msg.Prefetch;
+      }
+    }
+  }
+
+  action(b_issueGETX, "b", desc="Issue GETX") {
+    peek(mandatoryQueue_in, CacheMsg) {
+      enqueue(requestNetwork_out, RequestMsg, latency="L1_REQUEST_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceRequestType:GETX;
+        out_msg.Requestor := machineID;
+        out_msg.Destination.add(map_L1CacheMachId_to_L2Cache(address, machineID));
+        out_msg.MessageSize := MessageSizeType:Request_Control;
+        out_msg.AccessMode := in_msg.AccessMode;
+        out_msg.Prefetch := in_msg.Prefetch;
+      }
+    }
+  }
+
+  action(d_issuePUTX, "d", desc="Issue PUTX") {
+    // enqueue(writebackNetwork_out, RequestMsg, latency="L1_REQUEST_LATENCY") {
+    enqueue(requestNetwork_out, RequestMsg, latency="L1_REQUEST_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceRequestType:PUTX;
+      out_msg.Requestor := machineID;
+      out_msg.Destination.add(map_L1CacheMachId_to_L2Cache(address, machineID));
+      out_msg.MessageSize := MessageSizeType:Writeback_Control;
+    }
+  }
+
+  action(dd_issuePUTO, "\d", desc="Issue PUTO") {
+    // enqueue(writebackNetwork_out, RequestMsg, latency="L1_REQUEST_LATENCY") {
+    enqueue(requestNetwork_out, RequestMsg, latency="L1_REQUEST_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceRequestType:PUTO;
+      out_msg.Requestor := machineID;
+      out_msg.Destination.add(map_L1CacheMachId_to_L2Cache(address, machineID));
+      out_msg.MessageSize := MessageSizeType:Writeback_Control;
+    }
+  }
+
+  action(dd_issuePUTS, "\ds", desc="Issue PUTS") {
+    // enqueue(writebackNetwork_out, RequestMsg, latency="L1_REQUEST_LATENCY") {
+    enqueue(requestNetwork_out, RequestMsg, latency="L1_REQUEST_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceRequestType:PUTS;
+      out_msg.Requestor := machineID;
+      out_msg.Destination.add(map_L1CacheMachId_to_L2Cache(address, machineID));
+      out_msg.MessageSize := MessageSizeType:Writeback_Control;
+    }
+  }
+
+  action(e_sendData, "e", desc="Send data from cache to requestor") {
+    peek(requestNetwork_in, RequestMsg) {
+      if (in_msg.RequestorMachine == MachineType:L2Cache) {
+        enqueue(responseNetwork_out, ResponseMsg, latency="L1_REQUEST_LATENCY") {
+          out_msg.Address := address;
+          out_msg.Type := CoherenceResponseType:DATA;
+          out_msg.Sender := machineID;
+          out_msg.Destination.add(map_L1CacheMachId_to_L2Cache(in_msg.Address, machineID));
+          out_msg.DataBlk := getCacheEntry(address).DataBlk;
+          // out_msg.Dirty := getCacheEntry(address).Dirty;
+          out_msg.Dirty := false;
+          out_msg.Acks := in_msg.Acks;
+          out_msg.MessageSize := MessageSizeType:Response_Data;
+        }
+        DEBUG_EXPR("Sending data to L2");
+        DEBUG_EXPR(in_msg.Address);
+      }
+      else {
+        enqueue(responseNetwork_out, ResponseMsg, latency="L1_REQUEST_LATENCY") {
+          out_msg.Address := address;
+          out_msg.Type := CoherenceResponseType:DATA;
+          out_msg.Sender := machineID;
+          out_msg.Destination.add(in_msg.Requestor);
+          out_msg.DataBlk := getCacheEntry(address).DataBlk;
+          // out_msg.Dirty := getCacheEntry(address).Dirty;
+          out_msg.Dirty := false;
+          out_msg.Acks := in_msg.Acks;
+          out_msg.MessageSize := MessageSizeType:ResponseLocal_Data;
+        }
+        DEBUG_EXPR("Sending data to L1");
+      }
+    }
+  }
+
+  action(e_sendDataToL2, "ee", desc="Send data from cache to requestor") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L1_REQUEST_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceResponseType:DATA;
+      out_msg.Sender := machineID;
+      out_msg.Destination.add(map_L1CacheMachId_to_L2Cache(address, machineID));
+      out_msg.DataBlk := getCacheEntry(address).DataBlk;
+      out_msg.Dirty := getCacheEntry(address).Dirty;
+      out_msg.Acks := 0; // irrelevant
+      out_msg.MessageSize := MessageSizeType:Response_Data;
+    }
+  }
+
+
+  action(ee_sendDataExclusive, "\e", desc="Send data from cache to requestor, don't keep a shared copy") {
+    peek(requestNetwork_in, RequestMsg) {
+      if (in_msg.RequestorMachine == MachineType:L2Cache) {
+        enqueue(responseNetwork_out, ResponseMsg, latency="L1_REQUEST_LATENCY") {
+          out_msg.Address := address;
+          out_msg.Type := CoherenceResponseType:DATA_EXCLUSIVE;
+          out_msg.Sender := machineID;
+          out_msg.SenderMachine := MachineType:L1Cache;
+          out_msg.Destination.add(map_L1CacheMachId_to_L2Cache(in_msg.Address, machineID));
+          out_msg.DataBlk := getCacheEntry(address).DataBlk;
+          out_msg.Dirty := getCacheEntry(address).Dirty;
+          out_msg.Acks := in_msg.Acks;
+          out_msg.MessageSize := MessageSizeType:Response_Data;
+        }
+        DEBUG_EXPR("Sending exclusive data to L2");
+      }
+      else {
+        enqueue(responseNetwork_out, ResponseMsg, latency="L1_REQUEST_LATENCY") {
+          out_msg.Address := address;
+          out_msg.Type := CoherenceResponseType:DATA_EXCLUSIVE;
+          out_msg.Sender := machineID;
+          out_msg.SenderMachine := MachineType:L1Cache;
+          out_msg.Destination.add(in_msg.Requestor);
+          out_msg.DataBlk := getCacheEntry(address).DataBlk;
+          out_msg.Dirty := getCacheEntry(address).Dirty;
+          out_msg.Acks := in_msg.Acks;
+          out_msg.MessageSize := MessageSizeType:ResponseLocal_Data;
+        }
+        DEBUG_EXPR("Sending exclusive data to L1");
+      }
+    }
+  }
+  
+  action(f_sendAck, "f", desc="Send ack from cache to requestor") {
+    peek(requestNetwork_in, RequestMsg) {
+      if (in_msg.RequestorMachine == MachineType:L1Cache) {
+        enqueue(responseNetwork_out, ResponseMsg, latency="L1_REQUEST_LATENCY") {
+          out_msg.Address := address;
+          out_msg.Type := CoherenceResponseType:ACK;
+          out_msg.Sender := machineID;
+          out_msg.SenderMachine := MachineType:L1Cache;
+          out_msg.Destination.add(in_msg.Requestor);
+          out_msg.Acks := 0 - 1; // -1
+          out_msg.MessageSize := MessageSizeType:Response_Control;
+        }
+      }
+      else {
+        enqueue(responseNetwork_out, ResponseMsg, latency="L1_REQUEST_LATENCY") {
+          out_msg.Address := address;
+          out_msg.Type := CoherenceResponseType:ACK;
+          out_msg.Sender := machineID;
+          out_msg.SenderMachine := MachineType:L1Cache;
+          out_msg.Destination.add(map_L1CacheMachId_to_L2Cache(in_msg.Address, machineID));
+          out_msg.Acks := 0 - 1; // -1
+          out_msg.MessageSize := MessageSizeType:Response_Control;
+        }
+      }
+    }
+  }
+
+  action(g_sendUnblock, "g", desc="Send unblock to memory") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L1_REQUEST_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceResponseType:UNBLOCK;
+      out_msg.Sender := machineID;
+      out_msg.Destination.add(map_L1CacheMachId_to_L2Cache(address, machineID));
+      out_msg.MessageSize := MessageSizeType:Unblock_Control;
+    }
+  }
+
+  action(gg_sendUnblockExclusive, "\g", desc="Send unblock exclusive to memory") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L1_REQUEST_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceResponseType:UNBLOCK_EXCLUSIVE;
+      out_msg.Sender := machineID;
+      out_msg.Destination.add(map_L1CacheMachId_to_L2Cache(address, machineID));
+      out_msg.MessageSize := MessageSizeType:Unblock_Control;
+    }
+  }
+
+  action(h_load_hit, "h", desc="Notify sequencer the load completed.") {
+    DEBUG_EXPR(getCacheEntry(address).DataBlk);
+    sequencer.readCallback(address, getCacheEntry(address).DataBlk);
+  }
+
+  action(hh_store_hit, "\h", desc="Notify sequencer that store completed.") {
+    DEBUG_EXPR(getCacheEntry(address).DataBlk);
+    sequencer.writeCallback(address, getCacheEntry(address).DataBlk);
+    getCacheEntry(address).Dirty := true;
+  }
+
+  action(i_allocateTBE, "i", desc="Allocate TBE") {
+    check_allocate(TBEs);
+    TBEs.allocate(address);
+    TBEs[address].DataBlk := getCacheEntry(address).DataBlk; // Data only used for writebacks
+    TBEs[address].Dirty := getCacheEntry(address).Dirty;
+  }
+
+  action(j_popTriggerQueue, "j", desc="Pop trigger queue.") {
+    triggerQueue_in.dequeue();
+  }
+
+  action(jj_unsetUseTimer, "\jj", desc="Unset use timer.") {
+    useTimerTable.unset(address);
+  }
+
+  action(k_popMandatoryQueue, "k", desc="Pop mandatory queue.") {
+    mandatoryQueue_in.dequeue();
+  }
+  
+  action(l_popForwardQueue, "l", desc="Pop forwareded request queue.") {
+    requestNetwork_in.dequeue();
+  }
+
+  action(m_decrementNumberOfMessages, "m", desc="Decrement the number of messages for which we're waiting") {
+    peek(responseToL1Cache_in, ResponseMsg) {
+      DEBUG_EXPR("MRM_DEBUG: L1 decrementNumberOfMessages");
+      DEBUG_EXPR(id);
+      DEBUG_EXPR(in_msg.Acks);
+      TBEs[address].NumPendingMsgs := TBEs[address].NumPendingMsgs - in_msg.Acks;
+    }
+  }
+
+  action(mm_decrementNumberOfMessages, "\m", desc="Decrement the number of messages for which we're waiting") {
+    peek(requestNetwork_in, RequestMsg) {
+      TBEs[address].NumPendingMsgs := TBEs[address].NumPendingMsgs - in_msg.Acks;
+    }
+  }
+
+  action(n_popResponseQueue, "n", desc="Pop response queue") {
+    responseToL1Cache_in.dequeue();
+  }
+
+  action(o_checkForCompletion, "o", desc="Check if we have received all the messages required for completion") {
+    if (TBEs[address].NumPendingMsgs == 0) {
+      enqueue(triggerQueue_out, TriggerMsg) {
+        out_msg.Address := address;
+        out_msg.Type := TriggerType:ALL_ACKS;
+      }
+    }
+  }
+
+  action(o_scheduleUseTimeout, "oo", desc="Schedule a use timeout.") {
+    useTimerTable.set(address, 50);
+  }
+
+
+  action(q_sendDataFromTBEToCache, "q", desc="Send data from TBE to cache") {
+    peek(requestNetwork_in, RequestMsg) {
+      if (in_msg.RequestorMachine == MachineType:L1Cache) {
+        enqueue(responseNetwork_out, ResponseMsg, latency="L1_REQUEST_LATENCY") {
+          out_msg.Address := address;
+          out_msg.Type := CoherenceResponseType:DATA;
+          out_msg.Sender := machineID;
+          out_msg.Destination.add(in_msg.Requestor);
+          out_msg.DataBlk := TBEs[address].DataBlk;
+          // out_msg.Dirty := TBEs[address].Dirty;
+          out_msg.Dirty := false;
+          out_msg.Acks := in_msg.Acks;
+          out_msg.MessageSize := MessageSizeType:ResponseLocal_Data;
+        }
+      }
+      else {
+        enqueue(responseNetwork_out, ResponseMsg, latency="L1_REQUEST_LATENCY") {
+          out_msg.Address := address;
+          out_msg.Type := CoherenceResponseType:DATA;
+          out_msg.Sender := machineID;
+          out_msg.Destination.add(map_L1CacheMachId_to_L2Cache(address,machineID));
+          out_msg.DataBlk := TBEs[address].DataBlk;
+          // out_msg.Dirty := TBEs[address].Dirty;
+          out_msg.Dirty := false;
+          out_msg.Acks := in_msg.Acks;
+          out_msg.MessageSize := MessageSizeType:Response_Data;
+        }
+      }
+    }
+  }
+
+  action(q_sendExclusiveDataFromTBEToCache, "qq", desc="Send data from TBE to cache") {
+    peek(requestNetwork_in, RequestMsg) {
+      if (in_msg.RequestorMachine == MachineType:L1Cache) {
+        enqueue(responseNetwork_out, ResponseMsg, latency="L1_REQUEST_LATENCY") {
+          out_msg.Address := address;
+          out_msg.Type := CoherenceResponseType:DATA_EXCLUSIVE;
+          out_msg.Sender := machineID;
+          out_msg.Destination.add(in_msg.Requestor);
+          out_msg.DataBlk := TBEs[address].DataBlk;
+          out_msg.Dirty := TBEs[address].Dirty;
+          out_msg.Acks := in_msg.Acks;
+          out_msg.MessageSize := MessageSizeType:ResponseLocal_Data;
+        }
+      }
+      else {
+        enqueue(responseNetwork_out, ResponseMsg, latency="L1_REQUEST_LATENCY") {
+          out_msg.Address := address;
+          out_msg.Type := CoherenceResponseType:DATA_EXCLUSIVE;
+          out_msg.Sender := machineID;
+          out_msg.Destination.add(map_L1CacheMachId_to_L2Cache(address,machineID));
+          out_msg.DataBlk := TBEs[address].DataBlk;
+          out_msg.Dirty := TBEs[address].Dirty;
+          out_msg.Acks := in_msg.Acks;
+          out_msg.MessageSize := MessageSizeType:Response_Data;
+        }
+      }
+    }
+  }
+
+
+  // L2 will usually request data for a writeback
+  action(qq_sendWBDataFromTBEToL2, "\q", desc="Send data from TBE to L2") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L1_REQUEST_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Sender := machineID;
+      out_msg.SenderMachine := MachineType:L1Cache;
+      out_msg.Destination.add(map_L1CacheMachId_to_L2Cache(address, machineID));
+      out_msg.Dirty := TBEs[address].Dirty;
+      if (TBEs[address].Dirty) {
+        out_msg.Type := CoherenceResponseType:WRITEBACK_DIRTY_DATA;
+      } else {
+        out_msg.Type := CoherenceResponseType:WRITEBACK_CLEAN_DATA;
+      }
+      out_msg.DataBlk := TBEs[address].DataBlk;
+      out_msg.MessageSize := MessageSizeType:Writeback_Data;
+    }
+  }
+
+  action(s_deallocateTBE, "s", desc="Deallocate TBE") {
+    TBEs.deallocate(address);
+  }
+
+  action(u_writeDataToCache, "u", desc="Write data to cache") {
+    peek(responseToL1Cache_in, ResponseMsg) {
+      getCacheEntry(address).DataBlk := in_msg.DataBlk;
+      getCacheEntry(address).Dirty := in_msg.Dirty;
+
+      if (in_msg.Type == CoherenceResponseType:DATA) {
+        //assert(in_msg.Dirty == false);
+      }
+    }
+
+  }
+
+  action(v_writeDataToCacheVerify, "v", desc="Write data to cache, assert it was same as before") {
+    peek(responseToL1Cache_in, ResponseMsg) {
+      assert(getCacheEntry(address).DataBlk == in_msg.DataBlk);
+      getCacheEntry(address).DataBlk := in_msg.DataBlk;
+      getCacheEntry(address).Dirty := in_msg.Dirty;
+    }
+  }
+  
+  action(kk_deallocateL1CacheBlock, "\k", desc="Deallocate cache block.  Sets the cache to invalid, allowing a replacement in parallel with a fetch.") {
+    if (L1DcacheMemory.isTagPresent(address)) {
+      L1DcacheMemory.deallocate(address);
+    } else {
+      L1IcacheMemory.deallocate(address);
+    }
+  }
+  
+  action(ii_allocateL1DCacheBlock, "\i", desc="Set L1 D-cache tag equal to tag of block B.") {
+    if (L1DcacheMemory.isTagPresent(address) == false) {
+      L1DcacheMemory.allocate(address);
+    }
+  }
+
+  action(jj_allocateL1ICacheBlock, "\j", desc="Set L1 I-cache tag equal to tag of block B.") {
+    if (L1IcacheMemory.isTagPresent(address) == false) {
+      L1IcacheMemory.allocate(address);
+    }
+  }
+
+
+
+  action(uu_profileMiss, "\u", desc="Profile the demand miss") {
+    peek(mandatoryQueue_in, CacheMsg) {
+      profile_miss(in_msg, id);
+    }
+  }
+
+  action(z_recycleRequestQueue, "z", desc="Send the head of the mandatory queue to the back of the queue.") {
+    requestNetwork_in.recycle();
+  }
+
+  action(zz_recycleMandatoryQueue, "\z", desc="Send the head of the mandatory queue to the back of the queue.") {
+    mandatoryQueue_in.recycle();
+  }
+
+  //*****************************************************
+  // TRANSITIONS
+  //*****************************************************
+
+  // Transitions for Load/Store/L2_Replacement from transient states
+  transition({IM, SM, OM, IS, OI, SI, MI, II}, {Store, L1_Replacement}) {
+    zz_recycleMandatoryQueue;
+  }
+
+  transition({M_W, MM_W}, L1_Replacement) {
+    zz_recycleMandatoryQueue;
+  }
+
+  transition({M_W, MM_W}, {Fwd_GETS, Fwd_GETX, Own_GETX, Inv}) {
+    z_recycleRequestQueue;
+  }
+
+  transition({IM, IS, OI, MI, SI, II}, {Load, Ifetch}) {
+    zz_recycleMandatoryQueue;
+  }
+
+  // Transitions from Idle
+  transition(I, Load, IS) {
+    ii_allocateL1DCacheBlock;
+    i_allocateTBE;
+    a_issueGETS;
+    // uu_profileMiss;
+    k_popMandatoryQueue;
+  }
+
+  transition(I, Ifetch, IS) {
+    jj_allocateL1ICacheBlock;
+    i_allocateTBE;
+    a_issueGETS;
+    // uu_profileMiss;
+    k_popMandatoryQueue;
+  }
+
+  transition(I, Store, IM) {
+    ii_allocateL1DCacheBlock;
+    i_allocateTBE;
+    b_issueGETX;
+    // uu_profileMiss;
+    k_popMandatoryQueue;
+  }
+
+  transition(I, L1_Replacement) {
+    kk_deallocateL1CacheBlock;
+  }
+
+  transition(I, Inv) {
+    f_sendAck;
+    l_popForwardQueue;
+  }
+
+  // Transitions from Shared
+  transition({S, SM}, {Load, Ifetch}) {
+    h_load_hit;
+    k_popMandatoryQueue;
+  }
+
+  transition(S, Store, SM) {
+    i_allocateTBE;
+    b_issueGETX;
+    // uu_profileMiss;
+    k_popMandatoryQueue;
+  }
+
+  transition(S, L1_Replacement, SI) {
+    i_allocateTBE;
+    dd_issuePUTS;
+    kk_deallocateL1CacheBlock;
+  }
+
+  transition(S, Inv, I) {
+    f_sendAck;
+    l_popForwardQueue;
+  }
+
+  transition(S, Fwd_GETS) {
+    e_sendData;
+    l_popForwardQueue;
+  }
+
+  // Transitions from Owned
+  transition({O, OM}, {Load, Ifetch}) {
+    h_load_hit;
+    k_popMandatoryQueue;
+  }
+
+  transition(O, Store, OM) {
+    i_allocateTBE;
+    b_issueGETX;
+    // uu_profileMiss;
+    k_popMandatoryQueue;
+  }
+
+  transition(O, L1_Replacement, OI) {
+    i_allocateTBE;
+    dd_issuePUTO;
+    kk_deallocateL1CacheBlock;
+  }
+
+  transition(O, Fwd_GETX, I) {
+    ee_sendDataExclusive;
+    l_popForwardQueue;
+  }
+
+  transition(O, Fwd_GETS) {
+    e_sendData;
+    l_popForwardQueue;
+  }
+
+  // Transitions from MM
+  transition({MM, MM_W}, {Load, Ifetch}) {
+    h_load_hit;
+    k_popMandatoryQueue;
+  }
+
+  transition({MM, MM_W}, Store) {
+    hh_store_hit;
+    k_popMandatoryQueue;
+  }
+
+  transition(MM, L1_Replacement, MI) {
+    i_allocateTBE;
+    d_issuePUTX;
+    kk_deallocateL1CacheBlock;
+  }
+
+  transition(MM, Fwd_GETX, I) {
+    ee_sendDataExclusive;
+    l_popForwardQueue;
+  }
+
+  transition(MM, Fwd_GETS, I) {
+    ee_sendDataExclusive;
+    l_popForwardQueue;
+  }
+  
+  // Transitions from M
+  transition({M, M_W}, {Load, Ifetch}) {
+    h_load_hit;
+    k_popMandatoryQueue;
+  }
+
+  transition(M, Store, MM) {
+    hh_store_hit;
+    k_popMandatoryQueue;
+  }
+
+  transition(M_W, Store, MM_W) {
+    hh_store_hit;
+    k_popMandatoryQueue;
+  }
+
+  transition(M, L1_Replacement, MI) {
+    i_allocateTBE;
+    d_issuePUTX;
+    kk_deallocateL1CacheBlock;
+  }
+
+  transition(M, Fwd_GETX, I) {
+    // e_sendData;
+    ee_sendDataExclusive;
+    l_popForwardQueue;
+  }
+
+  transition(M, Fwd_GETS, O) {
+    e_sendData;
+    l_popForwardQueue;
+  }
+
+  // Transitions from IM
+
+  transition(IM, Inv) {
+    f_sendAck;
+    l_popForwardQueue;
+  }
+
+  transition(IM, Ack) {
+    m_decrementNumberOfMessages;
+    o_checkForCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(IM, {Exclusive_Data, Data}, OM) {
+    u_writeDataToCache;
+    m_decrementNumberOfMessages; 
+    o_checkForCompletion;
+    n_popResponseQueue;
+  }
+
+  // Transitions from SM
+  transition(SM, Inv, IM) {
+    f_sendAck;
+    l_popForwardQueue;
+  }
+
+  transition(SM, Ack) {
+    m_decrementNumberOfMessages;
+    o_checkForCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(SM, {Data, Exclusive_Data}, OM) {
+    // v_writeDataToCacheVerify;
+    m_decrementNumberOfMessages; 
+    o_checkForCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(SM, Fwd_GETS) {
+    e_sendData;
+    l_popForwardQueue;
+  }
+
+  // Transitions from OM
+  transition(OM, Own_GETX) {
+    mm_decrementNumberOfMessages;
+    o_checkForCompletion;
+    l_popForwardQueue;
+  }
+
+
+  // transition(OM, Fwd_GETX, OMF) {
+  transition(OM, Fwd_GETX, IM) {
+    ee_sendDataExclusive;
+    l_popForwardQueue;
+  }
+
+  transition(OM, Fwd_GETS, OM) {
+    e_sendData;
+    l_popForwardQueue;
+  }
+
+  //transition({OM, OMF}, Ack) {
+  transition(OM, Ack) {
+    m_decrementNumberOfMessages;
+    o_checkForCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(OM, All_acks, MM_W) {
+    hh_store_hit;
+    gg_sendUnblockExclusive;
+    s_deallocateTBE;
+    o_scheduleUseTimeout;
+    j_popTriggerQueue;
+  }
+
+  transition(MM_W, Use_Timeout, MM) {
+    jj_unsetUseTimer;
+  }
+
+  // Transitions from IS
+
+  transition(IS, Inv) {
+    f_sendAck;
+    l_popForwardQueue;
+  }
+
+  transition(IS, Data, S) {
+    u_writeDataToCache;
+    m_decrementNumberOfMessages;
+    h_load_hit;
+    g_sendUnblock;
+    s_deallocateTBE;
+    n_popResponseQueue;
+  }
+
+  transition(IS, Exclusive_Data, M_W) {
+    u_writeDataToCache;
+    m_decrementNumberOfMessages;
+    h_load_hit;
+    gg_sendUnblockExclusive;
+    o_scheduleUseTimeout;
+    s_deallocateTBE;
+    n_popResponseQueue;
+  }
+
+  transition(M_W, Use_Timeout, M) {
+    jj_unsetUseTimer;
+  }
+
+  // Transitions from OI/MI
+
+  transition(MI, Fwd_GETS, OI) {
+    q_sendDataFromTBEToCache;
+    l_popForwardQueue;
+  }
+
+  transition(MI, Fwd_GETX, II) {
+    q_sendExclusiveDataFromTBEToCache;
+    l_popForwardQueue;
+  }
+
+  transition({SI, OI}, Fwd_GETS) {
+    q_sendDataFromTBEToCache;
+    l_popForwardQueue;
+  }
+
+  transition(OI, Fwd_GETX, II) {
+    q_sendExclusiveDataFromTBEToCache;
+    l_popForwardQueue;
+  }
+
+  transition({SI, OI, MI}, Writeback_Ack_Data, I) {
+    qq_sendWBDataFromTBEToL2;  // always send data
+    s_deallocateTBE;
+    l_popForwardQueue;
+  }
+
+  transition({SI, OI, MI}, Writeback_Ack, I) {
+    g_sendUnblock;
+    s_deallocateTBE;
+    l_popForwardQueue;
+  }
+
+  transition({MI, OI}, Writeback_Nack, OI) {  
+    // FIXME: This might cause deadlock by re-using the writeback
+    // channel, we should handle this case differently.
+    dd_issuePUTO;
+    l_popForwardQueue;
+  }
+
+  // Transitions from II
+  transition(II, {Writeback_Ack, Writeback_Ack_Data}, I) {
+    g_sendUnblock;
+    s_deallocateTBE;
+    l_popForwardQueue;
+  }
+
+  // transition({II, SI}, Writeback_Nack, I) {
+  transition(II, Writeback_Nack, I) {
+    s_deallocateTBE;
+    l_popForwardQueue;
+  }
+
+  transition(SI, Writeback_Nack) {
+    dd_issuePUTS;
+    l_popForwardQueue;
+  }
+
+  transition(II, Inv) {
+    f_sendAck;
+    l_popForwardQueue;
+  }
+
+  transition(SI, Inv, II) {
+    f_sendAck;
+    l_popForwardQueue;
+  }
+}
+
diff -rupN /home/grads/poremba/gems_orig/protocols/MOESI_CMP_directory_mainmem-L2cache.sm /home/grads/poremba/gems/protocols/MOESI_CMP_directory_mainmem-L2cache.sm
--- /home/grads/poremba/gems_orig/protocols/MOESI_CMP_directory_mainmem-L2cache.sm	1969-12-31 19:00:00.000000000 -0500
+++ /home/grads/poremba/gems/protocols/MOESI_CMP_directory_mainmem-L2cache.sm	2011-01-27 07:58:43.000000000 -0500
@@ -0,0 +1,2718 @@
+
+/*
+    Copyright (C) 1999-2005 by Mark D. Hill and David A. Wood for the
+    Wisconsin Multifacet Project.  Contact: gems@cs.wisc.edu
+    http://www.cs.wisc.edu/gems/
+
+    --------------------------------------------------------------------
+
+    This file is part of the SLICC (Specification Language for
+    Implementing Cache Coherence), a component of the Multifacet GEMS
+    (General Execution-driven Multiprocessor Simulator) software
+    toolset originally developed at the University of Wisconsin-Madison.
+                                                                                
+    SLICC was originally developed by Milo Martin with substantial
+    contributions from Daniel Sorin.
+
+    Substantial further development of Multifacet GEMS at the
+    University of Wisconsin was performed by Alaa Alameldeen, Brad
+    Beckmann, Ross Dickson, Pacia Harper, Milo Martin, Michael Marty,
+    Carl Mauer, Kevin Moore, Manoj Plakal, Daniel Sorin, Min Xu, and
+    Luke Yen.
+
+    --------------------------------------------------------------------
+
+    If your use of this software contributes to a published paper, we
+    request that you (1) cite our summary paper that appears on our
+    website (http://www.cs.wisc.edu/gems/) and (2) e-mail a citation
+    for your published paper to gems@cs.wisc.edu.
+
+    If you redistribute derivatives of this software, we request that
+    you notify us and either (1) ask people to register with us at our
+    website (http://www.cs.wisc.edu/gems/) or (2) collect registration
+    information and periodically send it to us.
+
+    --------------------------------------------------------------------
+
+    Multifacet GEMS is free software; you can redistribute it and/or
+    modify it under the terms of version 2 of the GNU General Public
+    License as published by the Free Software Foundation.
+
+    Multifacet GEMS is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+    General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with the Multifacet GEMS; if not, write to the Free Software
+    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
+    02111-1307, USA
+
+    The GNU General Public License is contained in the file LICENSE.
+
+### END HEADER ###
+*/
+/*
+ * $Id: MOESI_CMP_directory-L2cache.sm 1.22 05/01/19 15:55:39-06:00 beckmann@s0-28.cs.wisc.edu $
+ *
+ */
+
+machine(L2Cache, "Token protocol") {
+
+  // L2 BANK QUEUES
+  // From local bank of L2 cache TO the network
+  MessageBuffer L1RequestFromL2Cache, network="To", virtual_network="0", ordered="false";  // this L2 bank -> a local L1
+  MessageBuffer GlobalRequestFromL2Cache, network="To", virtual_network="1", ordered="false";  // this L2 bank -> mod-directory
+  MessageBuffer responseFromL2Cache, network="To", virtual_network="2", ordered="false";  // this L2 bank -> a local L1 || mod-directory
+
+  // FROM the network to this local bank of L2 cache
+  MessageBuffer L1RequestToL2Cache, network="From", virtual_network="0", ordered="false";  // a local L1 -> this L2 bank, Lets try this???
+  MessageBuffer GlobalRequestToL2Cache, network="From", virtual_network="1", ordered="false";  // mod-directory -> this L2 bank
+  MessageBuffer responseToL2Cache, network="From", virtual_network="2", ordered="false";  // a local L1 || mod-directory -> this L2 bank
+//  MessageBuffer L1WritebackToL2Cache, network="From", virtual_network="3", ordered="false";
+
+  // STATES
+  enumeration(State, desc="L2 Cache states", default="L2Cache_State_I") {
+
+    // Stable states
+    NP, desc="Not Present";
+    I, desc="Invalid";
+    ILS, desc="Idle/NP, but local sharers exist";
+    ILX, desc="Idle/NP, but local exclusive exists";
+    ILO, desc="Idle/NP, but local owner exists";
+    ILOX, desc="Idle/NP, but local owner exists and chip is exclusive";
+    ILOS, desc="Idle/NP, but local owner exists and local sharers as well";
+    ILOSX, desc="Idle/NP, but local owner exists, local sharers exist, chip is exclusive ";
+    S, desc="Shared, no local sharers";
+    O, desc="Owned, no local sharers";
+    OLS, desc="Owned with local sharers";
+    OLSX, desc="Owned with local sharers, chip is exclusive";
+    SLS, desc="Shared with local sharers";
+    M, desc="Modified";
+
+    // Transient States
+
+    IFGX, desc="Blocked, forwarded global GETX to local owner/exclusive.  No other on-chip invs needed";
+    IFGS, desc="Blocked, forwarded global GETS to local owner";
+    ISFGS, desc="Blocked, forwarded global GETS to local owner, local sharers exist";
+    // UNUSED
+    IFGXX, desc="Blocked, forwarded global GETX to local owner but may need acks from other sharers";
+    OFGX, desc="Blocked, forwarded global GETX to owner and got data but may need acks";
+
+    OLSF, desc="Blocked, got Fwd_GETX with local sharers, waiting for local inv acks";
+
+    // writebacks
+    ILOW, desc="local WB request, was ILO";
+    ILOXW, desc="local WB request, was ILOX";
+    ILOSW, desc="local WB request, was ILOS";
+    ILOSXW, desc="local WB request, was ILOSX";
+    SLSW, desc="local WB request, was SLS";
+    OLSW, desc="local WB request, was OLS";
+    ILSW, desc="local WB request, was ILS";
+    IW, desc="local WB request from only sharer, was ILS";
+    OW, desc="local WB request from only sharer, was OLS";
+    SW, desc="local WB request from only sharer, was SLS";
+    OXW, desc="local WB request from only sharer, was OLSX";
+    OLSXW, desc="local WB request from sharer, was OLSX";
+    ILXW, desc="local WB request, was ILX";
+
+    IFLS, desc="Blocked, forwarded local GETS to _some_ local sharer";
+    IFLO, desc="Blocked, forwarded local GETS to local owner";
+    IFLOX, desc="Blocked, forwarded local GETS to local owner but chip is exclusive";
+    IFLOXX, desc="Blocked, forwarded local GETX to local owner/exclusive, chip is exclusive";
+    IFLOSX, desc="Blocked, forwarded local GETS to local owner w/ other sharers, chip is exclusive";
+    IFLXO, desc="Blocked, forwarded local GETX to local owner with other sharers, chip is exclusive";
+
+    IGS, desc="Semi-blocked, issued local GETS to directory";
+    IGM, desc="Blocked, issued local GETX to directory. Need global acks and data";
+    IGMLS, desc="Blocked, issued local GETX to directory but may need to INV local sharers";
+    IGMO, desc="Blocked, have data for local GETX but need all acks";
+    IGMIO, desc="Blocked, issued local GETX, local owner with possible local sharer, may need to INV";
+    OGMIO, desc="Blocked, issued local GETX, was owner, may need to INV";
+    IGMIOF, desc="Blocked, issued local GETX, local owner, waiting for global acks, got Fwd_GETX";
+    IGMIOFS, desc="Blocked, issued local GETX, local owner, waiting for global acks, got Fwd_GETS";
+    OGMIOF, desc="Blocked, issued local GETX, was owner, waiting for global acks, got Fwd_GETX";
+
+    II, desc="Blocked, handling invalidations";
+    MM, desc="Blocked, was M satisfying local GETX";
+    SS, desc="Blocked, was S satisfying local GETS";
+    OO, desc="Blocked, was O satisfying local GETS";
+    OLSS, desc="Blocked, satisfying local GETS";
+    OLSXS, desc="Blocked, satisfying local GETS";
+    SLSS, desc="Blocked, satisfying local GETS";
+
+    OI, desc="Blocked, doing writeback, was O";
+    MI, desc="Blocked, doing writeback, was M";
+    MII, desc="Blocked, doing writeback, was M, got Fwd_GETX";
+    OLSI, desc="Blocked, doing writeback, was OLS";
+    ILSI, desc="Blocked, doing writeback, was OLS got Fwd_GETX";
+  }
+
+  // EVENTS
+  enumeration(Event, desc="Cache events") {
+
+    // Requests
+    L1_GETS,             desc="local L1 GETS request";
+    L1_GETX,             desc="local L1 GETX request";
+    L1_PUTO,             desc="local owner wants to writeback";
+    L1_PUTX,             desc="local exclusive wants to writeback";
+    L1_PUTS_only,             desc="only local sharer wants to writeback";
+    L1_PUTS,             desc="local sharer wants to writeback";
+    Fwd_GETX,      desc="A GetX from another processor";
+    Fwd_GETS,      desc="A GetS from another processor";
+    Own_GETX,      desc="A GetX from this node";
+    Inv,           desc="Invalidations from the directory";
+
+    // Responses
+    IntAck,             desc="Received an ack message";
+    ExtAck,             desc="Received an ack message";
+    All_Acks,         desc="Received all ack messages";
+    Data,            desc="Received a data message, responder has a shared copy";
+    Data_Exclusive,  desc="Received a data message";
+    L1_WBCLEANDATA,       desc="Writeback from L1, with data";
+    L1_WBDIRTYDATA,       desc="Writeback from L1, with data";
+
+    Writeback_Ack,   desc="Writeback O.K. from directory";
+    Writeback_Nack,  desc="Writeback not O.K. from directory";
+
+    Mem_Nack,  	desc="Mem Nack -> Read/Write failed to main memory";
+    Other_Mem_Nack,  	desc="Mem Nack -> Read/Write failed to main memory";
+    Mem_Ack,  	desc="Mem Ack -> Write completed to main memory";
+    Other_Mem_Ack,  	desc="Mem Nack -> Read/Write failed to main memory";
+
+    Unblock,         desc="Local L1 is telling L2 dir to unblock";
+    Exclusive_Unblock,         desc="Local L1 is telling L2 dir to unblock";
+
+
+    // events initiated by this L2
+    L2_Replacement,     desc="L2 Replacement", format="!r";
+
+	 // Timeout Table
+	Reissue_Timeout,	desc="Table that maintains lists of requests that need to be retryed";
+
+  }
+
+  // TYPES
+
+  // CacheEntry
+  structure(Entry, desc="...", interface="AbstractCacheEntry") {
+    State CacheState,        desc="cache state";
+    NetDest Sharers,            desc="Set of the internal processors that want the block in shared state";
+    MachineID Owner,    desc="ID of the L1 cache to forward the block to once we get a response";
+    bool OwnerValid, default="false", desc="true if Owner means something";
+    bool Dirty,              desc="Is the data dirty (different than memory)?";
+    DataBlock DataBlk,       desc="data for the block";
+  }
+
+
+  structure(DirEntry, desc="...") {
+    NetDest Sharers,            desc="Set of the internal processors that want the block in shared state";
+    MachineID Owner,   desc="ID of the L1 cache to forward the block to once we get a response";
+    bool OwnerValid, default="false", desc="true if Owner means something";
+    State DirState,        desc="directory state";
+  }
+
+  // TBE fields
+  structure(TBE, desc="...") {
+    Address Address,                      desc="Physical address for this TBE";
+    State TBEState,                       desc="Transient state";
+    Address PC,                           desc="Program counter of request";
+    DataBlock DataBlk,                    desc="Buffer for the data block";
+    bool Dirty,              desc="Is the data dirty (different than memory)?";
+
+    int NumExtPendingAcks, default="0",      desc="Number of global acks/data messages waiting for";
+    int NumIntPendingAcks, default="0",      desc="Number of global acks/data messages waiting for";
+    int Fwd_GETX_ExtAcks, default="0",                 desc="Number of acks that requestor will need";   
+    int Local_GETX_IntAcks, default="0",                 desc="Number of acks that requestor will need";   
+
+    NetDest L1_GetS_IDs,            desc="Set of the internal processors that want the block in shared state";
+    MachineID L1_GetX_ID,          desc="ID of the L1 cache to forward the block to once we get a response";
+    NetDest Fwd_GetS_IDs,            desc="Set of the internal processors that want the block in shared state";
+    MachineID Fwd_GetX_ID,          desc="ID of the L1 cache to forward the block to once we get a response";
+  }
+
+  external_type(TBETable) {
+    TBE lookup(Address);
+    void allocate(Address);
+    void deallocate(Address);
+    bool isPresent(Address);
+  }
+
+  external_type(CacheMemory) {
+    bool cacheAvail(Address);
+    Address cacheProbe(Address);
+    void allocate(Address);
+    void deallocate(Address);
+    Entry lookup(Address);
+    void changePermission(Address, AccessPermission);
+    bool isTagPresent(Address);
+    void setMRU(Address);
+  }
+
+  external_type(PerfectCacheMemory) {
+    void allocate(Address);
+    void deallocate(Address);
+    DirEntry lookup(Address);
+    bool isTagPresent(Address);
+  }
+
+
+  TBETable L2_TBEs, template_hack="<L2Cache_TBE>";
+  CacheMemory L2cacheMemory, template_hack="<L2Cache_Entry>", constructor_hack='L2_CACHE_NUM_SETS_BITS,L2_CACHE_ASSOC,MachineType_L2Cache,int_to_string(i)+"_L2"';
+  PerfectCacheMemory localDirectory, template_hack="<L2Cache_DirEntry>";
+  TimerTable reissueTimerTable;  
+
+
+  Entry getL2CacheEntry(Address addr), return_by_ref="yes" {
+    if (L2cacheMemory.isTagPresent(addr)) {
+      return L2cacheMemory[addr];
+    }
+  }
+  
+  void changePermission(Address addr, AccessPermission permission) {
+    if (L2cacheMemory.isTagPresent(addr)) {
+      return L2cacheMemory.changePermission(addr, permission);
+    } 
+  }
+
+  bool isCacheTagPresent(Address addr) {
+    return (L2cacheMemory.isTagPresent(addr) );
+  }
+  
+  bool isDirTagPresent(Address addr) {
+    return (localDirectory.isTagPresent(addr) );
+  }
+
+  bool isOnlySharer(Address addr, MachineID shar_id) {
+    if (isCacheTagPresent(addr)) {
+      assert (localDirectory.isTagPresent(addr) == false);
+      if (L2cacheMemory[addr].Sharers.count() > 1) {
+        return false;
+      }
+      else if (L2cacheMemory[addr].Sharers.count() == 1) {
+        if (L2cacheMemory[addr].Sharers.isElement(shar_id)) {
+          return true;
+        }
+        else {
+          return false;  // something happened which should cause this PUTS to be nacked
+        }
+        return true;
+      }
+      else {
+        return false;
+      }
+    }
+    else if (localDirectory.isTagPresent(addr)){
+      if (localDirectory[addr].Sharers.count() > 1) {
+        return false;
+      }
+      else if (localDirectory[addr].Sharers.count() == 1) {
+        if (localDirectory[addr].Sharers.isElement(shar_id)) {
+          return true;
+        }
+        else {
+          return false;  // something happened which should cause this PUTS to be nacked
+        }
+      }
+      else {
+        return false;
+      }
+    }
+    else {
+      // shouldn't happen unless L1 issues PUTS before unblock received
+      return false;
+    }
+  }
+
+  void copyCacheStateToDir(Address addr) {
+    assert(localDirectory.isTagPresent(addr) == false);
+    localDirectory.allocate(addr);
+    localDirectory[addr].DirState := L2cacheMemory[addr].CacheState;
+    localDirectory[addr].Sharers := L2cacheMemory[addr].Sharers;
+    localDirectory[addr].Owner := L2cacheMemory[addr].Owner;
+    localDirectory[addr].OwnerValid := L2cacheMemory[addr].OwnerValid;
+     
+  }
+
+  void copyDirToCache(Address addr) {
+    L2cacheMemory[addr].Sharers := localDirectory[addr].Sharers;
+    L2cacheMemory[addr].Owner := localDirectory[addr].Owner;
+    L2cacheMemory[addr].OwnerValid := localDirectory[addr].OwnerValid;
+  }
+     
+
+  void recordLocalSharerInDir(Address addr, MachineID shar_id) {
+    if (isCacheTagPresent(addr)) {
+      assert (localDirectory.isTagPresent(addr) == false);
+      L2cacheMemory[addr].Sharers.add(shar_id);
+    }
+    else {
+      if (localDirectory.isTagPresent(addr) == false) {
+        localDirectory.allocate(addr); 
+        localDirectory[addr].Sharers.clear();
+        localDirectory[addr].OwnerValid := false;
+      }
+      localDirectory[addr].Sharers.add(shar_id);
+    }
+  }
+
+  void recordNewLocalExclusiveInDir(Address addr, MachineID exc_id) {
+
+    if (isCacheTagPresent(addr)) {
+      assert (localDirectory.isTagPresent(addr) == false);
+      L2cacheMemory[addr].Sharers.clear();
+      L2cacheMemory[addr].OwnerValid := true;
+      L2cacheMemory[addr].Owner := exc_id; 
+    }
+    else {
+      if (localDirectory.isTagPresent(addr) == false) {
+        localDirectory.allocate(addr); 
+      }
+      localDirectory[addr].Sharers.clear();
+      localDirectory[addr].OwnerValid := true; 
+      localDirectory[addr].Owner := exc_id;
+    }
+  }
+
+
+  void removeAllLocalSharersFromDir(Address addr) {
+    if (isCacheTagPresent(addr)) {
+      assert (localDirectory.isTagPresent(addr) == false);
+      L2cacheMemory[addr].Sharers.clear();
+      L2cacheMemory[addr].OwnerValid := false;
+    }
+    else {
+      localDirectory[addr].Sharers.clear();
+      localDirectory[addr].OwnerValid := false; 
+    }
+  }
+
+  void removeSharerFromDir(Address addr, MachineID sender) {
+    if (isCacheTagPresent(addr)) {
+      assert (localDirectory.isTagPresent(addr) == false);
+      L2cacheMemory[addr].Sharers.remove(sender);
+    }
+    else {
+      localDirectory[addr].Sharers.remove(sender);
+    }
+  }
+
+  void removeOwnerFromDir(Address addr, MachineID sender) {
+    if (isCacheTagPresent(addr)) {
+      assert (localDirectory.isTagPresent(addr) == false);
+      L2cacheMemory[addr].OwnerValid := false;
+    }
+    else {
+      localDirectory[addr].OwnerValid := false;
+    }
+  }
+
+  bool isLocalSharer(Address addr, MachineID shar_id) {
+    if (isCacheTagPresent(addr)) {
+      assert (localDirectory.isTagPresent(addr) == false);
+      return L2cacheMemory[addr].Sharers.isElement(shar_id);
+    }
+    else {
+      return localDirectory[addr].Sharers.isElement(shar_id);
+    }
+
+  }
+
+  NetDest getLocalSharers(Address addr) {
+    if (isCacheTagPresent(addr)) {
+      assert (localDirectory.isTagPresent(addr) == false);
+      return L2cacheMemory[addr].Sharers;
+    }
+    else {
+      return localDirectory[addr].Sharers;
+    }
+
+  }
+
+  MachineID getLocalOwner(Address addr) {
+    if (isCacheTagPresent(addr)) {
+      assert (localDirectory.isTagPresent(addr) == false);
+      return L2cacheMemory[addr].Owner;
+    }
+    else {
+      return localDirectory[addr].Owner;
+    }
+
+  }
+
+
+  int countLocalSharers(Address addr) {
+    if (isCacheTagPresent(addr)) {
+      assert (localDirectory.isTagPresent(addr) == false);
+      return L2cacheMemory[addr].Sharers.count();
+    }
+    else {
+      return localDirectory[addr].Sharers.count();
+    }
+  }
+
+  bool isLocalOwnerValid(Address addr) {
+    if (isCacheTagPresent(addr)) {
+      assert (localDirectory.isTagPresent(addr) == false);
+      return L2cacheMemory[addr].OwnerValid;
+    }
+    else {
+      return localDirectory[addr].OwnerValid;
+    }
+  }
+
+  int countLocalSharersExceptRequestor(Address addr, MachineID requestor) {
+    if (isCacheTagPresent(addr)) {
+      assert (localDirectory.isTagPresent(addr) == false);
+      if (L2cacheMemory[addr].Sharers.isElement(requestor)) {
+        return ( L2cacheMemory[addr].Sharers.count() - 1 );
+      }
+      else {
+        return L2cacheMemory[addr].Sharers.count();
+      } 
+    }
+    else {
+      if (localDirectory[addr].Sharers.isElement(requestor)) {
+        return ( localDirectory[addr].Sharers.count() - 1 );
+      }
+      else {
+        return localDirectory[addr].Sharers.count();
+      }
+    }
+  }
+
+  
+
+  State getState(Address addr) {
+
+    if (L2_TBEs.isPresent(addr)) { 
+      return L2_TBEs[addr].TBEState;
+    } else if (isCacheTagPresent(addr)) {
+      return getL2CacheEntry(addr).CacheState;
+    } else if (isDirTagPresent(addr)) {
+      return localDirectory[addr].DirState;
+    } else {
+      return State:NP;
+    }
+  }
+
+  string getStateStr(Address addr) {
+    return L2Cache_State_to_string(getState(addr));
+  }
+
+  string getCoherenceRequestTypeStr(CoherenceRequestType type) {
+    return CoherenceRequestType_to_string(type);
+  }
+
+
+  void setState(Address addr, State state) {
+    assert((localDirectory.isTagPresent(addr) && L2cacheMemory.isTagPresent(addr)) == false);
+
+    if (L2_TBEs.isPresent(addr)) {
+      L2_TBEs[addr].TBEState := state;
+    }
+
+    if ( 
+         (state == State:M) || 
+         (state == State:O) || 
+         (state == State:S) || 
+         (state == State:OLS) || 
+         (state == State:SLS) || 
+         (state == State:OLSX) || 
+         (state == State:SLS) 
+       ) {  
+       assert(isCacheTagPresent(addr));
+    }
+    else if (
+         (state == State:ILS) || 
+         (state == State:ILX) || 
+         (state == State:ILO) || 
+         (state == State:ILOX) || 
+         (state == State:ILOS) || 
+         (state == State:ILOSX)  
+       ) {  
+       // assert(isCacheTagPresent(addr) == false);
+    }
+      
+    
+
+    if (isCacheTagPresent(addr)) {
+      if ( ((getL2CacheEntry(addr).CacheState != State:M) && (state == State:M)) ||
+           ((getL2CacheEntry(addr).CacheState != State:S) && (state == State:S)) ||
+           ((getL2CacheEntry(addr).CacheState != State:O) && (state == State:O)) ) {
+        getL2CacheEntry(addr).CacheState := state;
+        // disable Coherence Checker for now
+        // sequencer.checkCoherence(addr);
+      }
+      else {
+        getL2CacheEntry(addr).CacheState := state;
+      }
+
+      // Set permission
+      changePermission(addr, AccessPermission:Read_Only);
+    }
+    else if (localDirectory.isTagPresent(addr)) {
+      localDirectory[addr].DirState := state;
+    }
+
+  }
+
+  
+  bool isBlockExclusive(Address addr) {
+    if (isCacheTagPresent(addr)) {
+      // the list of exclusive states below is likely incomplete
+      if ( (getL2CacheEntry(addr).CacheState == State:M) || 
+           (getL2CacheEntry(addr).CacheState == State:MI) ) {
+        return true;
+      }
+    }
+
+    return false;
+  }
+
+  bool isBlockShared(Address addr) {
+    if (isCacheTagPresent(addr)) {
+      // the list of shared states below is likely incomplete
+      if ( (getL2CacheEntry(addr).CacheState == State:S) || 
+           (getL2CacheEntry(addr).CacheState == State:O)  ||
+           (getL2CacheEntry(addr).CacheState == State:OI) || 
+           (getL2CacheEntry(addr).CacheState == State:OXW)  ) {
+        return true;
+      }
+    }
+    return false;
+  }
+
+  MessageBuffer triggerQueue, ordered="true";
+
+  out_port(globalRequestNetwork_out, RequestMsg, GlobalRequestFromL2Cache);
+  out_port(localRequestNetwork_out, RequestMsg, L1RequestFromL2Cache);
+  out_port(responseNetwork_out, ResponseMsg, responseFromL2Cache);
+
+  out_port(triggerQueue_out, TriggerMsg, triggerQueue);
+
+
+
+  // ** IN_PORTS **
+
+  // Trigger Queue
+  in_port(triggerQueue_in, TriggerMsg, triggerQueue) {
+    if (triggerQueue_in.isReady()) {
+      peek(triggerQueue_in, TriggerMsg) {
+        if (in_msg.Type == TriggerType:ALL_ACKS) {
+          trigger(Event:All_Acks, in_msg.Address);
+        } else {
+          error("Unexpected message");
+        }
+      }
+    }
+  }
+
+    // Use Timer
+  in_port(reissueTimerTable_in, Address, reissueTimerTable) {
+    if (reissueTimerTable_in.isReady()) {
+      trigger(Event:Reissue_Timeout, reissueTimerTable.readyAddress());
+    }
+  }
+
+  // Request Network
+  in_port(requestNetwork_in, RequestMsg, GlobalRequestToL2Cache) {
+    if (requestNetwork_in.isReady()) {
+      peek(requestNetwork_in, RequestMsg) {
+        if (in_msg.Type == CoherenceRequestType:GETX) {
+          if (in_msg.Requestor == machineID) {
+            trigger(Event:Own_GETX, in_msg.Address);
+          } else {
+            trigger(Event:Fwd_GETX, in_msg.Address);
+          }
+        } else if (in_msg.Type == CoherenceRequestType:GETS) {
+          trigger(Event:Fwd_GETS, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:INV) {
+          trigger(Event:Inv, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:WB_ACK) {
+          trigger(Event:Writeback_Ack, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:WB_NACK) {
+          trigger(Event:Writeback_Nack, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:MEM_NACK) {
+          if (in_msg.Requestor == machineID) {
+          	trigger(Event:Mem_Nack, in_msg.Address);
+          } else {
+            //trigger(Event:Other_Mem_Nack, in_msg.Address);
+			// FIXME : We should just drop it possibly or something else?
+			requestNetwork_in.dequeue();
+          }
+	}else if (in_msg.Type == CoherenceRequestType:MEM_ACK) { // Only sent to allow you to free your write resources
+          if (in_msg.Requestor == machineID) {
+          	trigger(Event:Mem_Ack, in_msg.Address);
+          } else {
+            //trigger(Event:Other_Mem_Nack, in_msg.Address);
+			// FIXME : We should just drop it possibly or something else?
+			requestNetwork_in.dequeue();
+          }
+
+        } else {
+          error("Unexpected message");
+        }
+      }
+    }
+  }
+
+  in_port(L1requestNetwork_in, RequestMsg, L1RequestToL2Cache) {
+    if (L1requestNetwork_in.isReady()) {
+      peek(L1requestNetwork_in, RequestMsg) {
+        assert(in_msg.Destination.isElement(machineID));
+        if (in_msg.Type == CoherenceRequestType:GETX) {
+          trigger(Event:L1_GETX, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:GETS) {
+            trigger(Event:L1_GETS, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:PUTO) {
+          trigger(Event:L1_PUTO, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:PUTX) {
+          trigger(Event:L1_PUTX, in_msg.Address);
+        } else if (in_msg.Type == CoherenceRequestType:PUTS) {
+          if (isOnlySharer(in_msg.Address, in_msg.Requestor)) {
+            trigger(Event:L1_PUTS_only, in_msg.Address);
+          }
+          else {
+            trigger(Event:L1_PUTS, in_msg.Address);
+          }
+        } else {
+          error("Unexpected message");
+        }
+      }
+    }
+  }
+
+
+  // Response Network
+  in_port(responseNetwork_in, ResponseMsg, responseToL2Cache) {
+    if (responseNetwork_in.isReady()) {
+      peek(responseNetwork_in, ResponseMsg) {
+        assert(in_msg.Destination.isElement(machineID));
+        if (in_msg.Type == CoherenceResponseType:ACK) {
+          if (in_msg.SenderMachine == MachineType:L2Cache) {
+            trigger(Event:ExtAck, in_msg.Address);
+          }
+          else {
+            trigger(Event:IntAck, in_msg.Address);
+          }
+        } else if (in_msg.Type == CoherenceResponseType:DATA) {
+          trigger(Event:Data, in_msg.Address);
+        } else if (in_msg.Type == CoherenceResponseType:DATA_EXCLUSIVE) {
+          trigger(Event:Data_Exclusive, in_msg.Address);
+        } else if (in_msg.Type == CoherenceResponseType:UNBLOCK) {
+          trigger(Event:Unblock, in_msg.Address);
+        } else if (in_msg.Type == CoherenceResponseType:UNBLOCK_EXCLUSIVE) {
+          trigger(Event:Exclusive_Unblock, in_msg.Address);
+        } else if (in_msg.Type == CoherenceResponseType:WRITEBACK_DIRTY_DATA) {
+          if (L2cacheMemory.isTagPresent(in_msg.Address) == false &&
+                   L2cacheMemory.cacheAvail(in_msg.Address) == false) {
+            trigger(Event:L2_Replacement, L2cacheMemory.cacheProbe(in_msg.Address));
+          }
+          else {
+            trigger(Event:L1_WBDIRTYDATA, in_msg.Address);
+          }
+        } else if (in_msg.Type == CoherenceResponseType:WRITEBACK_CLEAN_DATA) {
+          if (L2cacheMemory.isTagPresent(in_msg.Address) == false &&
+                   L2cacheMemory.cacheAvail(in_msg.Address) == false) {
+            trigger(Event:L2_Replacement, L2cacheMemory.cacheProbe(in_msg.Address));
+          }
+          else {
+            trigger(Event:L1_WBCLEANDATA, in_msg.Address);
+          }
+        } else {
+          error("Unexpected message");
+        }
+      }
+    }
+  }
+
+  
+  // ACTIONS
+
+  action(a_issueGETS, "a", desc="issue local request globally") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      enqueue(globalRequestNetwork_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceRequestType:GETS;
+        out_msg.RequestorMachine := MachineType:L2Cache;
+        out_msg.Requestor := machineID;
+        out_msg.Destination.add(map_Address_to_Directory(address));
+        out_msg.MessageSize := MessageSizeType:Request_Control;
+      }
+    }
+  }
+
+  action(aa_issueGETS, "\a\a", desc="issue local request globally GETS - again") {
+      enqueue(globalRequestNetwork_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceRequestType:GETS_PERSISTENT;
+        out_msg.RequestorMachine := MachineType:L2Cache;
+        out_msg.Requestor := machineID;
+        out_msg.Destination.add(map_Address_to_Directory(address));
+        out_msg.MessageSize := MessageSizeType:Request_Control;
+      }
+  }
+
+  action(a_issueGETX, "\a", desc="issue local request globally") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      enqueue(globalRequestNetwork_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceRequestType:GETX;
+        out_msg.RequestorMachine := MachineType:L2Cache;
+        out_msg.Requestor := machineID;
+        out_msg.Destination.add(map_Address_to_Directory(address));
+        out_msg.MessageSize := MessageSizeType:Request_Control;
+      }
+    }
+  }
+
+   action(aa_issueGETX, "\aa", desc="issue local request globally - again") {
+      enqueue(globalRequestNetwork_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceRequestType:GETX_PERSISTENT;
+        out_msg.RequestorMachine := MachineType:L2Cache;
+        out_msg.Requestor := machineID;
+        out_msg.Destination.add(map_Address_to_Directory(address));
+        out_msg.MessageSize := MessageSizeType:Request_Control;
+      }
+  }
+
+  action(b_issuePUTX, "b", desc="Issue PUTX") {
+    enqueue(globalRequestNetwork_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceRequestType:PUTX;
+      out_msg.RequestorMachine := MachineType:L2Cache;
+      out_msg.Requestor := machineID;
+      out_msg.Destination.add(map_Address_to_Directory(address));
+      out_msg.MessageSize := MessageSizeType:Writeback_Control;
+    }
+  }
+
+  action(b_issuePUTO, "\b", desc="Issue PUTO") {
+    enqueue(globalRequestNetwork_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceRequestType:PUTO;
+      out_msg.Requestor := machineID;
+      out_msg.RequestorMachine := MachineType:L2Cache;
+      out_msg.Destination.add(map_Address_to_Directory(address));
+      out_msg.MessageSize := MessageSizeType:Writeback_Control;
+    }
+  }
+
+  /* PUTO, but local sharers exist */
+  action(b_issuePUTO_ls, "\bb", desc="Issue PUTO") {
+    enqueue(globalRequestNetwork_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceRequestType:PUTO_SHARERS;
+      out_msg.Requestor := machineID;
+      out_msg.RequestorMachine := MachineType:L2Cache;
+      out_msg.Destination.add(map_Address_to_Directory(address));
+      out_msg.MessageSize := MessageSizeType:Writeback_Control;
+    }
+  }
+
+  action(c_sendDataFromTBEToL1GETS, "c", desc="Send data from TBE to L1 requestors in TBE") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceResponseType:DATA;
+      out_msg.Sender := machineID;
+      out_msg.Destination.addNetDest(L2_TBEs[address].L1_GetS_IDs);
+      out_msg.DataBlk := L2_TBEs[address].DataBlk;
+      // out_msg.Dirty := L2_TBEs[address].Dirty;
+      // shared data should be clean
+      out_msg.Dirty := false;
+      out_msg.MessageSize := MessageSizeType:Response_Data;
+    }
+    DEBUG_EXPR(address);
+    DEBUG_EXPR(L2_TBEs[address].DataBlk);
+  }
+
+  action(c_sendDataFromTBEToL1GETX, "\c", desc="Send data from TBE to L1 requestors in TBE") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceResponseType:DATA_EXCLUSIVE;
+      out_msg.Sender := machineID;
+      out_msg.SenderMachine := MachineType:L2Cache;
+      out_msg.Destination.add(L2_TBEs[address].L1_GetX_ID);
+      out_msg.DataBlk := L2_TBEs[address].DataBlk;
+      out_msg.Dirty := L2_TBEs[address].Dirty;
+      out_msg.Acks := L2_TBEs[address].Local_GETX_IntAcks;
+      out_msg.MessageSize := MessageSizeType:Response_Data;
+    }
+    DEBUG_EXPR(address);
+    DEBUG_EXPR(L2_TBEs[address].DataBlk);
+  }
+
+  action(c_sendExclusiveDataFromTBEToL1GETS, "\cc", desc="Send data from TBE to L1 requestors in TBE") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceResponseType:DATA_EXCLUSIVE;
+      out_msg.Sender := machineID;
+      out_msg.SenderMachine := MachineType:L2Cache;
+      out_msg.Destination.addNetDest(L2_TBEs[address].L1_GetS_IDs);
+      out_msg.DataBlk := L2_TBEs[address].DataBlk;
+      out_msg.Dirty := L2_TBEs[address].Dirty;
+      out_msg.MessageSize := MessageSizeType:Response_Data;
+    }
+  }
+
+  action(c_sendDataFromTBEToFwdGETX, "cc", desc="Send data from TBE to external GETX") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceResponseType:DATA_EXCLUSIVE;
+      out_msg.Sender := machineID;
+      out_msg.SenderMachine := MachineType:L2Cache;
+      out_msg.Destination.add(L2_TBEs[address].Fwd_GetX_ID);
+      out_msg.DataBlk := L2_TBEs[address].DataBlk;
+      out_msg.Dirty := L2_TBEs[address].Dirty;
+      out_msg.Acks := L2_TBEs[address].Fwd_GETX_ExtAcks;
+      out_msg.MessageSize := MessageSizeType:Response_Data;
+    }
+  }
+
+  action(c_sendDataFromTBEToFwdGETS, "ccc", desc="Send data from TBE to external GETX") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceResponseType:DATA;
+      out_msg.Sender := machineID;
+      out_msg.Destination.addNetDest(L2_TBEs[address].Fwd_GetS_IDs);
+      out_msg.DataBlk := L2_TBEs[address].DataBlk;
+      // out_msg.Dirty := L2_TBEs[address].Dirty;
+      // shared data should be clean
+      out_msg.Dirty := false;
+      out_msg.Acks := L2_TBEs[address].Fwd_GETX_ExtAcks;
+      out_msg.MessageSize := MessageSizeType:Response_Data;
+    }
+    DEBUG_EXPR(address);
+    DEBUG_EXPR(L2_TBEs[address].DataBlk);
+  }
+
+  action(c_sendExclusiveDataFromTBEToFwdGETS, "\ccc", desc="Send data from TBE to external GETX") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceResponseType:DATA_EXCLUSIVE;
+      out_msg.Sender := machineID;
+      out_msg.SenderMachine := MachineType:L2Cache;
+      out_msg.Destination.addNetDest(L2_TBEs[address].Fwd_GetS_IDs);
+      out_msg.DataBlk := L2_TBEs[address].DataBlk;
+      out_msg.Dirty := L2_TBEs[address].Dirty;
+      out_msg.Acks := L2_TBEs[address].Fwd_GETX_ExtAcks;
+      out_msg.MessageSize := MessageSizeType:Response_Data;
+    }
+    DEBUG_EXPR(address);
+    DEBUG_EXPR(L2_TBEs[address].DataBlk);
+  }
+
+  action(d_sendDataToL1GETS, "d", desc="Send data directly to L1 requestor") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceResponseType:DATA;
+        out_msg.Sender := machineID;
+        out_msg.Destination.add(in_msg.Requestor);
+        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
+        // out_msg.Dirty := getL2CacheEntry(address).Dirty;
+        // shared data should be clean
+        out_msg.Dirty := false;
+        out_msg.MessageSize := MessageSizeType:ResponseL2hit_Data;
+      }
+    }
+    DEBUG_EXPR(address);
+    DEBUG_EXPR(getL2CacheEntry(address).DataBlk);
+  }
+
+  action(d_sendDataToL1GETX, "\d", desc="Send data and a token from TBE to L1 requestor") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceResponseType:DATA_EXCLUSIVE;
+        out_msg.Sender := machineID;
+        out_msg.SenderMachine := MachineType:L2Cache;
+        out_msg.Destination.add(in_msg.Requestor);
+        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
+        out_msg.Dirty := getL2CacheEntry(address).Dirty;
+        out_msg.MessageSize := MessageSizeType:ResponseL2hit_Data;
+        out_msg.Acks := L2_TBEs[address].Local_GETX_IntAcks;
+      }
+    }
+    DEBUG_EXPR(address);
+    DEBUG_EXPR(getL2CacheEntry(address).DataBlk);
+  }
+
+  action(dd_sendDataToFwdGETX, "dd", desc="send data") {
+    peek(requestNetwork_in, RequestMsg) {
+      enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceResponseType:DATA_EXCLUSIVE;
+        out_msg.Sender := machineID;
+        out_msg.SenderMachine := MachineType:L2Cache;
+        out_msg.Destination.add(in_msg.Requestor);
+        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
+        out_msg.Dirty := getL2CacheEntry(address).Dirty;
+        out_msg.MessageSize := MessageSizeType:Response_Data;
+        out_msg.Acks := in_msg.Acks;
+      }
+    }
+    DEBUG_EXPR(address);
+    DEBUG_EXPR(getL2CacheEntry(address).DataBlk);
+  }
+
+  
+  action(dd_sendDataToFwdGETS, "\dd", desc="send data") {
+    peek(requestNetwork_in, RequestMsg) {
+      enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceResponseType:DATA;
+        out_msg.Sender := machineID;
+        out_msg.Destination.add(in_msg.Requestor);
+        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
+        // out_msg.Dirty := getL2CacheEntry(address).Dirty;
+        // shared data should be clean
+        out_msg.Dirty := false;
+        out_msg.MessageSize := MessageSizeType:Response_Data;
+      }
+    }
+    DEBUG_EXPR(address);
+    DEBUG_EXPR(getL2CacheEntry(address).DataBlk);
+  }
+
+  action(dd_sendExclusiveDataToFwdGETS, "\d\d", desc="send data") {
+    peek(requestNetwork_in, RequestMsg) {
+      enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceResponseType:DATA_EXCLUSIVE;
+        out_msg.Sender := machineID;
+        out_msg.Destination.add(in_msg.Requestor);
+        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
+        out_msg.Dirty := getL2CacheEntry(address).Dirty;
+        out_msg.MessageSize := MessageSizeType:Response_Data;
+      }
+    }
+  }
+
+  action(e_sendAck, "e", desc="Send ack with the tokens we've collected thus far.") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceResponseType:ACK;
+      out_msg.Sender := machineID;
+      out_msg.SenderMachine := MachineType:L2Cache;
+      
+      out_msg.Destination.add( L2_TBEs[address].Fwd_GetX_ID);
+      out_msg.Acks := 0 - 1;
+      out_msg.MessageSize := MessageSizeType:Response_Control;
+    }
+  }
+
+  action(e_sendAckToL1Requestor, "\e", desc="Send ack with the tokens we've collected thus far.") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceResponseType:ACK;
+        out_msg.Sender := machineID;
+        out_msg.SenderMachine := MachineType:L2Cache;
+        out_msg.Destination.add(in_msg.Requestor);
+        out_msg.Acks := 0 - 1;
+        out_msg.MessageSize := MessageSizeType:Response_Control;
+      }
+    }
+  }
+
+  action(e_sendAckToL1RequestorFromTBE, "eee", desc="Send ack with the tokens we've collected thus far.") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceResponseType:ACK;
+      out_msg.Sender := machineID;
+      out_msg.SenderMachine := MachineType:L2Cache;
+      out_msg.Destination.add(L2_TBEs[address].L1_GetX_ID);
+      out_msg.Acks := 0 - 1;
+      out_msg.MessageSize := MessageSizeType:Response_Control;
+    }
+  }
+ 
+  action(ee_sendLocalInv, "\ee", desc="Send local invalidates") {
+    L2_TBEs[address].NumIntPendingAcks := countLocalSharers(address);
+    DEBUG_EXPR(address);
+    DEBUG_EXPR(getLocalSharers(address));
+    DEBUG_EXPR(id);
+    DEBUG_EXPR(L2_TBEs[address].NumIntPendingAcks);
+    if (isLocalOwnerValid(address)) {
+      L2_TBEs[address].NumIntPendingAcks := L2_TBEs[address].NumIntPendingAcks + 1;
+      DEBUG_EXPR(getLocalOwner(address));
+    }
+
+    enqueue( localRequestNetwork_out, RequestMsg, latency="L2_RESPONSE_LATENCY" ) {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceRequestType:INV;
+      out_msg.Requestor := machineID;
+      out_msg.RequestorMachine := MachineType:L2Cache;
+      out_msg.Destination.addNetDest(getLocalSharers(address));
+      if (isLocalOwnerValid(address)) 
+      {
+        out_msg.Destination.add(getLocalOwner(address));
+      }
+      out_msg.MessageSize := MessageSizeType:Invalidate_Control;
+    }
+  }
+
+  action(ee_sendLocalInvSharersOnly, "\eee", desc="Send local invalidates to sharers if they exist") {
+
+    // assert(countLocalSharers(address)  > 0);
+    L2_TBEs[address].NumIntPendingAcks := countLocalSharers(address);
+
+    if (countLocalSharers(address) > 0) {
+      enqueue( localRequestNetwork_out, RequestMsg, latency="L2_RESPONSE_LATENCY" ) {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceRequestType:INV;
+        out_msg.Requestor := machineID;
+        out_msg.RequestorMachine := MachineType:L2Cache;
+        out_msg.Destination.addNetDest(getLocalSharers(address));
+        out_msg.MessageSize := MessageSizeType:Invalidate_Control;
+      }
+    }
+  }
+
+  action(ee_addLocalIntAck, "e\ee", desc="add a local ack to wait for") {
+    L2_TBEs[address].NumIntPendingAcks := L2_TBEs[address].NumIntPendingAcks + 1;
+  }
+
+  action(ee_issueLocalInvExceptL1Requestor, "\eeee", desc="Send local invalidates to sharers if they exist") {
+      peek(L1requestNetwork_in, RequestMsg) {
+
+//         assert(countLocalSharers(address) > 0);
+        if (countLocalSharers(address) == 0) {
+          L2_TBEs[address].NumIntPendingAcks := 0;
+        }
+        else {
+
+          if (isLocalSharer(address, in_msg.Requestor)) {
+            L2_TBEs[address].NumIntPendingAcks := countLocalSharers(address) - 1;
+          }
+          else {
+            L2_TBEs[address].NumIntPendingAcks := countLocalSharers(address);
+          }
+
+          enqueue( localRequestNetwork_out, RequestMsg, latency="L2_RESPONSE_LATENCY" ) {
+            out_msg.Address := address;
+            out_msg.Type := CoherenceRequestType:INV;
+            out_msg.Requestor := in_msg.Requestor;
+            out_msg.RequestorMachine := MachineType:L1Cache;
+            out_msg.Destination.addNetDest(getLocalSharers(address));
+            out_msg.Destination.remove(in_msg.Requestor);
+            out_msg.MessageSize := MessageSizeType:Invalidate_Control;
+          }
+        }
+      }
+  }
+
+  action(ee_issueLocalInvExceptL1RequestorInTBE, "\eeeeee", desc="Send local invalidates to sharers if they exist") {
+    if (countLocalSharers(address) == 0) {
+      L2_TBEs[address].NumIntPendingAcks := 0;
+    }
+    else {
+      if (isLocalSharer(address, L2_TBEs[address].L1_GetX_ID)) {
+        L2_TBEs[address].NumIntPendingAcks := countLocalSharers(address) - 1;
+      }
+      else {
+        L2_TBEs[address].NumIntPendingAcks := countLocalSharers(address);
+      }
+    }
+    enqueue( localRequestNetwork_out, RequestMsg, latency="L2_RESPONSE_LATENCY" ) {
+        out_msg.Address := address;
+        out_msg.Type := CoherenceRequestType:INV;
+        out_msg.Requestor := L2_TBEs[address].L1_GetX_ID;
+        out_msg.RequestorMachine := MachineType:L1Cache;
+        out_msg.Destination.addNetDest(getLocalSharers(address));
+        out_msg.Destination.remove(L2_TBEs[address].L1_GetX_ID);
+        out_msg.MessageSize := MessageSizeType:Invalidate_Control;
+    }
+  }
+
+
+  action(f_sendUnblock, "f", desc="Send unblock to global directory") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceResponseType:UNBLOCK;
+      out_msg.Destination.add(map_Address_to_Directory(address));
+      out_msg.Sender := machineID;
+      out_msg.SenderMachine := MachineType:L2Cache;
+      out_msg.MessageSize := MessageSizeType:Unblock_Control;
+    }
+  }
+
+
+  action(f_sendExclusiveUnblock, "\f", desc="Send unblock to global directory") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceResponseType:UNBLOCK_EXCLUSIVE;
+      out_msg.Destination.add(map_Address_to_Directory(address));
+      out_msg.Sender := machineID;
+      out_msg.SenderMachine := MachineType:L2Cache;
+      out_msg.MessageSize := MessageSizeType:Unblock_Control;
+    }
+  }
+
+
+  action(g_recordLocalSharer, "g", desc="Record new local sharer from unblock message") {
+    peek(responseNetwork_in, ResponseMsg) {
+      recordLocalSharerInDir(in_msg.Address, in_msg.Sender);
+    }
+  }
+
+  action(g_recordLocalExclusive, "\g", desc="Record new local exclusive sharer from unblock message") {
+    peek(responseNetwork_in, ResponseMsg) {
+      recordNewLocalExclusiveInDir(address, in_msg.Sender);
+    }
+  }
+
+  action(gg_clearLocalSharers, "gg", desc="Clear local sharers") {
+    removeAllLocalSharersFromDir(address);
+  }
+
+  action(gg_clearSharerFromL1Response, "\gg", desc="Clear sharer from L1 response queue") {
+    peek(responseNetwork_in, ResponseMsg) {
+      removeSharerFromDir(in_msg.Address, in_msg.Sender);
+    }
+  }
+
+  action(gg_clearOwnerFromL1Response, "g\g", desc="Clear sharer from L1 response queue") {
+    peek(responseNetwork_in, ResponseMsg) {
+      removeOwnerFromDir(in_msg.Address, in_msg.Sender);
+    }
+  }
+
+  action(h_countLocalSharersExceptRequestor, "h", desc="counts number of acks needed for L1 GETX") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      L2_TBEs[address].Local_GETX_IntAcks := countLocalSharersExceptRequestor(address, in_msg.Requestor);
+    }
+  }
+
+  action(h_clearIntAcks, "\h", desc="clear IntAcks") {
+    L2_TBEs[address].Local_GETX_IntAcks := 0;
+  }
+
+  action(hh_countLocalSharersExceptL1GETXRequestorInTBE, "hh", desc="counts number of acks needed for L1 GETX") {
+    L2_TBEs[address].Local_GETX_IntAcks := countLocalSharersExceptRequestor(address, L2_TBEs[address].L1_GetX_ID);
+  }
+
+  action(i_copyDataToTBE, "\i", desc="Copy data from response queue to TBE") {
+    peek(responseNetwork_in, ResponseMsg) {
+      L2_TBEs[address].DataBlk := in_msg.DataBlk;
+      L2_TBEs[address].Dirty := in_msg.Dirty;
+    } 
+  }
+  
+  action(i_allocateTBE, "i", desc="Allocate TBE for internal/external request(isPrefetch=0, number of invalidates=0)") {
+    check_allocate(L2_TBEs);
+    L2_TBEs.allocate(address);
+    if(isCacheTagPresent(address)) {
+      L2_TBEs[address].DataBlk := getL2CacheEntry(address).DataBlk;
+      L2_TBEs[address].Dirty := getL2CacheEntry(address).Dirty;
+    }
+    L2_TBEs[address].NumIntPendingAcks := 0;  // default value
+    L2_TBEs[address].NumExtPendingAcks := 0;  // default value
+    L2_TBEs[address].Fwd_GetS_IDs.clear();
+    L2_TBEs[address].L1_GetS_IDs.clear();
+  }
+
+
+
+  action(j_forwardGlobalRequestToLocalOwner, "j", desc="Forward external request to local owner") {
+    peek(requestNetwork_in, RequestMsg) {
+      enqueue( localRequestNetwork_out, RequestMsg, latency="L2_RESPONSE_LATENCY" ) {
+        out_msg.Address := in_msg.Address;
+        out_msg.Type := in_msg.Type;
+        out_msg.Requestor := machineID;
+        out_msg.RequestorMachine := MachineType:L2Cache;
+        out_msg.Destination.add(getLocalOwner(in_msg.Address));
+        out_msg.Type := in_msg.Type;
+        out_msg.MessageSize := MessageSizeType:Forwarded_Control;
+        out_msg.Acks := 0 - 1;
+      }
+    }
+  }
+
+
+  action(k_forwardLocalGETSToLocalSharer, "k", desc="Forward local request to local sharer/owner") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      enqueue( localRequestNetwork_out, RequestMsg, latency="L2_RESPONSE_LATENCY" ) {
+        out_msg.Address := in_msg.Address; 
+        out_msg.Type := CoherenceRequestType:GETS;
+        out_msg.Requestor := in_msg.Requestor;
+        out_msg.RequestorMachine := MachineType:L1Cache;
+        // should randomize this so one node doesn't get abused more than others
+        out_msg.Destination.add(localDirectory[in_msg.Address].Sharers.smallestElement(MachineType:L1Cache));
+        out_msg.MessageSize := MessageSizeType:Forwarded_Control;
+      }
+    }
+  }
+
+  action(k_forwardLocalGETXToLocalOwner, "\k", desc="Forward local request to local owner") {
+    enqueue( localRequestNetwork_out, RequestMsg, latency="L2_RESPONSE_LATENCY" ) {
+      out_msg.Address := address;
+      out_msg.Type := CoherenceRequestType:GETX;
+      out_msg.Requestor := L2_TBEs[address].L1_GetX_ID;
+      out_msg.RequestorMachine := MachineType:L1Cache;
+      out_msg.Destination.add(localDirectory[address].Owner);
+      out_msg.MessageSize := MessageSizeType:Forwarded_Control;
+      out_msg.Acks := 1 + L2_TBEs[address].Local_GETX_IntAcks;
+    }
+  }
+
+  // same as previous except that it assumes to TBE is present to get number of acks
+  action(kk_forwardLocalGETXToLocalExclusive, "kk", desc="Forward local request to local owner") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      enqueue( localRequestNetwork_out, RequestMsg, latency="L2_RESPONSE_LATENCY" ) {
+        out_msg.Address := in_msg.Address; 
+        out_msg.Type := CoherenceRequestType:GETX;
+        out_msg.Requestor := in_msg.Requestor;
+        out_msg.RequestorMachine := MachineType:L1Cache;
+        out_msg.Destination.add(getLocalOwner(in_msg.Address));
+        out_msg.MessageSize := MessageSizeType:Forwarded_Control;
+        out_msg.Acks := 1;
+      }
+    }
+  }
+
+  action(kk_forwardLocalGETSToLocalOwner, "\kk", desc="Forward local request to local owner") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      enqueue( localRequestNetwork_out, RequestMsg, latency="L2_RESPONSE_LATENCY" ) {
+        out_msg.Address := in_msg.Address; 
+        out_msg.Type := CoherenceRequestType:GETS;
+        out_msg.Requestor := in_msg.Requestor;
+        out_msg.RequestorMachine := MachineType:L1Cache;
+        out_msg.Destination.add(getLocalOwner(in_msg.Address));
+        out_msg.MessageSize := MessageSizeType:Forwarded_Control;
+      }
+    }
+  }
+
+
+  action(l_writebackAckNeedData, "l", desc="Send writeback ack to L1 requesting data") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      enqueue( localRequestNetwork_out, RequestMsg, latency="L2_RESPONSE_LATENCY" ) {
+        out_msg.Address := in_msg.Address; 
+        // out_msg.Type := CoherenceResponseType:WRITEBACK_SEND_DATA;
+        out_msg.Type := CoherenceRequestType:WB_ACK_DATA;
+        out_msg.Requestor := machineID;
+        out_msg.RequestorMachine := MachineType:L2Cache;
+        out_msg.Destination.add(in_msg.Requestor);
+        out_msg.MessageSize := MessageSizeType:Writeback_Control;
+      }
+    }
+  }
+
+  action(l_writebackAckDropData, "\l", desc="Send writeback ack to L1 indicating to drop data") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      enqueue( localRequestNetwork_out, RequestMsg, latency="L2_RESPONSE_LATENCY" ) {
+        out_msg.Address := in_msg.Address; 
+        // out_msg.Type := CoherenceResponseType:WRITEBACK_ACK;
+        out_msg.Type := CoherenceRequestType:WB_ACK;
+        out_msg.Requestor := machineID;
+        out_msg.RequestorMachine := MachineType:L2Cache;
+        out_msg.Destination.add(in_msg.Requestor);
+        out_msg.MessageSize := MessageSizeType:Writeback_Control;
+      }
+    }
+  }
+
+  action(ll_writebackNack, "\ll", desc="Send writeback nack to L1") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      enqueue( localRequestNetwork_out, RequestMsg, latency="L2_RESPONSE_LATENCY" ) {
+        out_msg.Address := in_msg.Address; 
+        out_msg.Type := CoherenceRequestType:WB_NACK;
+        out_msg.Requestor := machineID;
+        out_msg.RequestorMachine := MachineType:L2Cache;
+        out_msg.Destination.add(in_msg.Requestor);
+        out_msg.MessageSize := MessageSizeType:Writeback_Control;
+      }
+    }
+  }
+
+  action(m_popRequestQueue, "m", desc="Pop request queue.") {
+    requestNetwork_in.dequeue();
+  }
+
+  action(m_decrementNumberOfMessagesInt, "\m", desc="Decrement the number of messages for which we're waiting") {
+    peek(responseNetwork_in, ResponseMsg) {
+      L2_TBEs[address].NumIntPendingAcks := L2_TBEs[address].NumIntPendingAcks + in_msg.Acks;
+    }
+  }
+
+  action(m_decrementNumberOfMessagesExt, "\mmm", desc="Decrement the number of messages for which we're waiting") {
+    peek(responseNetwork_in, ResponseMsg) {
+      L2_TBEs[address].NumExtPendingAcks := L2_TBEs[address].NumExtPendingAcks - in_msg.Acks;
+    }
+  }
+
+  action(mm_decrementNumberOfMessagesExt, "\mm", desc="Decrement the number of messages for which we're waiting") {
+    peek(requestNetwork_in, RequestMsg) {
+      L2_TBEs[address].NumExtPendingAcks := L2_TBEs[address].NumExtPendingAcks - in_msg.Acks;
+    }
+  }
+
+  action(n_popResponseQueue, "n", desc="Pop response queue") {
+    responseNetwork_in.dequeue();
+  }
+
+  action(n_popTriggerQueue, "\n", desc="Pop trigger queue.") {
+    triggerQueue_in.dequeue();
+  }
+
+  action(o_popL1RequestQueue, "o", desc="Pop L1 request queue.") {
+    L1requestNetwork_in.dequeue();
+  }
+
+
+  action(o_checkForIntCompletion, "\o", desc="Check if we have received all the messages required for completion") {
+    if (L2_TBEs[address].NumIntPendingAcks == 0) {
+      enqueue(triggerQueue_out, TriggerMsg) {
+        out_msg.Address := address;
+        out_msg.Type := TriggerType:ALL_ACKS;
+      }
+    }
+  }
+
+  action(o_checkForExtCompletion, "\oo", desc="Check if we have received all the messages required for completion") {
+    if (L2_TBEs[address].NumExtPendingAcks == 0) {
+      enqueue(triggerQueue_out, TriggerMsg) {
+        out_msg.Address := address;
+        out_msg.Type := TriggerType:ALL_ACKS;
+      }
+    }
+  }
+
+ action(oo_scheduleReissueTimeout, "\o\o", desc="Schedule a use timeout.") {
+    reissueTimerTable.set(address, 15);
+  }
+
+   action(p_unsetReissueTimer, "p", desc="Unset reissue timer.") {
+    if (reissueTimerTable.isSet(address)) {
+      reissueTimerTable.unset(address);
+    }
+  }
+
+  action( qq_sendDataFromTBEToMemory, "qq", desc="Send data from TBE to directory") {
+    enqueue(responseNetwork_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
+      out_msg.Address := address;
+      out_msg.Sender := machineID;
+      out_msg.SenderMachine := MachineType:L2Cache;
+      out_msg.Destination.add(map_Address_to_Directory(address));
+      out_msg.Dirty := L2_TBEs[address].Dirty;
+      if (L2_TBEs[address].Dirty) {
+        out_msg.Type := CoherenceResponseType:WRITEBACK_DIRTY_DATA;
+        out_msg.DataBlk := L2_TBEs[address].DataBlk;
+        out_msg.MessageSize := MessageSizeType:Writeback_Data;
+      } else {
+         out_msg.Type := CoherenceResponseType:WRITEBACK_CLEAN_ACK;
+        // NOTE: in a real system this would not send data.  We send
+        // data here only so we can check it at the memory
+         out_msg.DataBlk := L2_TBEs[address].DataBlk; 
+         out_msg.MessageSize := MessageSizeType:Writeback_Control;
+      }
+    }
+  }
+
+  action( r_setMRU, "\rrr", desc="manually set the MRU bit for cache line" ) {
+    if(isCacheTagPresent(address)) {
+      L2cacheMemory.setMRU(address);
+    }
+  }
+
+  action( s_recordGetXL1ID, "ss", desc="record local GETX requestor") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      L2_TBEs[address].L1_GetX_ID := in_msg.Requestor;
+    }
+  }
+
+  action(s_deallocateTBE, "s", desc="Deallocate external TBE") {
+    L2_TBEs.deallocate(address);
+  }
+
+  action( s_recordGetSL1ID, "\ss", desc="record local GETS requestor") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      L2_TBEs[address].L1_GetS_IDs.add(in_msg.Requestor);
+    }
+  }
+
+  action(t_recordFwdXID, "t", desc="record global GETX requestor") {
+    peek(requestNetwork_in, RequestMsg) {
+      L2_TBEs[address].Fwd_GetX_ID := in_msg.Requestor;
+      L2_TBEs[address].Fwd_GETX_ExtAcks := in_msg.Acks;
+    }
+  }
+
+  action(t_recordFwdSID, "\t", desc="record global GETS requestor") {
+    peek(requestNetwork_in, RequestMsg) {
+      L2_TBEs[address].Fwd_GetS_IDs.clear();
+      L2_TBEs[address].Fwd_GetS_IDs.add(in_msg.Requestor);
+    }
+  }
+
+
+  action(u_writeDataToCache, "u", desc="Write data to cache") {
+    peek(responseNetwork_in, ResponseMsg) {
+      getL2CacheEntry(address).DataBlk := in_msg.DataBlk;
+      if ((getL2CacheEntry(address).Dirty == false) && in_msg.Dirty) {
+        getL2CacheEntry(address).Dirty := in_msg.Dirty;
+      }
+    }
+  }
+  
+  action(vv_allocateL2CacheBlock, "\v", desc="Set L2 cache tag equal to tag of block B.") {
+    L2cacheMemory.allocate(address);
+  }
+
+  action(rr_deallocateL2CacheBlock, "\r", desc="Deallocate L2 cache block.  Sets the cache to not present, allowing a replacement in parallel with a fetch.") {
+    L2cacheMemory.deallocate(address);
+  }
+
+
+  action(w_assertIncomingDataAndCacheDataMatch, "w", desc="Assert that the incoming data and the data in the cache match") {
+    peek(responseNetwork_in, ResponseMsg) {
+      assert(getL2CacheEntry(address).DataBlk == in_msg.DataBlk);
+    }
+  }
+
+  action(uu_profileMiss, "\u", desc="Profile the demand miss") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      // AccessModeType not implemented
+      profile_L2Cache_miss(convertToGenericType(in_msg.Type), in_msg.AccessMode, MessageSizeTypeToInt(in_msg.MessageSize),  in_msg.Prefetch, machineIDToNodeID(in_msg.Requestor));
+    }
+  }
+
+
+
+  action(y_copyCacheStateToDir, "y", desc="Copy cache state to directory state") {
+
+    assert(isCacheTagPresent(address)); 
+    copyCacheStateToDir(address);
+
+  }
+
+  action(y_copyDirToCacheAndRemove, "/y", desc="Copy dir state to cache and remove") {
+    copyDirToCache(address);
+    localDirectory.deallocate(address);
+  }
+
+
+  action(z_stall, "z", desc="Stall") {
+  }
+  
+
+  action(zz_recycleL1RequestQueue, "zz", desc="Send the head of the mandatory queue to the back of the queue.") {
+    peek(L1requestNetwork_in, RequestMsg) {
+      APPEND_TRANSITION_COMMENT(in_msg.Requestor);
+    }
+    L1requestNetwork_in.recycle();
+  }
+
+  action(zz_recycleRequestQueue, "\zz", desc="Send the head of the mandatory queue to the back of the queue.") {
+    peek(requestNetwork_in, RequestMsg) {
+      APPEND_TRANSITION_COMMENT(in_msg.Requestor);
+    }
+    requestNetwork_in.recycle();
+  }
+
+
+  action(zz_recycleResponseQueue, "\z\z", desc="Send the head of the mandatory queue to the back of the queue.") {
+    peek(responseNetwork_in, ResponseMsg) {
+      APPEND_TRANSITION_COMMENT(in_msg.Sender);
+    }
+    responseNetwork_in.recycle();
+  }
+
+
+
+  //*****************************************************
+  // TRANSITIONS
+  //*****************************************************
+
+  transition({II, IFGX, IFGS, ISFGS, IFGXX, IFLXO, OFGX, ILOW, ILOXW, ILOSW, ILOSXW, SLSW, OLSW, ILSW, IW, OW, SW, OXW, OLSXW, ILXW, IFLS, IFLO, IFLOX, IFLOXX, IFLOSX, OLSXS, IGS, IGM, IGMLS, IGMO, IGMIO, OGMIO, IGMIOF, OGMIOF, MM, SS, OO, OI, MI, MII, OLSI, ILSI, SLSS, OLSS, OLSF, IGMIOFS}, {L1_PUTO, L1_PUTS, L1_PUTS_only, L1_PUTX}) {
+    zz_recycleL1RequestQueue;
+  }
+
+  transition({II, IFGX, IFGS, ISFGS, IFGXX, IFLXO, OFGX, ILOW, ILOXW, ILOSW, ILOSXW, SLSW, OLSW, ILSW, IW, OW, SW, OXW, OLSXW, ILXW, IFLS, IFLO, IFLOX, IFLOXX, IFLOSX, OLSXS, IGS, IGM, IGMLS, IGMO, IGMIO, OGMIO, IGMIOF, OGMIOF, MM, SS, OO, OI, MI, MII, OLSI, ILSI, SLSS, OLSS, OLSF, IGMIOFS}, {L1_GETX, L1_GETS}) {
+    zz_recycleL1RequestQueue;
+  }
+
+  transition({IFGX, IFGS, ISFGS, IFGXX, IFLXO, OFGX, ILOW, ILOXW, ILOSW, ILOSXW, SLSW, OLSW, ILSW, IW, ILXW, OW, SW, OXW, OLSXW, IFLS, IFLO, IFLOX, IFLOXX, IFLOSX,OLSXS,  IGS, IGM, IGMLS, IGMO, MM, SS, OO, OI, MI, MII, OLSI, ILSI, SLSS, OLSS, OLSF, IGMIOFS}, L2_Replacement) {
+    zz_recycleResponseQueue;
+  }
+
+  transition({IFGX, IFGS, ISFGS, IFGXX, IFLXO, OFGX, ILOW, ILOXW, ILOSW, ILOSXW, SLSW, OLSW, ILSW, IW, OW, SW, OXW, OLSXW, ILXW, IFLS, IFLO, IFLOX, IFLOXX, IFLOSX,OLSXS, MM, SS, OO, SLSS, OLSS, OLSF, IGMIOFS}, {Fwd_GETX, Fwd_GETS, Inv}) {
+    zz_recycleRequestQueue;
+  }
+
+  // must happened because we forwarded GETX to local exclusive trying to do wb
+  transition({I, M, O, ILS, ILOX, OLS, SLS, OLSX, S}, L1_PUTX) {
+    ll_writebackNack;
+    o_popL1RequestQueue;
+  }
+
+// happened if we forwarded GETS to exclusive who tried to do writeback
+//  ?? should we just Nack these instead?  Could be a bugs here
+  transition(ILO, L1_PUTX, ILOW) {
+     l_writebackAckNeedData;
+     o_popL1RequestQueue;
+  }
+
+  // this can happen if we forwarded a L1_GETX to exclusiver after it issued a PUTX
+  transition(ILOS, L1_PUTX, ILOSW) {
+    l_writebackAckNeedData;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILOSX, L1_PUTX, ILOSXW) {
+    l_writebackAckNeedData;
+    o_popL1RequestQueue;
+  }
+
+  // must happened because we got Inv when L1 attempted PUTS
+  transition(I, L1_PUTS) {
+    ll_writebackNack;
+    o_popL1RequestQueue;
+  }
+
+  transition(I, L1_PUTO) {
+    ll_writebackNack;
+    o_popL1RequestQueue;
+  }
+
+  // FORWARDED REQUESTS
+
+  transition({ILO, ILX, ILOX}, Fwd_GETS, IFGS) {
+    i_allocateTBE;
+    t_recordFwdSID;
+    j_forwardGlobalRequestToLocalOwner;
+    m_popRequestQueue;
+  }
+
+  transition({ILOS, ILOSX}, Fwd_GETS, ISFGS) {
+    i_allocateTBE;
+    t_recordFwdSID;
+    j_forwardGlobalRequestToLocalOwner;
+    m_popRequestQueue;
+  }
+
+  transition(IFGS, Data, ILO) {
+    i_copyDataToTBE;
+    c_sendDataFromTBEToFwdGETS;
+    s_deallocateTBE;
+    n_popResponseQueue;
+  }
+
+  transition(ISFGS, Data, ILOS) {
+    i_copyDataToTBE;
+    c_sendDataFromTBEToFwdGETS;
+    s_deallocateTBE;
+    n_popResponseQueue;
+  }
+
+  transition(IFGS, Data_Exclusive, I) {
+    i_copyDataToTBE;
+    c_sendExclusiveDataFromTBEToFwdGETS;
+    gg_clearLocalSharers;
+    s_deallocateTBE;
+    n_popResponseQueue;
+  }
+
+
+  transition({ILX, ILO, ILOX}, Fwd_GETX, IFGX) {
+    i_allocateTBE;
+    t_recordFwdXID;
+    j_forwardGlobalRequestToLocalOwner;
+    m_popRequestQueue;
+  }
+
+  transition(IFGX, {Data_Exclusive, Data}, I) {
+    i_copyDataToTBE;
+    c_sendDataFromTBEToFwdGETX;
+    gg_clearLocalSharers;
+    s_deallocateTBE;
+    n_popResponseQueue;
+  }
+
+  transition({ILOSX, ILOS}, Fwd_GETX, IFGXX) {
+    i_allocateTBE;
+    t_recordFwdXID;
+    j_forwardGlobalRequestToLocalOwner;
+    ee_sendLocalInvSharersOnly;
+    ee_addLocalIntAck;
+    m_popRequestQueue;
+  }
+
+
+  transition(IFGXX, IntAck) {
+    m_decrementNumberOfMessagesInt;
+    o_checkForIntCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(IFGXX, Data_Exclusive) {
+    i_copyDataToTBE;
+    m_decrementNumberOfMessagesInt;
+    o_checkForIntCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(IFGXX, All_Acks, I) {
+    c_sendDataFromTBEToFwdGETX;
+    gg_clearLocalSharers;
+    s_deallocateTBE;
+    n_popTriggerQueue;
+  }
+ 
+
+  // transition({O, OX}, Fwd_GETX, I) {
+  transition(O, Fwd_GETX, I) {
+    dd_sendDataToFwdGETX;
+    y_copyCacheStateToDir;
+    rr_deallocateL2CacheBlock;
+    m_popRequestQueue;
+  }
+
+  transition({O, OLS}, Fwd_GETS) {
+    dd_sendDataToFwdGETS;
+    m_popRequestQueue;
+  }
+
+  // transition({OLSX, OX}, Fwd_GETS, O) {
+  transition(OLSX, Fwd_GETS, OLS) {
+    dd_sendDataToFwdGETS;
+    m_popRequestQueue;
+  }
+
+
+  transition(M, Fwd_GETX, I) {
+    dd_sendDataToFwdGETX;
+    rr_deallocateL2CacheBlock;
+    m_popRequestQueue;
+  }
+
+  // MAKE THIS THE SAME POLICY FOR NOW
+
+  // transition(M, Fwd_GETS, O) {
+  //   dd_sendDataToFwdGETS;
+  //   m_popRequestQueue;
+  // } 
+
+  transition(M, Fwd_GETS, I) {
+     dd_sendExclusiveDataToFwdGETS;
+     rr_deallocateL2CacheBlock;
+     m_popRequestQueue;
+  } 
+
+
+  transition({OLS, OLSX}, Fwd_GETX, OLSF) {
+    i_allocateTBE;
+    t_recordFwdXID;
+    ee_sendLocalInv;
+    m_popRequestQueue;
+  }
+
+  transition(OLSF, IntAck) {
+    m_decrementNumberOfMessagesInt;
+    o_checkForIntCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(OLSF, All_Acks, I) {
+    c_sendDataFromTBEToFwdGETX;
+    gg_clearLocalSharers;
+    s_deallocateTBE;
+    rr_deallocateL2CacheBlock;
+    n_popTriggerQueue;
+  }
+
+
+
+  // INVALIDATIONS FROM GLOBAL DIRECTORY
+
+  transition({IGM, IGS}, Inv) {
+    t_recordFwdXID;
+    e_sendAck;
+    m_popRequestQueue;
+  }
+
+  transition({I,NP}, Inv) {
+    i_allocateTBE;
+    t_recordFwdXID;
+    e_sendAck;
+    s_deallocateTBE;
+    m_popRequestQueue;
+  }
+
+  // NEED INV for S state
+
+  transition({ILS, ILO, ILX}, Inv, II) {
+    i_allocateTBE;
+    t_recordFwdXID;
+    ee_sendLocalInv;
+    gg_clearLocalSharers;
+    m_popRequestQueue;
+  }
+
+  transition(SLS, Inv, II) {
+    i_allocateTBE;
+    t_recordFwdXID;
+    ee_sendLocalInv;
+    rr_deallocateL2CacheBlock;
+    m_popRequestQueue;
+  }
+
+  transition(II, IntAck) {
+    m_decrementNumberOfMessagesInt;
+    o_checkForIntCompletion;
+    n_popResponseQueue;
+  } 
+
+  transition(II, All_Acks, I) {
+    e_sendAck;
+    s_deallocateTBE;
+    n_popTriggerQueue;
+  }
+
+  transition(S, Inv, I) {
+    i_allocateTBE;
+    t_recordFwdXID;
+    e_sendAck;
+    s_deallocateTBE;
+    rr_deallocateL2CacheBlock;
+    m_popRequestQueue;
+  }
+
+
+  // LOCAL REQUESTS SATISFIED LOCALLY
+
+  transition(OLSX, L1_GETX, IFLOX) {
+    i_allocateTBE;
+    s_recordGetXL1ID;
+    // count number of INVs needed that doesn't include requestor
+    h_countLocalSharersExceptRequestor;
+    // issue INVs to everyone except requestor
+    ee_issueLocalInvExceptL1Requestor;
+    d_sendDataToL1GETX
+    y_copyCacheStateToDir;
+    r_setMRU;
+    rr_deallocateL2CacheBlock;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+  transition(IFLOX, Exclusive_Unblock, ILX) {
+    g_recordLocalExclusive;
+    s_deallocateTBE;
+    n_popResponseQueue;
+  }
+
+  transition(OLSX, L1_GETS, OLSXS) {
+    d_sendDataToL1GETS;
+    r_setMRU;
+    o_popL1RequestQueue;
+  }
+
+  transition(OLSXS, Unblock, OLSX) {
+    g_recordLocalSharer;
+    n_popResponseQueue;
+  }
+
+  // after this, can't get Fwd_GETX
+  transition(IGMO, Own_GETX) {
+    mm_decrementNumberOfMessagesExt;
+    o_checkForExtCompletion;
+    m_popRequestQueue;
+
+  }
+
+
+  transition(ILX, L1_GETS, IFLOXX) {
+    kk_forwardLocalGETSToLocalOwner;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILOSX, L1_GETS, IFLOSX) {
+    kk_forwardLocalGETSToLocalOwner;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+  transition({ILOS, ILO}, L1_GETS, IFLO) {
+    kk_forwardLocalGETSToLocalOwner;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILS, L1_GETS, IFLS) {
+    k_forwardLocalGETSToLocalSharer;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+  transition({ILX, ILOX}, L1_GETX, IFLOXX) {
+    kk_forwardLocalGETXToLocalExclusive;
+    e_sendAckToL1Requestor;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILOX, L1_GETS, IFLOX) {
+    kk_forwardLocalGETSToLocalOwner;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+  transition(IFLOX, Unblock, ILOSX) {
+    g_recordLocalSharer;
+    n_popResponseQueue;
+  }
+
+  transition(IFLS, Unblock, ILS) {
+    g_recordLocalSharer;
+    n_popResponseQueue;
+  }
+ 
+  transition(IFLOXX, Unblock, ILOSX) {
+    g_recordLocalSharer;
+    n_popResponseQueue;
+  }
+
+  transition(IFLOSX, Unblock, ILOSX) {
+    g_recordLocalSharer;
+    n_popResponseQueue;
+  }
+
+  transition({IFLOSX, IFLOXX}, Exclusive_Unblock, ILX) {
+    g_recordLocalExclusive;
+    n_popResponseQueue;
+  }
+
+  transition(IFLO, Unblock, ILOS) {
+    g_recordLocalSharer;
+    n_popResponseQueue;
+  }
+
+
+  transition(ILOSX, L1_GETX, IFLXO) {
+    i_allocateTBE;
+    s_recordGetXL1ID;
+    h_countLocalSharersExceptRequestor;
+    ee_issueLocalInvExceptL1Requestor;
+    k_forwardLocalGETXToLocalOwner;
+    e_sendAckToL1RequestorFromTBE;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+  transition(IFLXO, Exclusive_Unblock, ILX) {
+    g_recordLocalExclusive;
+    s_deallocateTBE;
+    n_popResponseQueue;
+  }
+
+
+
+  // LOCAL REQUESTS THAT MUST ISSUE
+
+  transition(NP, {L1_PUTS, L1_PUTX, L1_PUTO}) {
+    ll_writebackNack;
+    o_popL1RequestQueue;
+  }
+
+  transition({NP, I}, L1_GETS, IGS) {
+    i_allocateTBE;
+    s_recordGetSL1ID;
+    a_issueGETS;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+  transition({NP, I}, L1_GETX, IGM) {
+    i_allocateTBE;
+    s_recordGetXL1ID;
+    a_issueGETX;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+  transition(S, L1_GETX, IGM) {
+    i_allocateTBE;
+    s_recordGetXL1ID;
+    a_issueGETX;
+    y_copyCacheStateToDir;
+    r_setMRU;
+    rr_deallocateL2CacheBlock;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILS, L1_GETX, IGMLS) {
+    i_allocateTBE;
+    s_recordGetXL1ID;
+    a_issueGETX;
+    // count number of INVs (just sharers?) needed that doesn't include requestor
+    h_countLocalSharersExceptRequestor;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+  transition(IGMLS, Inv) {
+    t_recordFwdXID;
+    ee_sendLocalInv;
+    m_popRequestQueue;
+  }
+
+  transition(IGMLS, IntAck) {
+    m_decrementNumberOfMessagesInt;
+    o_checkForIntCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(IGMLS, All_Acks, IGM) {
+    gg_clearLocalSharers;
+    h_clearIntAcks; 
+    e_sendAck;
+    n_popTriggerQueue;
+  }
+
+  // transition(IGMLS, ExtAck, IGMO) {
+  transition(IGMLS, ExtAck) {
+    m_decrementNumberOfMessagesExt;
+    o_checkForExtCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(IGMLS, {Data, Data_Exclusive}, IGMO) {
+    ee_issueLocalInvExceptL1RequestorInTBE;
+    i_copyDataToTBE;
+    m_decrementNumberOfMessagesExt;
+    o_checkForExtCompletion;
+    n_popResponseQueue;
+  }
+
+
+  transition(ILOS, L1_GETX, IGMIO) {
+    i_allocateTBE;
+    s_recordGetXL1ID;
+    a_issueGETX;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+
+  // new exclusive happened while sharer attempted writeback
+  transition({ILX}, {L1_PUTS, L1_PUTS_only, L1_PUTO}) {
+    ll_writebackNack;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILOX, {L1_PUTS, L1_PUTS_only}) {
+  	ll_writebackNack;
+  	o_popL1RequestQueue;
+  }
+
+ transition({OLSX}, L1_PUTO) {
+    ll_writebackNack;
+    o_popL1RequestQueue;
+  }
+
+  transition(OLS, L1_GETX, OGMIO) {
+    i_allocateTBE;
+    s_recordGetXL1ID;
+    a_issueGETX;
+    h_countLocalSharersExceptRequestor;
+    // COPY DATA FROM CACHE TO TBE (happens during i_allocateTBE)
+    y_copyCacheStateToDir;
+    rr_deallocateL2CacheBlock;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+  transition(OGMIO, Fwd_GETS) {
+    t_recordFwdSID;
+    c_sendDataFromTBEToFwdGETS;
+    m_popRequestQueue;
+  }
+
+  transition(ILO, L1_GETX, IGMIO) {
+    i_allocateTBE;
+    s_recordGetXL1ID;
+    a_issueGETX;
+    // the following, of course, returns 0 sharers but do anyways for consistency
+    h_countLocalSharersExceptRequestor;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILO, L1_PUTS) {
+    ll_writebackNack;
+    o_popL1RequestQueue;
+  }
+
+  transition(IGMIO, Fwd_GETX, IGMIOF) {
+    t_recordFwdXID;
+    j_forwardGlobalRequestToLocalOwner;
+    ee_sendLocalInvSharersOnly;
+    ee_addLocalIntAck;
+    m_popRequestQueue;
+  }
+
+  transition(IGMIO, Fwd_GETS, IGMIOFS) {
+    t_recordFwdSID;
+    j_forwardGlobalRequestToLocalOwner;
+    m_popRequestQueue;
+  }
+
+  transition(IGMIOFS, Data, IGMIO) {
+    i_copyDataToTBE;
+    c_sendDataFromTBEToFwdGETS;
+    n_popResponseQueue;
+  }
+
+  transition(OGMIO, Fwd_GETX, OGMIOF) {
+    t_recordFwdXID;
+    ee_sendLocalInvSharersOnly;
+    m_popRequestQueue;
+  }
+
+  transition(OGMIOF, IntAck) {
+    m_decrementNumberOfMessagesInt;
+    o_checkForIntCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(OGMIOF, All_Acks, IGM) {
+    gg_clearLocalSharers;
+    hh_countLocalSharersExceptL1GETXRequestorInTBE;
+    c_sendDataFromTBEToFwdGETX;
+    n_popTriggerQueue;
+  }
+
+  transition(IGMIOF, IntAck) {
+    m_decrementNumberOfMessagesInt;
+    o_checkForIntCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(IGMIOF, Data_Exclusive) {
+    i_copyDataToTBE;
+    m_decrementNumberOfMessagesInt;
+    o_checkForIntCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(IGMIOF, All_Acks, IGM) {
+    gg_clearLocalSharers;
+    c_sendDataFromTBEToFwdGETX;
+    n_popTriggerQueue;
+  }
+
+  transition(IGMIO, All_Acks, IGMO) {
+    hh_countLocalSharersExceptL1GETXRequestorInTBE;
+    ee_issueLocalInvExceptL1RequestorInTBE;
+    k_forwardLocalGETXToLocalOwner;
+    e_sendAckToL1RequestorFromTBE;
+    n_popTriggerQueue;
+  }
+
+  transition(OGMIO, All_Acks, IGMO) {
+    ee_issueLocalInvExceptL1RequestorInTBE;
+    c_sendDataFromTBEToL1GETX;
+    n_popTriggerQueue;
+  }
+
+  transition({IGMIO, OGMIO}, Own_GETX) {
+    mm_decrementNumberOfMessagesExt;
+    o_checkForExtCompletion;
+    m_popRequestQueue;
+
+  }
+
+  transition(IGM, {Data, Data_Exclusive}, IGMO) {
+    i_copyDataToTBE;
+    m_decrementNumberOfMessagesExt;
+    o_checkForExtCompletion;
+    n_popResponseQueue;
+  }
+
+  transition({IGM, IGMIO, OGMIO}, ExtAck) {
+    m_decrementNumberOfMessagesExt;
+    o_checkForExtCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(IGMO, ExtAck) {
+    m_decrementNumberOfMessagesExt;
+    o_checkForExtCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(IGS, Data) {
+    i_copyDataToTBE;
+    m_decrementNumberOfMessagesExt;
+    c_sendDataFromTBEToL1GETS;
+    n_popResponseQueue;
+  }
+
+  transition(IGS, Data_Exclusive) {
+    i_copyDataToTBE;
+    m_decrementNumberOfMessagesExt;
+    c_sendExclusiveDataFromTBEToL1GETS;
+    n_popResponseQueue;
+  }
+
+  transition(IGS, Unblock, ILS) {
+    g_recordLocalSharer;
+    f_sendUnblock;
+    s_deallocateTBE;
+    n_popResponseQueue;
+  }
+
+  transition(IGS, Exclusive_Unblock, ILX) {
+    g_recordLocalExclusive;
+    f_sendExclusiveUnblock;
+    s_deallocateTBE;
+    n_popResponseQueue;
+  }
+
+  transition(IGMO, All_Acks) {
+    c_sendDataFromTBEToL1GETX;
+    n_popTriggerQueue;
+  }
+
+  transition(IGMO, Exclusive_Unblock, ILX) {
+    g_recordLocalExclusive;
+    f_sendExclusiveUnblock;
+    s_deallocateTBE;
+    n_popResponseQueue;
+  }
+
+
+  transition(SLS, L1_GETX, IGMLS) {
+    i_allocateTBE;
+    s_recordGetXL1ID;
+    a_issueGETX;
+    // count number of INVs needed that doesn't include requestor
+    h_countLocalSharersExceptRequestor;
+    // issue INVs to everyone except requestor
+    y_copyCacheStateToDir;
+    rr_deallocateL2CacheBlock;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+
+  }
+
+  transition(SLS, L1_GETS, SLSS ) {
+    d_sendDataToL1GETS;
+    r_setMRU;
+    o_popL1RequestQueue;
+  }
+
+  transition(SLSS, Unblock, SLS) {
+    g_recordLocalSharer;
+    n_popResponseQueue;
+  }
+
+  
+  transition(O, L1_GETX, IGMO) {
+    i_allocateTBE;
+    s_recordGetXL1ID;
+    a_issueGETX;
+    y_copyCacheStateToDir;
+    rr_deallocateL2CacheBlock;
+    uu_profileMiss;
+    o_popL1RequestQueue;
+  }
+   
+  transition(OLS, L1_GETS, OLSS) {
+    d_sendDataToL1GETS;
+    r_setMRU;
+    o_popL1RequestQueue;
+  }
+
+  transition(OLSS, Unblock, OLS) {
+    g_recordLocalSharer;
+    n_popResponseQueue;
+  }
+
+  transition(IGMO, Fwd_GETX, IGM) {
+    t_recordFwdXID;
+    c_sendDataFromTBEToFwdGETX;
+    m_popRequestQueue;
+   
+  }
+
+  transition(IGMO, Fwd_GETS) {
+    t_recordFwdSID;
+    c_sendDataFromTBEToFwdGETS;
+    m_popRequestQueue;
+  }
+
+  
+  // LOCAL REQUESTS SATISFIED DIRECTLY BY L2
+
+  transition(M, L1_PUTS) {
+    ll_writebackNack;
+    o_popL1RequestQueue;
+  }
+
+  transition(M, L1_GETX, MM) {
+    i_allocateTBE;
+    // should count 0 of course
+    h_countLocalSharersExceptRequestor;
+    d_sendDataToL1GETX
+    y_copyCacheStateToDir;
+    rr_deallocateL2CacheBlock;
+    s_deallocateTBE;
+    o_popL1RequestQueue;
+  }
+
+  transition(MM, Exclusive_Unblock, ILX) {
+    g_recordLocalExclusive;
+    n_popResponseQueue;
+  }
+
+  transition(M, L1_GETS, OO) {
+    i_allocateTBE;
+    // should count 0 of course
+    h_countLocalSharersExceptRequestor;
+    d_sendDataToL1GETX;
+    r_setMRU;
+    s_deallocateTBE;
+    o_popL1RequestQueue;
+  }
+
+  transition(S, L1_GETS, SS) {
+    d_sendDataToL1GETS;
+    r_setMRU;
+    o_popL1RequestQueue;
+  }
+
+  transition(SS, Unblock, SLS) {
+    g_recordLocalSharer;
+    n_popResponseQueue;
+  }
+
+  transition(O, L1_GETS, OO) {
+    d_sendDataToL1GETS;
+    r_setMRU;
+    o_popL1RequestQueue;
+  }
+
+  transition(OO, Unblock, OLS) {
+    g_recordLocalSharer;
+    n_popResponseQueue;
+  }
+
+  transition(OO, Exclusive_Unblock, ILX) {
+    g_recordLocalExclusive
+    y_copyCacheStateToDir;
+    rr_deallocateL2CacheBlock;
+    n_popResponseQueue;
+  }
+
+
+  // L1 WRITEBACKS
+  transition(ILO, L1_PUTO, ILOW) {
+    l_writebackAckNeedData;
+    o_popL1RequestQueue;
+  } 
+
+  transition(ILOX, L1_PUTO, ILOXW) {
+    l_writebackAckNeedData;
+    o_popL1RequestQueue;
+  } 
+
+
+  transition(ILOS, L1_PUTO, ILOSW) {
+    l_writebackAckNeedData;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILOSX, L1_PUTO, ILOSXW) {
+    l_writebackAckNeedData;
+    o_popL1RequestQueue;
+  }
+
+
+  // hmmm...keep data or drop.  Just drop for now
+  transition(ILOS, L1_PUTS_only, ILOW) {
+    l_writebackAckDropData;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILSW, Unblock, ILS) {
+    gg_clearSharerFromL1Response;
+    n_popResponseQueue;
+  }
+
+  transition(ILOW, Unblock, ILO) {
+    gg_clearSharerFromL1Response;
+    n_popResponseQueue;
+  }
+
+  transition(ILOSX, L1_PUTS_only, ILOXW) {
+    l_writebackAckDropData;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILOXW, Unblock, ILOX) {
+    gg_clearSharerFromL1Response;
+    n_popResponseQueue;
+  }
+
+  // hmmm...keep data or drop.  Just drop for now
+  transition(ILOS, L1_PUTS, ILOSW) {
+    l_writebackAckDropData;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILOSX, L1_PUTS, ILOSXW) {
+    l_writebackAckDropData;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILOSW, Unblock, ILOS) {
+    gg_clearSharerFromL1Response;
+    n_popResponseQueue;
+  }
+
+  transition(ILOSXW, Unblock, ILOSX) {
+    gg_clearSharerFromL1Response;
+    n_popResponseQueue;
+  }
+
+  transition(SLS, L1_PUTS, SLSW) {
+    l_writebackAckDropData;
+    o_popL1RequestQueue;
+  }
+
+  transition(SLS, L1_PUTS_only, SW) {
+    l_writebackAckDropData;
+    o_popL1RequestQueue;
+  }
+
+  transition(SW, {Unblock}, S) {
+    gg_clearSharerFromL1Response;
+    n_popResponseQueue;
+  } 
+
+  transition(OLS, L1_PUTS, OLSW) {
+    l_writebackAckDropData;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILS, {L1_PUTO}) {
+    ll_writebackNack;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILS, L1_PUTS, ILSW) {
+    l_writebackAckNeedData;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILS, L1_PUTS_only, IW) {
+    l_writebackAckNeedData;
+    o_popL1RequestQueue;
+  }
+
+   transition(OLS, L1_PUTS_only, OW) {
+    l_writebackAckDropData;
+    o_popL1RequestQueue;
+  }
+
+  transition(OLSX, L1_PUTS_only, OXW) {
+    l_writebackAckDropData;
+    o_popL1RequestQueue;
+  }
+
+  transition(OLSX, L1_PUTS, OLSXW) {
+    l_writebackAckDropData;
+    o_popL1RequestQueue;
+  }
+
+  transition(OLSXW, {Unblock}, OLSX) {
+    gg_clearSharerFromL1Response;
+    n_popResponseQueue;
+  }
+
+  transition(OW, {Unblock}, O) {
+    gg_clearSharerFromL1Response;
+    n_popResponseQueue;
+  }
+
+  transition(OXW, {Unblock}, M) {
+    gg_clearSharerFromL1Response;
+    n_popResponseQueue;
+  }
+
+  transition(ILX, L1_PUTX, ILXW ) {
+    l_writebackAckNeedData;
+    o_popL1RequestQueue;
+  }
+
+  transition(ILXW, L1_WBDIRTYDATA, M) {
+    gg_clearLocalSharers;
+    vv_allocateL2CacheBlock;
+    y_copyDirToCacheAndRemove;
+    u_writeDataToCache;
+    n_popResponseQueue;
+  }
+
+  // clean writeback
+  transition(ILXW, L1_WBCLEANDATA, M) {
+    gg_clearLocalSharers;
+    vv_allocateL2CacheBlock;
+    y_copyDirToCacheAndRemove;
+    u_writeDataToCache;
+    n_popResponseQueue;
+  }
+
+  transition(ILXW, Unblock, ILX) {
+    // writeback canceled because L1 invalidated
+    n_popResponseQueue;
+  }
+
+  transition(ILSW, L1_WBCLEANDATA, SLS) {
+    vv_allocateL2CacheBlock;
+    y_copyDirToCacheAndRemove;
+    u_writeDataToCache;
+    gg_clearSharerFromL1Response;
+    n_popResponseQueue;
+  }
+
+  transition(IW, L1_WBCLEANDATA, S) {
+    vv_allocateL2CacheBlock;
+    y_copyDirToCacheAndRemove;
+    u_writeDataToCache;
+    gg_clearSharerFromL1Response;
+    n_popResponseQueue;
+    
+  }
+
+  // Owner can have dirty data
+  transition(ILOW, {L1_WBCLEANDATA, L1_WBDIRTYDATA}, O) {
+    vv_allocateL2CacheBlock;
+    y_copyDirToCacheAndRemove;
+    gg_clearOwnerFromL1Response;
+    u_writeDataToCache;
+    n_popResponseQueue;
+  }
+
+  transition(ILOXW, L1_WBDIRTYDATA, M) {
+    vv_allocateL2CacheBlock;
+    y_copyDirToCacheAndRemove;
+    gg_clearOwnerFromL1Response;
+    u_writeDataToCache;
+    n_popResponseQueue;
+  }
+
+  transition(ILOXW, L1_WBCLEANDATA, M) {
+    vv_allocateL2CacheBlock;
+    y_copyDirToCacheAndRemove;
+    gg_clearOwnerFromL1Response;
+    u_writeDataToCache;
+    n_popResponseQueue;
+  }
+
+  transition(ILOSW, {L1_WBCLEANDATA, L1_WBDIRTYDATA}, OLS) {
+    vv_allocateL2CacheBlock;
+    y_copyDirToCacheAndRemove;
+    gg_clearOwnerFromL1Response;
+    u_writeDataToCache;
+    n_popResponseQueue;
+  }
+
+  transition(ILOSXW, {L1_WBCLEANDATA, L1_WBDIRTYDATA}, OLSX) {
+    vv_allocateL2CacheBlock;
+    y_copyDirToCacheAndRemove;
+    gg_clearOwnerFromL1Response;
+    u_writeDataToCache;
+    n_popResponseQueue;
+  }
+
+
+  transition(SLSW, {Unblock}, SLS) {
+    gg_clearSharerFromL1Response;
+    n_popResponseQueue;
+  }
+
+  transition(OLSW, {Unblock}, OLS) {
+    gg_clearSharerFromL1Response;
+    n_popResponseQueue;
+  }
+
+
+  // L2 WRITEBACKS
+  transition({I, S}, L2_Replacement, I) {
+    rr_deallocateL2CacheBlock;
+  }
+
+  transition(ILS, L2_Replacement) {
+    y_copyCacheStateToDir;
+    rr_deallocateL2CacheBlock;
+  }
+
+  transition(ILX, L2_Replacement )  {
+    y_copyCacheStateToDir;
+    rr_deallocateL2CacheBlock;
+  }
+
+  transition({ILO, ILOS}, L2_Replacement )  {
+    y_copyCacheStateToDir;
+    rr_deallocateL2CacheBlock;
+  }
+
+  transition(SLS, L2_Replacement, ILS) {
+    y_copyCacheStateToDir;
+    rr_deallocateL2CacheBlock;
+  }
+
+  transition({OLS, OLSX}, L2_Replacement, OLSI) {
+    y_copyCacheStateToDir;
+    b_issuePUTO_ls;
+    i_allocateTBE;
+    rr_deallocateL2CacheBlock;
+  }
+
+
+  transition(O, L2_Replacement, OI) {
+    b_issuePUTO;
+    i_allocateTBE;
+    rr_deallocateL2CacheBlock;
+  }
+
+  transition(M, L2_Replacement, MI) {
+    b_issuePUTX;
+    i_allocateTBE;
+    rr_deallocateL2CacheBlock;
+  }
+
+  transition(OLSI, Fwd_GETX, ILSI) {
+    t_recordFwdXID;
+    ee_sendLocalInv;
+    m_popRequestQueue;
+  }
+
+  transition(ILSI, IntAck) {
+    m_decrementNumberOfMessagesInt;
+    o_checkForIntCompletion;
+    n_popResponseQueue;
+  }
+
+  transition(ILSI, All_Acks, MII) {
+    gg_clearLocalSharers;
+    c_sendDataFromTBEToFwdGETX;
+    n_popTriggerQueue;
+  }
+
+  transition(OLSI, Fwd_GETS) {
+    t_recordFwdSID;
+    c_sendDataFromTBEToFwdGETS;
+    m_popRequestQueue;
+  }
+
+  transition({MI, OI}, Fwd_GETS, OI) {
+    t_recordFwdSID;
+    c_sendDataFromTBEToFwdGETS;
+    m_popRequestQueue;
+  }
+
+  transition({MI, OI}, Fwd_GETX, MII) {
+    t_recordFwdXID;
+    c_sendDataFromTBEToFwdGETX;
+    m_popRequestQueue;
+  }
+
+  //transition({MI, OI}, Writeback_Ack, I) {
+  transition({MI, OI}, Writeback_Ack) {
+    qq_sendDataFromTBEToMemory;
+    //s_deallocateTBE;
+    m_popRequestQueue;
+  }
+
+  transition(MII, Writeback_Nack, I) {
+    s_deallocateTBE;
+    m_popRequestQueue;
+  }
+
+  transition(OI, Writeback_Nack) {
+    b_issuePUTO;
+    m_popRequestQueue;
+  }
+
+  //transition(OLSI, Writeback_Ack, ILS) {
+  transition(OLSI, Writeback_Ack ) {
+    qq_sendDataFromTBEToMemory;
+    //s_deallocateTBE;
+    m_popRequestQueue;
+  }
+
+  transition(MII, Writeback_Ack, I) {
+    f_sendUnblock;
+    s_deallocateTBE;
+    m_popRequestQueue;
+  }
+
+  transition(ILSI, Writeback_Ack, ILS) {
+    f_sendUnblock;
+    s_deallocateTBE;
+    m_popRequestQueue;
+  }
+
+   transition({IGM,IGS,IGMIO,IGMLS,IGMO,MI,OI,OLSI} ,Mem_Nack) {
+	// Place it on timer table queue 	
+	oo_scheduleReissueTimeout;	
+	m_popRequestQueue;
+  }
+   transition({OGMIO} ,Mem_Nack) {
+    // Nothing to do in this case -> because its not waiting for data
+	m_popRequestQueue;
+  }
+
+  transition(MII, Mem_Nack, I) {
+    f_sendUnblock;
+    s_deallocateTBE;
+    m_popRequestQueue;
+  }
+
+   transition({OLSI,ILSI} ,Mem_Ack,ILS) {
+	s_deallocateTBE;
+	m_popRequestQueue;
+  }
+   transition({MI,OI} ,Mem_Ack,I) {
+	s_deallocateTBE;
+	m_popRequestQueue;
+  }
+
+  // No transistions -> we are just waiting to send the request to the
+  // directory again?
+  transition( {IGS},Reissue_Timeout) {
+	aa_issueGETS;
+	p_unsetReissueTimer;
+  }
+
+  
+   transition({IGM,IGMIO,IGMLS,IGMO,OGMIO} ,Reissue_Timeout) {
+	aa_issueGETX;	
+	p_unsetReissueTimer;
+  }
+   
+	transition({MI,OI,OLSI} ,Reissue_Timeout) {
+		qq_sendDataFromTBEToMemory;
+		p_unsetReissueTimer;
+   }
+
+  	transition({ILSI} ,Reissue_Timeout) {
+        f_sendUnblock;
+	    s_deallocateTBE;
+		p_unsetReissueTimer;
+   }
+
+  	transition({ILS} ,Reissue_Timeout) {
+		p_unsetReissueTimer;
+   }
+
+}
diff -rupN /home/grads/poremba/gems_orig/protocols/MOESI_CMP_directory_mainmem-msg.sm /home/grads/poremba/gems/protocols/MOESI_CMP_directory_mainmem-msg.sm
--- /home/grads/poremba/gems_orig/protocols/MOESI_CMP_directory_mainmem-msg.sm	1969-12-31 19:00:00.000000000 -0500
+++ /home/grads/poremba/gems/protocols/MOESI_CMP_directory_mainmem-msg.sm	2011-01-27 07:58:52.000000000 -0500
@@ -0,0 +1,174 @@
+
+/*
+    Copyright (C) 1999-2005 by Mark D. Hill and David A. Wood for the
+    Wisconsin Multifacet Project.  Contact: gems@cs.wisc.edu
+    http://www.cs.wisc.edu/gems/
+
+    --------------------------------------------------------------------
+
+    This file is part of the SLICC (Specification Language for
+    Implementing Cache Coherence), a component of the Multifacet GEMS
+    (General Execution-driven Multiprocessor Simulator) software
+    toolset originally developed at the University of Wisconsin-Madison.
+                                                                                
+    SLICC was originally developed by Milo Martin with substantial
+    contributions from Daniel Sorin.
+
+    Substantial further development of Multifacet GEMS at the
+    University of Wisconsin was performed by Alaa Alameldeen, Brad
+    Beckmann, Ross Dickson, Pacia Harper, Milo Martin, Michael Marty,
+    Carl Mauer, Kevin Moore, Manoj Plakal, Daniel Sorin, Min Xu, and
+    Luke Yen.
+
+    --------------------------------------------------------------------
+
+    If your use of this software contributes to a published paper, we
+    request that you (1) cite our summary paper that appears on our
+    website (http://www.cs.wisc.edu/gems/) and (2) e-mail a citation
+    for your published paper to gems@cs.wisc.edu.
+
+    If you redistribute derivatives of this software, we request that
+    you notify us and either (1) ask people to register with us at our
+    website (http://www.cs.wisc.edu/gems/) or (2) collect registration
+    information and periodically send it to us.
+
+    --------------------------------------------------------------------
+
+    Multifacet GEMS is free software; you can redistribute it and/or
+    modify it under the terms of version 2 of the GNU General Public
+    License as published by the Free Software Foundation.
+
+    Multifacet GEMS is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+    General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with the Multifacet GEMS; if not, write to the Free Software
+    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
+    02111-1307, USA
+
+    The GNU General Public License is contained in the file LICENSE.
+
+### END HEADER ###
+*/
+/*
+ * $Id: MOESI_CMP_directory-msg.sm 1.7 05/01/19 15:48:35-06:00 mikem@royal16.cs.wisc.edu $
+ *
+ */
+
+// CoherenceRequestType
+enumeration(CoherenceRequestType, desc="...") {
+  GETX,      desc="Get eXclusive";
+  GETS,      desc="Get Shared";
+  PUTX,      desc="Put eXclusive";
+  PUTO,      desc="Put Owned";
+  PUTO_SHARERS,      desc="Put Owned, but sharers exist so don't remove from sharers list";
+  PUTS,      desc="Put Shared";
+  WB_ACK,    desc="Writeback ack";
+  WB_ACK_DATA,    desc="Writeback ack";
+  WB_NACK,   desc="Writeback neg. ack";
+  INV,       desc="Invalidation";
+  MEM_NACK,  desc="Neg ACKnowledgment ";
+  MEM_ACK,  desc="Mem ACKnowledgment ";
+  GETX_PERSISTENT,      desc="Get eXclusive issued to main memory again";
+  GETS_PERSISTENT,      desc="Get Shared issued to main memory again";
+}
+
+// CoherenceResponseType
+enumeration(CoherenceResponseType, desc="...") {
+  ACK,               desc="ACKnowledgment, responder doesn't have a copy";
+  DATA,              desc="Data";
+  DATA_EXCLUSIVE,    desc="Data, no processor has a copy";
+  UNBLOCK,           desc="Unblock";
+  UNBLOCK_EXCLUSIVE, desc="Unblock, we're in E/M";
+  WRITEBACK_CLEAN_DATA,   desc="Clean writeback (contains data)";
+  WRITEBACK_CLEAN_ACK,   desc="Clean writeback (contains no data)";
+  WRITEBACK_DIRTY_DATA,   desc="Dirty writeback (contains data)";
+  MEM_NACK,               desc="ACKnowledgment, main memory cannot handle request right now";
+}
+
+// TriggerType
+enumeration(TriggerType, desc="...") {
+  ALL_ACKS,            desc="See corresponding event";
+}
+
+// Memory system responses - known latency is not currently supported
+enumeration(MemResponseType, desc="...") {
+  MEM_RETRY, desc="Main memory queue full - retry request later";
+  UNKNOWN, desc="Main memory processing request = unknown latency";
+  KNOWN, desc="Main memory processing done = known latency";
+}
+
+// TriggerMsg
+structure(TriggerMsg, desc="...", interface="Message") {
+  Address Address,             desc="Physical address for this request";
+  TriggerType Type,            desc="Type of trigger";
+}
+
+// RequestMsg (and also forwarded requests)
+structure(RequestMsg, desc="...", interface="NetworkMessage") {
+  Address Address,             desc="Physical address for this request";
+  CoherenceRequestType Type,   desc="Type of request (GetS, GetX, PutX, etc)";
+  MachineID Requestor,            desc="Node who initiated the request";
+  MachineType RequestorMachine,   desc="type of component";
+  NetDest Destination,             desc="Multicast destination mask";
+  int Acks,                    desc="How many acks to expect";
+  MessageSizeType MessageSize, desc="size category of the message";
+  AccessModeType AccessMode,    desc="user/supervisor access type";
+  PrefetchBit Prefetch,         desc="Is this a prefetch request";
+}
+
+// ResponseMsg (and also unblock requests)
+structure(ResponseMsg, desc="...", interface="NetworkMessage") {
+  Address Address,             desc="Physical address for this request";
+  CoherenceResponseType Type,  desc="Type of response (Ack, Data, etc)";
+  MachineID Sender,               desc="Node who sent the data";
+  MachineType SenderMachine,   desc="type of component sending msg";
+  NetDest Destination,             desc="Node to whom the data is sent";
+  DataBlock DataBlk,           desc="data for the cache line";
+  bool Dirty,                  desc="Is the data dirty (different than memory)?";
+  int Acks,                    desc="How many acks to expect";
+  MessageSizeType MessageSize, desc="size category of the message";
+}
+
+
+// ResponseMsg (and also unblock requests)
+structure(MemResponseMsg, desc="...", interface="NetworkMessage") {
+  Address Address,             desc="Physical address for this request";
+  CoherenceRequestType Type,  desc="Type of response (Ack, Data, etc)";
+  MachineID Requestor,               desc="Node who originally requested the data";
+  NetDest Destination,             desc="Node to whom the data is sent";
+  DataBlock DataBlk,           desc="data for the cache line";
+  MessageSizeType MessageSize, desc="size category of the message";
+}
+
+GenericRequestType convertToGenericType(CoherenceRequestType type) {
+  if(type == CoherenceRequestType:PUTX) {
+    return GenericRequestType:PUTX;
+  } else if(type == CoherenceRequestType:GETS) {
+    return GenericRequestType:GETS;
+  } else if(type == CoherenceRequestType:GETX) {
+    return GenericRequestType:GETX;
+  } else if(type == CoherenceRequestType:PUTS) {
+    return GenericRequestType:PUTS;
+  } else if(type == CoherenceRequestType:PUTX) {
+    return GenericRequestType:PUTS;
+  } else if(type == CoherenceRequestType:PUTO) {
+    return GenericRequestType:PUTO;
+  } else if(type == CoherenceRequestType:PUTO_SHARERS) {
+    return GenericRequestType:PUTO;
+  } else if(type == CoherenceRequestType:INV) {
+    return GenericRequestType:INV;
+  } else if(type == CoherenceRequestType:WB_ACK) {
+    return GenericRequestType:WB_ACK;
+  } else if(type == CoherenceRequestType:WB_ACK_DATA) {
+    return GenericRequestType:WB_ACK;
+  } else if(type == CoherenceRequestType:WB_NACK) {
+    return GenericRequestType:NACK;
+  } else {
+    DEBUG_EXPR(type);
+    error("invalid CoherenceRequestType");
+  }
+}
+
diff -rupN /home/grads/poremba/gems_orig/protocols/MOESI_CMP_directory_mainmem.slicc /home/grads/poremba/gems/protocols/MOESI_CMP_directory_mainmem.slicc
--- /home/grads/poremba/gems_orig/protocols/MOESI_CMP_directory_mainmem.slicc	1969-12-31 19:00:00.000000000 -0500
+++ /home/grads/poremba/gems/protocols/MOESI_CMP_directory_mainmem.slicc	2011-01-27 07:59:45.000000000 -0500
@@ -0,0 +1,5 @@
+../protocols/MOESI_CMP_directory_mainmem-msg.sm
+../protocols/MOESI_CMP_directory_mainmem-L2cache.sm
+../protocols/MOESI_CMP_directory_mainmem-L1cache.sm
+../protocols/MOESI_CMP_directory_mainmem-dir.sm
+../protocols/standard_CMP-protocol.sm
diff -rupN /home/grads/poremba/gems_orig/ruby/common/Debug.def /home/grads/poremba/gems/ruby/common/Debug.def
--- /home/grads/poremba/gems_orig/ruby/common/Debug.def	2011-02-07 16:36:51.000000000 -0500
+++ /home/grads/poremba/gems/ruby/common/Debug.def	2011-01-24 09:38:52.000000000 -0500
@@ -14,4 +14,5 @@ DEFINE_COMP(STOREBUFFER_COMP,       'b',
 DEFINE_COMP(CACHE_COMP,             'c', "Cache")
 DEFINE_COMP(PREDICTOR_COMP,         'p', "Predictor")
 DEFINE_COMP(ALLOCATOR_COMP,         'a', "Allocator")
+DEFINE_COMP(MAINMEM_COMP,           'm', "Main Memory")
 
diff -rupN /home/grads/poremba/gems_orig/ruby/config/config.include /home/grads/poremba/gems/ruby/config/config.include
--- /home/grads/poremba/gems_orig/ruby/config/config.include	2011-02-07 16:36:52.000000000 -0500
+++ /home/grads/poremba/gems/ruby/config/config.include	2011-02-10 13:19:35.000000000 -0500
@@ -288,6 +288,9 @@ PARAM( NUMBER_OF_VIRTUAL_NETWORKS );
 PARAM( FAN_OUT_DEGREE );
 PARAM_BOOL( g_PRINT_TOPOLOGY );
 
+// Main Memory Parameters
+PARAM_STRING( MM_CONFIG );
+
 // transactional memory
 PARAM( XACT_LENGTH );
 PARAM( XACT_SIZE );
diff -rupN /home/grads/poremba/gems_orig/ruby/config/rubyconfig.defaults /home/grads/poremba/gems/ruby/config/rubyconfig.defaults
--- /home/grads/poremba/gems_orig/ruby/config/rubyconfig.defaults	2011-02-07 16:36:52.000000000 -0500
+++ /home/grads/poremba/gems/ruby/config/rubyconfig.defaults	2011-02-14 09:27:04.000000000 -0500
@@ -464,3 +464,7 @@ MEM_FIXED_DELAY: 0
 // BASIC_BUS_BUSY_TIME: 3
 // MEM_CTL_LATENCY: 20
 // REFRESH_PERIOD: 3120
+
+
+MM_CONFIG: mainmem.conf
+
diff -rupN /home/grads/poremba/gems_orig/ruby/config/RubyConfig.h /home/grads/poremba/gems/ruby/config/RubyConfig.h
--- /home/grads/poremba/gems_orig/ruby/config/RubyConfig.h	2011-02-07 16:36:52.000000000 -0500
+++ /home/grads/poremba/gems/ruby/config/RubyConfig.h	2011-02-10 13:19:17.000000000 -0500
@@ -159,6 +159,8 @@ public:
   static void init();
   static void printConfiguration(ostream& out);
 
+  static char* getMainMemConfig() { return MM_CONFIG; }
+
   // Memory Controller
   static int memBusCycleMultiplier () { return MEM_BUS_CYCLE_MULTIPLIER; }
   static int banksPerRank () { return BANKS_PER_RANK; }
diff -rupN /home/grads/poremba/gems_orig/ruby/init.C /home/grads/poremba/gems/ruby/init.C
--- /home/grads/poremba/gems_orig/ruby/init.C	2011-02-07 16:36:52.000000000 -0500
+++ /home/grads/poremba/gems/ruby/init.C	2011-01-24 10:21:47.000000000 -0500
@@ -102,6 +102,7 @@ extern "C" attr_value_t ruby_session_get
                                           attr_value_t *idx );
 extern "C" set_error_t ruby_session_set( void *id, conf_object_t *obj, 
                                          attr_value_t *val, attr_value_t *idx );
+extern void configure_mainmem( void );
 static  initvar_t  *ruby_initvar_obj = NULL;
 
 //***************************************************************************
@@ -189,6 +190,10 @@ void init_simulator()
   }
 #endif // #ifdef CONTIGUOUS_ADDRESSES
 
+#ifdef SIM_MAINMEM
+  configure_mainmem();
+#endif
+
   cout << "Ruby initialization complete" << endl;
 }
 
diff -rupN /home/grads/poremba/gems_orig/ruby/mainmem/MainMem.C /home/grads/poremba/gems/ruby/mainmem/MainMem.C
--- /home/grads/poremba/gems_orig/ruby/mainmem/MainMem.C	1969-12-31 19:00:00.000000000 -0500
+++ /home/grads/poremba/gems/ruby/mainmem/MainMem.C	2011-02-14 16:49:08.000000000 -0500
@@ -0,0 +1,216 @@
+/*
+ *  This file is part of NVMain- A cycle accurate timing, bit-accurate
+ *  energy simulator for non-volatile memory. Originally developed by 
+ *  Matt Poremba at the Pennsylvania State University.
+ *
+ *  Website: __WEBSITE__
+ *  Email: mrp5060@psu.edu
+ *
+ *  ---------------------------------------------------------------------
+ *
+ *  If you use this software for publishable research, please include 
+ *  the original NVMain paper in the citation list and mention the use 
+ *  of NVMain.
+ *
+ */
+
+#include "MainMem.h"
+#include "mainmem_interface.h"
+
+#include "System.h"
+#include "Global.h"
+#include "MemResponseType.h"
+#include "Chip.h"
+
+#include "RankWrapper.h"
+#include "AddressTranslator.h"
+
+#include "Config.h"
+#include "nvmain.h"
+
+#define MAINMEM_WAKEUP_PERIOD 1
+
+
+void send_data_to_Directory( Address address, CoherenceRequestType type, MachineID Requestor, MachineID dirOwner );
+MemResponseType send_request_to_memory( Address address, CoherenceRequestType type, MachineID Requestor, MachineID dirOwner, DataBlock *dBlock);
+
+
+MainMem::MainMem()
+{
+  g_eventQueue_ptr->scheduleEvent( this, MAINMEM_WAKEUP_PERIOD );
+  m_request_id = 0;
+  m_request_list.clear( );
+
+  memory = new NVMain( );
+  config = new Config( );
+
+  config->Read( RubyConfig::getMainMemConfig( ) );
+
+  std::cout << "NVMain: Reading configuration file " << RubyConfig::getMainMemConfig( ) << std::endl;
+
+  memory->SetConfig( config );
+}
+
+
+MainMem::~MainMem()
+{
+  delete memory;
+}
+
+
+void MainMem::wakeup( )
+{
+  Time current_time = g_eventQueue_ptr->getTime(); 
+  list<MemRequest *>::iterator requestIterator;
+  MemRequest *completedRequest;
+
+  //cout << "[MainMem] Woke up.\n";
+
+  if( !m_request_list.empty( ) )
+  {
+    for( requestIterator = m_request_list.begin(); 
+	 requestIterator != m_request_list.end();
+	 requestIterator++ )
+      {
+	if( ( *requestIterator)->status == MEM_REQUEST_COMPLETE )
+	  //if( current_time - (*requestIterator)->request_time >= 1000 )
+	  {
+	    //std::cout << "[MainMem]: NVMain reported request complete.\n";
+	    send_data_to_Directory( (*requestIterator)->m_address, (*requestIterator)->m_type,
+				    (*requestIterator)->m_requestor, (*requestIterator)->m_dirOwner );
+	    
+	    completedRequest = *requestIterator;
+	    /*
+	     * TODO: Apparently deleting this request pointer causes problems, which means
+	     * something in the networking code is assuming ownership of pointer in the MemRequest
+	     * struct. Fix this obvious memory leak here.
+	     */
+
+	    m_request_list.erase( requestIterator );
+	    requestIterator--;
+	    
+	    
+	    if( m_request_list.empty( ) )
+	      break;
+	  }
+      }
+  }
+
+  g_eventQueue_ptr->scheduleEvent( this, MAINMEM_WAKEUP_PERIOD );
+  memory->Cycle( );
+
+  m_last_wakeup = current_time;
+}
+
+void MainMem::printStats( ostream& out )
+{
+
+}
+
+void MainMem::print(ostream& out) const
+{
+  out << "[MainMem]";
+}
+
+
+std::list<MemRequest *> *MainMem::getRequestList( )
+{
+  return &m_request_list;
+}
+
+
+NVMain *MainMem::getMemory( )
+{
+  return memory;
+}
+
+
+void configure_mainmem( )
+{
+
+}
+
+void send_data_to_Directory( Address address, CoherenceRequestType type, MachineID Requestor, MachineID dirOwner )
+{  
+  int chip_id = dirOwner.num / RubyConfig::numberOfDirectoryPerChip();
+  int dir_id = dirOwner.num % RubyConfig::numberOfDirectoryPerChip();
+  Chip* chip_ptr = dynamic_cast<Chip *>(g_system_ptr->getChip( chip_id ));
+  MemResponseMsg out_msg;
+
+  out_msg.m_Address = address;
+  out_msg.m_Type = type;
+  out_msg.m_Requestor = Requestor;
+  out_msg.m_Destination.add( dirOwner );
+
+  chip_ptr->m_Directory_addressFromMem_vec[dir_id]->enqueue( out_msg );
+}
+
+MemResponseType send_get_request_to_memory( Address address, CoherenceRequestType type, MachineID Requestor, MachineID dirOwner)
+{
+  DataBlock *tempBlock = new DataBlock( );
+  MemResponseType rv;
+
+  rv = send_request_to_memory( address, type, Requestor, dirOwner, tempBlock);
+
+  delete tempBlock;
+
+  return rv;
+}
+
+MemResponseType send_put_request_to_memory( Address address, CoherenceRequestType type, MachineID Requestor, MachineID dirOwner, DataBlock dBlock)
+{
+  return send_request_to_memory( address, type, Requestor, dirOwner, &dBlock);
+}
+
+MemResponseType send_request_to_memory( Address address, CoherenceRequestType type, MachineID Requestor, MachineID dirOwner, DataBlock *dBlock)
+{ 
+  std::list<MemRequest *> *requestList;
+  std::list<MemRequest *>::iterator requestIterator;
+  MemRequest *request = new MemRequest( );
+
+
+  /*
+   *  Build this request to search for it and add to the request list. 
+   */
+  request->m_address = address;
+  request->m_type = type;
+  request->m_requestor = Requestor;
+  request->m_dirOwner = dirOwner;
+
+  /*
+   *  Get the request list from our class... This avoids using global variables.
+   *
+   *  A request list is used so the wakeup() function knows to schedule a wakeup.
+   *  None of the code in this file should modify any of the requests!!! A copy
+   *  of the request is send to NVMain as a pointer, so the memory controller 
+   *  should mark this as completed, and then the wakeup() function will remove
+   *  the request from this request list.
+   */
+  requestList = g_system_ptr->getMainMem( )->getRequestList( );
+
+  /*
+   *  Check if the request has already been added to the list. If it has not, add it.
+   */
+
+  if( requestList->empty( ) )
+    requestIterator = requestList->end( );
+  else
+    requestIterator = find( requestList->begin(), requestList->end(), request );
+  
+
+  if( requestIterator == requestList->end() )
+  {
+    request->request_time = g_eventQueue_ptr->getTime();
+    request->request_id = g_system_ptr->getMainMem( )->getRequestId( );
+    g_system_ptr->getMainMem( )->setRequestId( request->request_id + 1 );
+
+    requestList->push_back( request );
+
+    g_system_ptr->getMainMem( )->getMemory( )->NewRequest( request );
+
+    g_eventQueue_ptr->scheduleEvent( g_system_ptr->getMainMem(), MAINMEM_WAKEUP_PERIOD );
+  }
+
+
+  return MemResponseType_UNKNOWN;
+}
diff -rupN /home/grads/poremba/gems_orig/ruby/mainmem/MainMem.h /home/grads/poremba/gems/ruby/mainmem/MainMem.h
--- /home/grads/poremba/gems_orig/ruby/mainmem/MainMem.h	1969-12-31 19:00:00.000000000 -0500
+++ /home/grads/poremba/gems/ruby/mainmem/MainMem.h	2011-02-14 16:49:10.000000000 -0500
@@ -0,0 +1,66 @@
+/*
+ *  This file is part of NVMain- A cycle accurate timing, bit-accurate
+ *  energy simulator for non-volatile memory. Originally developed by 
+ *  Matt Poremba at the Pennsylvania State University.
+ *
+ *  Website: __WEBSITE__
+ *  Email: mrp5060@psu.edu
+ *
+ *  ---------------------------------------------------------------------
+ *
+ *  If you use this software for publishable research, please include 
+ *  the original NVMain paper in the citation list and mention the use 
+ *  of NVMain.
+ *
+ */
+
+#ifdef SIM_MAINMEM
+
+#ifndef MAINMEM_H
+#define MAINMEM_H
+
+#include "Consumer.h"
+
+#include "MemRequest.h"
+
+//#include "nvmain.h"
+//#include "Config.h"
+
+#include <list>
+
+
+class NVMain;
+class Config;
+
+
+class MainMem : public Consumer
+{
+public:
+  MainMem();
+  ~MainMem();
+
+  // Virtual Methods
+  void wakeup();
+  void print(ostream& out) const;
+
+  void printStats(ostream& out);
+
+  std::list<MemRequest *> *getRequestList( );
+  NVMain *getMemory( );
+
+  int getRequestId( void ) { return m_request_id; };
+  void setRequestId( int r ) { m_request_id = r; };
+
+private:
+  Time m_last_wakeup;
+  unsigned int m_request_id;
+  std::list<MemRequest *> m_request_list;
+  NVMain *memory;
+  Config *config;
+
+};
+
+
+#endif
+
+#endif
diff -rupN /home/grads/poremba/gems_orig/ruby/mainmem/mainmem_interface.h /home/grads/poremba/gems/ruby/mainmem/mainmem_interface.h
--- /home/grads/poremba/gems_orig/ruby/mainmem/mainmem_interface.h	1969-12-31 19:00:00.000000000 -0500
+++ /home/grads/poremba/gems/ruby/mainmem/mainmem_interface.h	2011-02-10 09:13:52.000000000 -0500
@@ -0,0 +1,31 @@
+/*
+ *  This file is part of NVMain- A cycle accurate timing, bit-accurate
+ *  energy simulator for non-volatile memory. Originally developed by 
+ *  Matt Poremba at the Pennsylvania State University.
+ *
+ *  Website: __WEBSITE__
+ *  Email: mrp5060@psu.edu
+ *
+ *  ---------------------------------------------------------------------
+ *
+ *  If you use this software for publishable research, please include 
+ *  the original NVMain paper in the citation list and mention the use 
+ *  of NVMain.
+ *
+ */
+
+#ifdef SIM_MAINMEM
+#ifndef MAINMEM_INTERFACE_H
+#define MAINMEM_INTERFACE_H
+
+#include "MemResponseType.h"
+#include "Address.h"
+#include "MachineID.h"
+#include "CoherenceRequestType.h"
+#include "DataBlock.h"
+
+MemResponseType send_get_request_to_memory( Address address, CoherenceRequestType type, MachineID Requestor, MachineID dirOwner);
+MemResponseType send_put_request_to_memory( Address address, CoherenceRequestType type, MachineID Requestor, MachineID dirOwner, DataBlock dBlock);
+
+#endif
+#endif
diff -rupN /home/grads/poremba/gems_orig/ruby/mainmem/Makefile.gems /home/grads/poremba/gems/ruby/mainmem/Makefile.gems
--- /home/grads/poremba/gems_orig/ruby/mainmem/Makefile.gems	1969-12-31 19:00:00.000000000 -0500
+++ /home/grads/poremba/gems/ruby/mainmem/Makefile.gems	2011-02-11 13:04:55.000000000 -0500
@@ -0,0 +1,23 @@
+include $(MEM_DIR)/Makefile.nvmain
+
+CC = g++
+AR = ar
+CXXFLAGS = -DGEMS $(RUBY_FLAGS)
+INCLUDES = -I$(NVM_DIR)/src -I$(NVM_DIR)/NVM  -I$(NVM_DIR)/MemControl/$(MEM_CONTROL)
+MEM_OBJ = $(MEM_DIR)/MainMem.o
+MEM_SRC = $(MEM_DIR)/MainMem.C 
+
+
+$(MEM_OBJ): $(MEM_SRC)
+	$(CC)  -c -o $@ $< $(INCLUDES) $(CXXFLAGS)
+
+
+clean:
+	rm -f $(MEM_DIR)/*.o
+	rm -f $(MEM_DIR)/*~
+
+
+
+
+
+
diff -rupN /home/grads/poremba/gems_orig/ruby/mainmem/Makefile.nvmain /home/grads/poremba/gems/ruby/mainmem/Makefile.nvmain
--- /home/grads/poremba/gems_orig/ruby/mainmem/Makefile.nvmain	1969-12-31 19:00:00.000000000 -0500
+++ /home/grads/poremba/gems/ruby/mainmem/Makefile.nvmain	2011-02-11 13:12:58.000000000 -0500
@@ -0,0 +1,20 @@
+#
+# This includes all the new variables needed for the main makefile for ruby
+# so there are minimal changes to that file.
+#
+
+MEM_DIR = $(GEMS_ROOT)/ruby/mainmem
+NVM_DIR = /home/grads/poremba/Research/2011/NVMain/trunk
+
+MEM_SRC = $(notdir $(shell ls $(MEM_DIR)/*.C))
+MEM_OBJ = $(addprefix $(MEM_DIR)/,$(MEM_SRC:.C=.o))
+
+NVM_SRC = $(shell find $(NVM_DIR) -type f -name "*.cpp")
+NVM_OBJ = $(shell echo $(NVM_SRC) | sed 's/.cpp/.o/g')
+NVM_ARC = $(NVM_DIR)/nvmain.a
+
+RUBY_DIR = $(shell pwd)
+
+SPECIAL_FLAGS += -DSIM_MAINMEM
+
+
diff -rupN /home/grads/poremba/gems_orig/ruby/mainmem/MemRequest.h /home/grads/poremba/gems/ruby/mainmem/MemRequest.h
--- /home/grads/poremba/gems_orig/ruby/mainmem/MemRequest.h	1969-12-31 19:00:00.000000000 -0500
+++ /home/grads/poremba/gems/ruby/mainmem/MemRequest.h	2011-02-10 09:13:42.000000000 -0500
@@ -0,0 +1,72 @@
+/*
+ *  This file is part of NVMain- A cycle accurate timing, bit-accurate
+ *  energy simulator for non-volatile memory. Originally developed by 
+ *  Matt Poremba at the Pennsylvania State University.
+ *
+ *  Website: __WEBSITE__
+ *  Email: mrp5060@psu.edu
+ *
+ *  ---------------------------------------------------------------------
+ *
+ *  If you use this software for publishable research, please include 
+ *  the original NVMain paper in the citation list and mention the use 
+ *  of NVMain.
+ *
+ */
+
+#ifdef SIM_MAINMEM
+
+#ifndef MEMREQUEST_H
+#define MEMREQUEST_H
+
+
+#include "Address.h"
+#include "MachineID.h"
+#include "CoherenceRequestType.h"
+
+
+enum MemRequestStatus { MEM_REQUEST_INCOMPLETE, MEM_REQUEST_COMPLETE, MEM_REQUEST_NUM };
+
+class MemRequest
+{
+public:
+  MemRequest( ) { };
+  ~MemRequest( ) { };
+
+
+  Address m_address;
+  CoherenceRequestType m_type;
+  MachineID m_requestor;
+  MachineID m_dirOwner;
+  MemRequestStatus status;
+  unsigned int request_id;
+
+  // temporary:
+  Time request_time;
+
+};
+
+
+bool operator==( const MemRequest& obj1, const MemRequest& obj2 );
+bool operator!=( const MemRequest& obj1, const MemRequest& obj2 );
+
+
+inline
+bool operator==( const MemRequest& obj1, const MemRequest& obj2 )
+{
+  return ( obj1.m_address == obj2.m_address && obj1.m_type == obj2.m_type &&
+	   obj1.m_requestor == obj2.m_requestor && obj1.m_dirOwner == obj2.m_dirOwner );
+}
+
+
+inline
+bool operator!=( const MemRequest& obj1, const MemRequest& obj2 )
+{
+  return ( obj1.m_address != obj2.m_address || obj1.m_type != obj2.m_type ||
+	   obj1.m_requestor != obj2.m_requestor || obj1.m_dirOwner != obj2.m_dirOwner );
+}
+  
+
+#endif
+
+#endif
diff -rupN /home/grads/poremba/gems_orig/ruby/Makefile /home/grads/poremba/gems/ruby/Makefile
--- /home/grads/poremba/gems_orig/ruby/Makefile	2011-02-07 16:36:52.000000000 -0500
+++ /home/grads/poremba/gems/ruby/Makefile	2011-02-14 08:47:03.000000000 -0500
@@ -61,6 +61,7 @@ include network/${NETWORK}/Makefile.incl
 include network/${GARNET}/Makefile.include
 include network/${GARNET_DETAIL}/Makefile.include
 include network/${ORION}/Makefile.include
+include mainmem/Makefile.nvmain
 
 ifdef PROTOCOL
 GENERATED_DIR := generated/$(PROTOCOL)
@@ -69,7 +70,7 @@ endif
 
 # Note that VPATH has to be defined before the common Makefile is
 # included.
-VPATH = ${NETWORK_VPATH}:${GARNET_VPATH}:.:${GARNET_DETAIL_VPATH}:${ORION_VPATH}:$(GEMS_ROOT)/common:$(GEMS_ROOT)/common/gzstream:buffers:common:slicc_interface:profiler:config:eventqueue:system:interfaces:simics:tester:recorder:log_tm:rock:$(GENERATED_DIR):$(GEMS_ROOT)/common/ioutil:network
+VPATH = ${NETWORK_VPATH}:${GARNET_VPATH}:.:${GARNET_DETAIL_VPATH}:${ORION_VPATH}:$(GEMS_ROOT)/common:$(GEMS_ROOT)/common/gzstream:buffers:common:slicc_interface:profiler:config:eventqueue:system:interfaces:simics:tester:recorder:log_tm:rock:$(GENERATED_DIR):$(GEMS_ROOT)/common/ioutil:network:$(MEM_DIR)
 
 # Need to keep this statement here, the order is tricky here
 include $(GEMS_ROOT)/common/Makefile.common
@@ -314,6 +315,8 @@ else
 endif
 endif
 endif
+	rm -f $(MEM_OBJ)
+	$(MAKE) -f $(NVM_DIR)/Makefile NVM_DIR="$(NVM_DIR)" clean
 
 # Generate protocol handlers from protocol descriptions
 $(GENERATED_DIR)/generated: $(GENERATED_DIR)/created $(HTML_DIR)/created $(DESC) $(SLICC) attrparse.y attrlex.l
@@ -330,17 +333,16 @@ $(GENERATED_DIR)/default_param.h: ../com
 $(GENERATED_DIR)/tester_param.h: ../common/ioutil/embedtext.py config/tester.defaults
 	python ../common/ioutil/embedtext.py config/tester.defaults $(GENERATED_DIR)/tester_param.h global_default_tester_param
 
-$(BIN_DIR)/tester.exec: simics_api_dummy.c $(RUBY_OBJ) $(BIN_DIR)/created $(GENERATED_DIR)/generated
-	@echo ""
+$(BIN_DIR)/tester.exec: simics_api_dummy.c $(RUBY_OBJ) $(BIN_DIR)/created $(GENERATED_DIR)/generated $(MEM_OBJ) $(NVM_ARC)
 	@echo "Linking tester binary ..."
-	$(CC) -o $@ $(LDFLAGS) simics/simics_api_dummy.c $(RUBY_OBJ) 
+	$(CC) -o $@ $(LDFLAGS) simics/simics_api_dummy.c $(RUBY_OBJ) $(MEM_OBJ) $(NVM_ARC) 
 	@echo "Made tester"
 
 # make ruby.closure for template closure, as side effect some .o will get
 # recompiled. If you see error in this stage, it might be the case you want to
 # add more dummy functions in simics_api_dummy.c.
-$(BIN_DIR)/ruby.closure: simics_api_dummy.c $(RUBY_OBJ) $(BIN_DIR)/created $(GENERATED_DIR)/generated
-	$(CC) -o /dev/null $(LDFLAGS) simics/simics_api_dummy.c $(RUBY_OBJ) 
+$(BIN_DIR)/ruby.closure: simics_api_dummy.c $(RUBY_OBJ) $(BIN_DIR)/created $(GENERATED_DIR)/generated $(MEM_OBJ) $(NVM_ARC)
+	$(CC) -o /dev/null $(LDFLAGS) simics/simics_api_dummy.c $(RUBY_OBJ) $(MEM_OBJ) $(NVM_ARC)
 	touch $@
 	@echo "Template closure done"
 
@@ -361,6 +363,17 @@ else
 endif
 endif
 
+$(MEM_OBJ): $(MEM_SRC)
+	@echo "Building main memory simulator interface..."
+	$(MAKE) -f $(MEM_DIR)/Makefile.gems CXXFLAGS="${CFLAGS}" MEM_DIR="${MEM_DIR}" RUBY_DEBUG=0
+	$(CP) $(MEM_DIR)/*.o $(RUBY_OBJ_DIR)
+
+$(NVM_ARC): $(NVM_SRC)
+	@echo "Building NVMain simulator..."
+	$(MAKE) -f $(NVM_DIR)/Makefile NVM_DIR="$(NVM_DIR)" clean
+	$(MAKE) -f $(NVM_DIR)/Makefile RUBY_FLAGS="$(CFLAGS)" RUBY="$(RUBY_DIR)" NVM_DIR="${NVM_DIR}" TRACE=0 
+	$(MAKE) -f $(NVM_DIR)/Makefile RUBY_FLAGS="$(CFLAGS)" RUBY="$(RUBY_DIR)" NVM_DIR="${NVM_DIR}" TRACE=0 nvmain
+	$(CP) $(NVM_ARC) $(RUBY_OBJ_DIR)
 
 DEP := $(addprefix $(RUBY_OBJ_DIR)/,$(SRC_C:.c=.d) $(SRC_CPP:.C=.d))
 
diff -rupN /home/grads/poremba/gems_orig/ruby/module/Makefile /home/grads/poremba/gems/ruby/module/Makefile
--- /home/grads/poremba/gems_orig/ruby/module/Makefile	2011-02-07 16:36:52.000000000 -0500
+++ /home/grads/poremba/gems/ruby/module/Makefile	2011-02-14 08:55:52.000000000 -0500
@@ -17,12 +17,13 @@
 #   CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 
 # For Simics 2.X
-GEMS_ROOT = $(SIMICS_BASE)/../
+#GEMS_ROOT = $(SIMICS_BASE)/../
 
 # For Simics 3.0
-#GEMS_ROOT = $(SRC_BASE)/../../
+GEMS_ROOT = $(SRC_BASE)/../../
 
 include $(GEMS_ROOT)/common/Makefile.simics_version
+include $(GEMS_ROOT)/ruby/mainmem/Makefile.nvmain
 
 MODULE_DIR = ruby
 MODULE_NAME = ruby
@@ -86,6 +87,7 @@ endif
 # overwritting their linking parameters.
 #MODULE_LDFLAGS += -Wl,-Bstatic -lstdc++ -lz -static-libgcc
 MODULE_LDFLAGS += -Wl,-Bdynamic -lstdc++ -lz -shared-libgcc
+MODULE_LDFLAGS += $(NVM_DIR)/nvmain.a
 
 LDFLAGS_DYN = 
 
diff -rupN /home/grads/poremba/gems_orig/ruby/profiler/Profiler.C /home/grads/poremba/gems/ruby/profiler/Profiler.C
--- /home/grads/poremba/gems_orig/ruby/profiler/Profiler.C	2011-02-07 16:36:51.000000000 -0500
+++ /home/grads/poremba/gems/ruby/profiler/Profiler.C	2011-01-26 16:57:52.000000000 -0500
@@ -95,6 +95,9 @@
 #include "interface.h"
 #include "XactVisualizer.h"
 #include "XactProfiler.h"
+#ifdef SIM_MAINMEM
+#include "MainMem.h"
+#endif
 
 extern "C" {
 #include "Rock.h"
@@ -243,6 +246,10 @@ void Profiler::wakeup()
   if (PROFILE_ALL_INSTRUCTIONS) {
     m_inst_profiler_ptr->printStats(*m_periodic_output_file_ptr);
   }
+
+#ifdef SIM_MAINMEM
+  g_system_ptr->getMainMem()->printStats(*m_periodic_output_file_ptr);
+#endif
   
   //g_system_ptr->getNetwork()->printStats(*m_periodic_output_file_ptr);
   g_eventQueue_ptr->scheduleEvent(this, m_stats_period);
diff -rupN /home/grads/poremba/gems_orig/ruby/system/System.C /home/grads/poremba/gems/ruby/system/System.C
--- /home/grads/poremba/gems_orig/ruby/system/System.C	2011-02-07 16:36:52.000000000 -0500
+++ /home/grads/poremba/gems/ruby/system/System.C	2011-01-26 17:14:19.000000000 -0500
@@ -67,6 +67,9 @@
 #include "System.h"
 #include "Profiler.h"
 #include "Network.h"
+#ifdef SIM_MAINMEM
+#include "MainMem.h"
+#endif
 #include "Tester.h"
 #include "SimicsDriver.h"
 #include "SyntheticDriver.h"
@@ -86,6 +89,9 @@ System::System()
 
   m_driver_ptr = NULL;
   m_profiler_ptr = new Profiler;
+#ifdef SIM_MAINMEM
+  m_mainmem_ptr = new MainMem( );
+#endif
 
   // NETWORK INITIALIZATION
   // create the network by calling a function that calls new
@@ -180,6 +186,9 @@ void System::printStats(ostream& out)
   }
   m_network_ptr->printStats(out);
   m_driver_ptr->printStats(out);
+#ifdef SIM_MAINMAIN
+  m_mainmem_ptr->printStats(out);
+#endif
   Chip::printStats(out);
 }
 
diff -rupN /home/grads/poremba/gems_orig/ruby/system/System.h /home/grads/poremba/gems/ruby/system/System.h
--- /home/grads/poremba/gems_orig/ruby/system/System.h	2011-02-07 16:36:52.000000000 -0500
+++ /home/grads/poremba/gems/ruby/system/System.h	2011-02-07 15:38:22.000000000 -0500
@@ -78,6 +78,9 @@
 class Profiler;
 class Network;
 class Driver;
+#ifdef SIM_MAINMEM
+class MainMem;
+#endif
 class CacheRecorder;
 class Tracer;
 class Sequencer;
@@ -101,6 +104,9 @@ public:
   Driver* getDriver() { assert(m_driver_ptr != NULL); return m_driver_ptr; }
   Tracer* getTracer() { assert(m_tracer_ptr != NULL); return m_tracer_ptr; }
   Network* getNetwork() { assert(m_network_ptr != NULL); return m_network_ptr; }
+#ifdef SIM_MAINMEM
+  MainMem* getMainMem() { assert(m_mainmem_ptr != NULL); return m_mainmem_ptr; }
+#endif
   XactIsolationChecker* getXactIsolationChecker() { assert(m_xact_isolation_checker!= NULL); return m_xact_isolation_checker;} 
   XactCommitArbiter* getXactCommitArbiter() { assert(m_xact_commit_arbiter!= NULL); return m_xact_commit_arbiter;} 
   XactVisualizer*    getXactVisualizer() { assert(m_xact_visualizer!= NULL); return m_xact_visualizer;} 
@@ -139,6 +145,9 @@ private:
   Profiler* m_profiler_ptr;
   Driver* m_driver_ptr;
   Tracer* m_tracer_ptr;
+#ifdef SIM_MAINMEM
+  MainMem* m_mainmem_ptr;
+#endif
   XactIsolationChecker *m_xact_isolation_checker;
   XactCommitArbiter    *m_xact_commit_arbiter;
   XactVisualizer       *m_xact_visualizer;
diff -rupN /home/grads/poremba/gems_orig/scripts/makesymlinks.sh /home/grads/poremba/gems/scripts/makesymlinks.sh
--- /home/grads/poremba/gems_orig/scripts/makesymlinks.sh	2011-02-07 16:36:58.000000000 -0500
+++ /home/grads/poremba/gems/scripts/makesymlinks.sh	2010-10-02 10:48:33.000000000 -0400
@@ -22,7 +22,7 @@ cd ../..
 # in your Simics 3 install
 echo "Making symlink for import directory..."
 #ln -s /simics-3.0.11/import import
-ln -s [SET PATH TO SIMICS INSTALL HERE]/import import
+ln -s $SIMICS_INSTALL/import import
 
 echo "Making symlinks for modules..."
 cd modules
diff -rupN /home/grads/poremba/gems_orig/slicc/symbols/StateMachine.C /home/grads/poremba/gems/slicc/symbols/StateMachine.C
--- /home/grads/poremba/gems_orig/slicc/symbols/StateMachine.C	2011-02-07 16:37:02.000000000 -0500
+++ /home/grads/poremba/gems/slicc/symbols/StateMachine.C	2011-01-24 14:57:08.000000000 -0500
@@ -260,6 +260,9 @@ void StateMachine::printControllerH(ostr
   out << "#include \"Consumer.h\"" << endl;
   out << "#include \"TransitionResult.h\"" << endl;
   out << "#include \"Types.h\"" << endl;
+  if( getIdent() == "Directory" ) {
+    out << "#include \"mainmem_interface.h\"" << endl;
+  }
   out << "#include \"" << component << "_Profiler.h\"" << endl;
   out << endl;
 
@@ -433,6 +436,9 @@ void StateMachine::printCWakeup(ostream&
   out << "#include \"Types.h\"" << endl;
   out << "#include \"System.h\"" << endl;
   out << "#include \"Chip.h\"" << endl;
+  if( getIdent() == "Directory" ) {
+    out << "#include \"mainmem_interface.h\"" << endl;
+  }
   out << endl;
   out << "void " << component << "_Controller::wakeup()" << endl;
   out << "{" << endl;
